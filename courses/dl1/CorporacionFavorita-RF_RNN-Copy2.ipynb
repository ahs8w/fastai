{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:39:33.984864Z",
     "start_time": "2018-03-22T22:39:33.566315Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:39:35.549224Z",
     "start_time": "2018-03-22T22:39:34.058442Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastai.structured import *\n",
    "# from fastai.column_data import *\n",
    "np.set_printoptions(threshold=50, edgeitems=25)\n",
    "\n",
    "PATH='data/favorita/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:39:35.843540Z",
     "start_time": "2018-03-22T22:39:35.679371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holidays_events.csv        stores.csv\r\n",
      "items.csv                  test.csv\r\n",
      "oil.csv                    train.csv\r\n",
      "\u001b[34mrf_rnn\u001b[m\u001b[m                     train_six_months_full_data\r\n",
      "sample_submission.csv      transactions.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:39:36.019303Z",
     "start_time": "2018-03-22T22:39:35.980411Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate into 2 models\n",
    "\n",
    "1. Store/Item/Date combinations exist in test -> DOW/DOM averages\n",
    "2. Store/Item/Date combinations do not exist -> Remove store_nbr, item_nbr, use family,cluster,etc. to generalize  \n",
    "    [0.7118, 0.7376, 0.3322, 0.28510000000000002]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/aharless/dissecting-ceshine-lee-s-lgbm-kernel\n",
    "\n",
    "https://www.kaggle.com/captcalculator/a-very-extensive-favorita-exploratory-analysis/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Validation Set which best mimics % of missing Test combos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving averages\n",
    "https://www.kaggle.com/paulorzp/log-ma-and-days-of-week-means-lb-0-529/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:07:47.062005Z",
     "start_time": "2018-03-22T21:07:47.025014Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtypes = {'id':'uint32', 'item_nbr':'uint32', 'store_nbr':'uint8', 'onpromotion':'bool'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:09:09.055463Z",
     "start_time": "2018-03-22T21:07:47.431185Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{PATH}train.csv', usecols=[1, 2, 3, 4, 5], dtype=dtypes,\n",
    "            converters={'unit_sales': lambda u: np.log1p(float(u)) if float(u) > 0 else 0},\n",
    "            parse_dates=['date'], skiprows=range(1, 114176251))  # header counts as row 0\n",
    "\n",
    "# 86672217 => Skip dates before 2016-08-01\n",
    "# 114176250 => 2017-05-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:11:25.073813Z",
     "start_time": "2018-03-22T21:11:21.810643Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load test\n",
    "test = pd.read_csv(f'{PATH}test.csv', dtype=dtypes, parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join tables and remove item_nbr and store_nbr -> generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:13:29.241820Z",
     "start_time": "2018-03-22T21:13:29.199094Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items = pd.read_csv(f'{PATH}items.csv', low_memory=False)\n",
    "stores = pd.read_csv(f'{PATH}stores.csv', low_memory=False)\n",
    "# holidays = pd.read_csv(f'{PATH}holidays_events.csv', parse_dates=['date'], low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:31:15.906309Z",
     "start_time": "2018-03-21T21:31:15.859512Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:13:47.495489Z",
     "start_time": "2018-03-22T21:13:45.318670Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, stores, how='left', on=['store_nbr'])\n",
    "test = pd.merge(test, stores, how='left', on=['store_nbr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:13:48.789363Z",
     "start_time": "2018-03-22T21:13:48.752009Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:31:38.901116Z",
     "start_time": "2018-03-21T21:31:38.858824Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:14:03.549368Z",
     "start_time": "2018-03-22T21:13:59.656818Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, items, how='left', on=['item_nbr'])\n",
    "test = pd.merge(test, items, how='left', on=['item_nbr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:14:36.767993Z",
     "start_time": "2018-03-22T21:14:36.731578Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove 'store_nbr' and 'item_nbr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:14:55.587668Z",
     "start_time": "2018-03-22T21:14:54.401920Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(['store_nbr','item_nbr'], axis=1, inplace=True)\n",
    "test.drop(['store_nbr','item_nbr'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:14:57.123296Z",
     "start_time": "2018-03-22T21:14:57.075920Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:14:58.169606Z",
     "start_time": "2018-03-22T21:14:58.122200Z"
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Separate validation set before filling in missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Problem:**  \n",
    "missing ~25% of the ['item_nbr', 'store_nbr'] combinations of training set  \n",
    "Need to create a validation set with similar circumstances..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:20:54.838041Z",
     "start_time": "2018-03-21T21:20:54.602035Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# last 2 weeks\n",
    "valid = train[train.date>='2017-07-16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:20:57.885871Z",
     "start_time": "2018-03-21T21:20:57.840547Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# drop valid from train\n",
    "train = train[:-(len(valid))]; train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:21:03.210456Z",
     "start_time": "2018-03-21T21:21:02.744933Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "valid = valid.reset_index(drop=True)\n",
    "\n",
    "valid['dow'] = valid['date'].dt.dayofweek\n",
    "valid['dom'] = valid['date'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create missing rows (items,stores,dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T23:09:48.329831Z",
     "start_time": "2018-03-20T23:09:38.710228Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating records for all items, in all markets on all dates\n",
    "# for correct calculation of daily unit sales averages.\n",
    "u_dates = train.date.unique()\n",
    "u_stores = train.store_nbr.unique()\n",
    "u_items = train.item_nbr.unique()\n",
    "train.set_index(['date', 'store_nbr', 'item_nbr'], inplace=True)\n",
    "train = train.reindex(\n",
    "    pd.MultiIndex.from_product(\n",
    "        (u_dates, u_stores, u_items),\n",
    "        names=['date','store_nbr','item_nbr']\n",
    "    )\n",
    ").reset_index()\n",
    "\n",
    "del u_dates, u_stores, u_items\n",
    "\n",
    "train.loc[:, 'unit_sales'].fillna(0, inplace=True) # fill NaNs\n",
    "train.loc[:, 'onpromotion'].fillna(False, inplace=True) # fill NaNs\n",
    "lastdate = train.iloc[train.shape[0]-1].date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:21:09.330451Z",
     "start_time": "2018-03-21T21:21:08.272115Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['dow'] = train['date'].dt.dayofweek\n",
    "train['dom'] = train['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T23:09:59.131427Z",
     "start_time": "2018-03-20T23:09:57.766306Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(f'{PATH}rf_rnn', exist_ok=True)\n",
    "train.to_feather(f'{PATH}rf_rnn/train_3_mo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:21:11.109462Z",
     "start_time": "2018-03-21T21:21:11.072109Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train = pd.read_feather(f'{PATH}rf_rnn/train_full_year_incomplete')\n",
    "# dtypes = {'id':'uint32', 'item_nbr':'uint32', 'store_nbr':'uint8', 'onpromotion': 'bool'}\n",
    "lastdate = train.iloc[train.shape[0]-1].date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:21:17.097932Z",
     "start_time": "2018-03-21T21:21:15.086778Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Days of Week Means\n",
    "#By tarobxl: https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/42948\n",
    "ma_dw = train[['item_nbr','store_nbr','dow','unit_sales']].groupby(\n",
    "        ['item_nbr','store_nbr','dow'])['unit_sales'].mean().to_frame('madw').reset_index()\n",
    "ma_wk = ma_dw[['item_nbr','store_nbr','madw']].groupby(\n",
    "        ['store_nbr', 'item_nbr'])['madw'].mean().to_frame('mawk').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:21:21.004213Z",
     "start_time": "2018-03-21T21:21:17.413936Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Days of Month Means\n",
    "ma_dm = train[['item_nbr','store_nbr','dom','unit_sales']].groupby(\n",
    "    ['item_nbr','store_nbr','dom'])['unit_sales'].mean().to_frame('madm').reset_index()\n",
    "ma_mo = ma_dm[['item_nbr','store_nbr','madm']].groupby(\n",
    "    ['item_nbr','store_nbr'])['madm'].mean().to_frame('mamo').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:21:27.728395Z",
     "start_time": "2018-03-21T21:21:22.260665Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "#Moving Averages\n",
    "ma_is = train[['item_nbr','store_nbr','unit_sales']].groupby(\n",
    "        ['item_nbr','store_nbr'])['unit_sales'].mean().to_frame('mais')\n",
    "\n",
    "for i in [55,34,21,13,8,5,3,2,1]:\n",
    "    tmp = train[train.date>lastdate-timedelta(int(i))]\n",
    "    tmpg = tmp.groupby(['item_nbr','store_nbr'])['unit_sales'].mean().to_frame('mais'+str(i))\n",
    "    ma_is = ma_is.join(tmpg, how='left')\n",
    "\n",
    "del tmp,tmpg\n",
    "\n",
    "ma_is['mais']=ma_is.median(axis=1)\n",
    "ma_is.reset_index(inplace=True)\n",
    "ma_is.drop(list(ma_is.columns.values)[3:],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:30:57.933665Z",
     "start_time": "2018-03-21T21:30:54.516482Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load test\n",
    "test = pd.read_csv(f'{PATH}test.csv', dtype=dtypes, parse_dates=['date'])\n",
    "# test['dow'] = test['date'].dt.dayofweek\n",
    "# test['dom'] = test['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:21:58.550312Z",
     "start_time": "2018-03-21T21:21:35.987708Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge moving averages onto test df\n",
    "test = pd.merge(test, ma_is, how='left', on=['item_nbr','store_nbr'])\n",
    "test = pd.merge(test, ma_wk, how='left', on=['item_nbr','store_nbr'])\n",
    "test = pd.merge(test, ma_mo, how='left', on=['item_nbr','store_nbr'])\n",
    "test = pd.merge(test, ma_dw, how='left', on=['item_nbr','store_nbr','dow'])\n",
    "test = pd.merge(test, ma_dm, how='left', on=['item_nbr','store_nbr','dom'])\n",
    "\n",
    "# merge moving averages onto valid df\n",
    "valid = pd.merge(valid, ma_is, how='left', on=['item_nbr','store_nbr'])\n",
    "valid = pd.merge(valid, ma_wk, how='left', on=['item_nbr','store_nbr'])\n",
    "valid = pd.merge(valid, ma_mo, how='left', on=['item_nbr','store_nbr'])\n",
    "valid = pd.merge(valid, ma_dw, how='left', on=['item_nbr','store_nbr','dow'])\n",
    "valid = pd.merge(valid, ma_dm, how='left', on=['item_nbr','store_nbr','dom'])\n",
    "\n",
    "# merge moving averages onto train df\n",
    "train = pd.merge(train, ma_is, how='left', on=['item_nbr','store_nbr'])\n",
    "train = pd.merge(train, ma_wk, how='left', on=['item_nbr','store_nbr'])\n",
    "train = pd.merge(train, ma_mo, how='left', on=['item_nbr','store_nbr'])\n",
    "train = pd.merge(train, ma_dw, how='left', on=['item_nbr','store_nbr','dow'])\n",
    "train = pd.merge(train, ma_dm, how='left', on=['item_nbr','store_nbr','dom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:22:06.126190Z",
     "start_time": "2018-03-21T21:21:58.911740Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataFrameSummary(test).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:25:34.503707Z",
     "start_time": "2018-03-21T21:25:34.326360Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val = valid[(valid['date']>='2017-7-26') & (valid['date']<='2017-8-9')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:26:08.553153Z",
     "start_time": "2018-03-21T21:26:05.504023Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataFrameSummary(val).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T23:58:12.424595Z",
     "start_time": "2018-03-20T23:58:10.191744Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_feather(f'{PATH}rf_rnn/train_dom_dow_w_avgs')\n",
    "valid.to_feather(f'{PATH}rf_rnn/valid_dom_dow_w_avgs')\n",
    "test.to_feather(f'{PATH}rf_rnn/test_dom_dow_w_avgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Calculate averages for train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T23:16:34.065703Z",
     "start_time": "2018-03-20T23:16:27.989846Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# avg price * dow multiplier\n",
    "train['avg_dow'] = train.mais\n",
    "pos_idx = train['mawk'] > 0  # avoid division by zero error\n",
    "train_pos = train.loc[pos_idx]\n",
    "train.loc[pos_idx, 'avg_dow'] = train_pos['mais'] * train_pos['madw'] / train_pos['mawk']\n",
    "# train.loc[:, 'avg_dow'].fillna(train['avg_dow'].median(), inplace=True)  # fill w/ median instead of 0\n",
    "train.drop(['mawk', 'madw'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T23:16:39.914397Z",
     "start_time": "2018-03-20T23:16:34.461417Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# avg price * dom multiplier\n",
    "train['avg_dom'] = train.mais\n",
    "pos_idx = train['mamo'] > 0  # avoid division by zero error\n",
    "train_pos = train.loc[pos_idx]\n",
    "train.loc[pos_idx, 'avg_dom'] = train_pos['mais'] * train_pos['madm'] / train_pos['mamo']\n",
    "# train.loc[:, 'avg_dom'].fillna(train['avg_dom'].median(), inplace=True)\n",
    "train.drop(['mais', 'mamo', 'madm'], axis=1, inplace=True); train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T23:16:41.294476Z",
     "start_time": "2018-03-20T23:16:40.430293Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test['avg_dow'] = test.mais\n",
    "pos_idx = test['mawk'] > 0\n",
    "test_pos = test.loc[pos_idx]\n",
    "test.loc[pos_idx, 'avg_dow'] = test_pos['mais'] * test_pos['madw'] / test_pos['mawk']\n",
    "# test.loc[:, 'avg_dow'].fillna(test['avg_dow'].median(), inplace=True)\n",
    "test.drop(['mawk', 'madw'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T23:16:42.342370Z",
     "start_time": "2018-03-20T23:16:41.731908Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test['avg_dom'] = test.mais\n",
    "pos_idx = test['mamo'] > 0\n",
    "test_pos = test.loc[pos_idx]\n",
    "test.loc[pos_idx, 'avg_dom'] = test_pos['mais'] * test_pos['madm'] / test_pos['mamo']\n",
    "# test.loc[:, \"avg_dom\"].fillna(test['avg_dom'].median(), inplace=True)\n",
    "test.drop(['mais', 'mamo', 'madm'], axis=1, inplace=True); test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T23:19:13.043670Z",
     "start_time": "2018-03-20T23:19:12.649851Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "valid['avg_dow'] = valid.mais\n",
    "pos_idx = valid['mawk'] > 0\n",
    "valid_pos = valid.loc[pos_idx]\n",
    "valid.loc[pos_idx, 'avg_dow'] = valid_pos['mais'] * valid_pos['madw'] / valid_pos['mawk']\n",
    "# valid.loc[:, 'avg_dow'].fillna(valid['avg_dow'].median(), inplace=True)\n",
    "valid.drop(['mawk', 'madw'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T23:19:13.842786Z",
     "start_time": "2018-03-20T23:19:13.514940Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "valid['avg_dom'] = valid.mais\n",
    "pos_idx = valid['mamo'] > 0\n",
    "valid_pos = valid.loc[pos_idx]\n",
    "valid.loc[pos_idx, 'avg_dom'] = valid_pos['mais'] * valid_pos['madm'] / valid_pos['mamo']\n",
    "# valid.loc[:, \"avg_dom\"].fillna(valid['avg_dom'].median(), inplace=True)\n",
    "valid.drop(['mais', 'mamo', 'madm'], axis=1, inplace=True); valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T23:58:45.906983Z",
     "start_time": "2018-03-20T23:58:45.868895Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del pos_idx, train_pos, test_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T16:42:46.434801Z",
     "start_time": "2018-03-20T16:42:44.365596Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.to_feather(f'{PATH}rf_rnn/train_w_averages_incomplete')\n",
    "test.to_feather(f'{PATH}rf_rnn/test_w_averages_incomplete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Establish baseline (moving averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T00:01:02.290752Z",
     "start_time": "2018-03-21T00:01:02.252646Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Root Mean Squared Logarathimic Error\n",
    "# kaggle definition\n",
    "# np.square(np.log(y_pred + 1) - np.log(y_true + 1)).mean() ** 0.5\n",
    "\n",
    "def rmsle(pred, targ):\n",
    "    # pred and targs are both log1p values already\n",
    "    mean_diff = np.square(pred - targ).mean()\n",
    "    return round(math.sqrt(mean_diff), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T00:03:56.658299Z",
     "start_time": "2018-03-21T00:03:52.248045Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# testing 25% more for promotion items\n",
    "#dow\n",
    "train['avg_dow_promo'] = train['avg_dow']\n",
    "train.loc[train['onpromotion'] == True, 'avg_dow_promo'] *= 1.25\n",
    "\n",
    "valid['avg_dow_promo'] = valid['avg_dow']\n",
    "valid.loc[valid['onpromotion'] == True, 'avg_dow_promo'] *= 1.25\n",
    "# dom\n",
    "train['avg_dom_promo'] = train['avg_dom']\n",
    "train.loc[train['onpromotion'] == True, 'avg_dom_promo'] *= 1.25\n",
    "\n",
    "valid['avg_dom_promo'] = valid['avg_dom']\n",
    "valid.loc[valid['onpromotion'] == True, 'avg_dom_promo'] *= 1.25\n",
    "\n",
    "# drop avg_dow_promo columns from train/valid\n",
    "train.drop('avg_dow_promo', axis=1, inplace=True)\n",
    "valid.drop('avg_dow_promo', axis=1, inplace=True)\n",
    "train.drop('avg_dom_promo', axis=1, inplace=True)\n",
    "valid.drop('avg_dom_promo', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T00:02:47.433727Z",
     "start_time": "2018-03-21T00:02:46.588870Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The baseline predictions on full training set\n",
    "print(rmsle(train.avg_dow, train.unit_sales))  #=> 0.7158\n",
    "print(rmsle(train.avg_dom, train.unit_sales))  #=> 0.337\n",
    "# 0.5269\n",
    "# 0.5264\n",
    "\n",
    "# baseline w/ promo multiplier\n",
    "print(rmsle(train.avg_dow_promo, train.unit_sales))  #=> 0.7133\n",
    "print(rmsle(train.avg_dom_promo, train.unit_sales))\n",
    "# 0.5292\n",
    "# 0.5238\n",
    "\n",
    "# 0.5985\n",
    "# 0.5699\n",
    "# 0.5993\n",
    "# 0.5741"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T00:03:11.593100Z",
     "start_time": "2018-03-21T00:03:11.514257Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# baseline predictions on validation set\n",
    "print(rmsle(valid.avg_dow, valid.unit_sales))  #=> 0.5138\n",
    "print(rmsle(valid.avg_dom, valid.unit_sales))  #=> 0.2611\n",
    "# 0.4915\n",
    "# 0.483\n",
    "\n",
    "# baseline w/ promo multiplier\n",
    "print(rmsle(valid.avg_dow_promo, valid.unit_sales))  #=> 0.5116\n",
    "print(rmsle(valid.avg_dom_promo, valid.unit_sales))\n",
    "# 0.5013\n",
    "# 0.4891\n",
    "\n",
    "# 0.663\n",
    "# 0.7611\n",
    "# 0.6654\n",
    "# 0.762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T00:04:05.245211Z",
     "start_time": "2018-03-21T00:04:04.511049Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# average dom/dow for full and valid sets\n",
    "print(rmsle(train[['avg_dow', 'avg_dom']].mean(axis=1), train.unit_sales))\n",
    "print(rmsle(valid[['avg_dow', 'avg_dom']].mean(axis=1), valid.unit_sales))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It appears that avg dow/dom is the best baseline predictor..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T17:23:07.614917Z",
     "start_time": "2018-03-20T17:23:03.277036Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DataFrameSummary(valid).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T17:23:22.647880Z",
     "start_time": "2018-03-20T17:23:17.804322Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DataFrameSummary(test).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Submit test on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T00:07:19.147707Z",
     "start_time": "2018-03-21T00:07:18.938370Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set unit_sales\n",
    "test['unit_sales'] = test[['avg_dom','avg_dow']].mean(axis=1)\n",
    "# test.loc[test['onpromotion'] == True, 'unit_sales'] *= 1.25\n",
    "\n",
    "# need to convert unit_sales back from log1p\n",
    "test['unit_sales'] = test['unit_sales'].apply(pd.np.expm1) # restoring unit values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T00:07:43.914833Z",
     "start_time": "2018-03-21T00:07:20.177647Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SUBM = f'{PATH}rf_rnn/subm/'\n",
    "os.makedirs(SUBM, exist_ok=True)\n",
    "\n",
    "test.to_csv(f'{SUBM}avg_dow_dom_v2.csv.gz', columns=['id','unit_sales'], index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T00:11:58.268044Z",
     "start_time": "2018-03-21T00:10:05.977140Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c favorita-grocery-sales-forecasting -f {SUBM}avg_dow_dom_v2.csv.gz -m \"dow and dom averages v2\"\n",
    "#=> 0.537  avg_dow w/ promo multiplier\n",
    "#=> 0.718  dow/dom averages -- why you so bad!?\n",
    "#=> 0.718  dow/dom_v2 averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:40:25.013804Z",
     "start_time": "2018-03-22T22:40:20.837453Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_feather(f'{PATH}rf_rnn/train_w_averages')\n",
    "test = pd.read_feather(f'{PATH}rf_rnn/test_w_averages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: need to convert dates back to datetime?!\n",
    "train['date'] = train['date'].astype('datetime64[ns]')\n",
    "test['date'] = test['date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:31:12.089042Z",
     "start_time": "2018-03-21T21:31:12.043857Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items = pd.read_csv(f'{PATH}items.csv', low_memory=False)\n",
    "stores = pd.read_csv(f'{PATH}stores.csv', low_memory=False)\n",
    "# holidays = pd.read_csv(f'{PATH}holidays_events.csv', parse_dates=['date'], low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:31:15.906309Z",
     "start_time": "2018-03-21T21:31:15.859512Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:31:32.747750Z",
     "start_time": "2018-03-21T21:31:30.451956Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, stores, how='left', on=['store_nbr'])\n",
    "test = pd.merge(test, stores, how='left', on=['store_nbr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:31:33.802170Z",
     "start_time": "2018-03-21T21:31:33.763279Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T00:00:03.202112Z",
     "start_time": "2018-03-16T00:00:03.153921Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# looks like we only need to worry about local holidays...\n",
    "holidays[(holidays['date'] >= '2017-08-16') & (holidays['date'] <= '2017-08-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T15:23:10.465069Z",
     "start_time": "2018-03-16T15:23:10.416063Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "local_holidays = holidays.loc[(holidays['locale'] == 'Local') & (holidays['transferred'] == False)].copy()\n",
    "local_holidays['holiday'] = True\n",
    "local_holidays = local_holidays.rename(index=str, columns={\"locale_name\": \"city\"}).drop(\n",
    "    ['type','locale','description','transferred'], axis=1)\n",
    "local_holidays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T15:33:13.417042Z",
     "start_time": "2018-03-16T15:32:41.734527Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, local_holidays, how='left', on=['date','city'])\n",
    "test = pd.merge(test, local_holidays, how='left', on=['date','city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T15:33:25.357000Z",
     "start_time": "2018-03-16T15:33:20.615639Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.loc[:, 'holiday'].fillna(False, inplace=True) # fill NaNs\n",
    "test.loc[:, 'holiday'].fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T15:33:34.702882Z",
     "start_time": "2018-03-16T15:33:34.666488Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del holidays, local_holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:31:38.901116Z",
     "start_time": "2018-03-21T21:31:38.858824Z"
    }
   },
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:32:01.792757Z",
     "start_time": "2018-03-21T21:31:57.801980Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, items, how='left', on=['item_nbr'])\n",
    "test = pd.merge(test, items, how='left', on=['item_nbr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T15:35:46.962931Z",
     "start_time": "2018-03-16T15:34:43.825992Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.isnull(train).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T21:32:10.602776Z",
     "start_time": "2018-03-21T21:32:10.565855Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T15:36:41.339771Z",
     "start_time": "2018-03-16T15:35:55.824508Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_feather(f'{PATH}rf_rnn/train_w_features')\n",
    "test.to_feather(f'{PATH}rf_rnn/test_w_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep - handle categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T15:46:02.924283Z",
     "start_time": "2018-03-16T15:45:59.522093Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train = pd.read_feather(f'{PATH}rf_rnn/train_w_features')\n",
    "test = pd.read_feather(f'{PATH}rf_rnn/test_w_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:21:37.196282Z",
     "start_time": "2018-03-22T21:21:20.610209Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add date info\n",
    "add_datepart(train, 'date')\n",
    "add_datepart(test, 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:21:42.725198Z",
     "start_time": "2018-03-22T21:21:42.686194Z"
    }
   },
   "outputs": [],
   "source": [
    "test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:26:42.811135Z",
     "start_time": "2018-03-22T21:26:41.586683Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.drop(np.append(test.columns.values[15:], ['Year', 'Month', 'Week']), axis=1, inplace=True)\n",
    "train.drop(np.append(test.columns.values[15:], ['Year', 'Month', 'Week']), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:27:14.326127Z",
     "start_time": "2018-03-22T21:27:14.290289Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_vars = ['onpromotion', 'city', 'state', 'type', 'cluster','family', 'class', 'perishable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:27:21.293869Z",
     "start_time": "2018-03-22T21:27:17.544995Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for v in cat_vars:\n",
    "    train[v] = train[v].astype('category').cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:27:35.003525Z",
     "start_time": "2018-03-22T21:27:34.065075Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apply_cats(test, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:16:28.572531Z",
     "start_time": "2018-03-22T22:16:27.254085Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_feather(f'{PATH}rf_rnn/train_cats')\n",
    "test.to_feather(f'{PATH}rf_rnn/test_cats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:12:41.689473Z",
     "start_time": "2018-03-22T22:12:38.109125Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_feather(f'{PATH}rf_rnn/train_cats')\n",
    "test = pd.read_feather(f'{PATH}rf_rnn/test_cats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:14:52.652041Z",
     "start_time": "2018-03-22T22:14:52.600660Z"
    }
   },
   "outputs": [],
   "source": [
    "train.drop(train.columns.values[11:],1,inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:15:57.849930Z",
     "start_time": "2018-03-22T22:15:57.799199Z"
    }
   },
   "outputs": [],
   "source": [
    "# test.drop('Dayofyear',1,inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate target from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T15:17:46.467361Z",
     "start_time": "2018-03-19T15:17:38.996745Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# last 3.5 months\n",
    "train = pd.read_feather(f'{PATH}rf_rnn/train_w_categories')\n",
    "# test = pd.read_feather(f'{PATH}rf_rnn/test_w_categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:16:58.050470Z",
     "start_time": "2018-03-22T22:16:51.837124Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df, y, nas, mapper = proc_df(train, 'unit_sales', do_scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:16:59.714784Z",
     "start_time": "2018-03-22T22:16:59.669673Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# x_trn, x_val, y_trn, y_val = train_test_split(df, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "# good validation set => 2017-7-26 -> 2017-8-9\n",
    "# IDs => [9119925:10700781] (3.5 month dataset)\n",
    "# IDs => [18743184:22012344] (18743184 - 22012343)\n",
    "# len(test) => 3370464\n",
    "\n",
    "def split_val(df,a,b):\n",
    "    val = df[a:b].copy()\n",
    "    trn = df.drop(df.index[a:b]).copy()\n",
    "    return trn, val\n",
    "\n",
    "# x_trn,x_val = split_val(df,18743184,22012344)\n",
    "\n",
    "def split_val_arr(arr,a,b):\n",
    "    val = arr[a:b].copy()\n",
    "    trn = np.delete(arr, slice(a,b))\n",
    "    return trn, val\n",
    "\n",
    "# y_trn,y_val = split_val_arr(y,18743184,22012344)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:17:05.830659Z",
     "start_time": "2018-03-22T22:17:03.867831Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_trn,x_val = split_val(df,9119925,10700781)\n",
    "y_trn,y_val = split_val_arr(y,9119925,10700781)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:17:06.835145Z",
     "start_time": "2018-03-22T22:17:06.795901Z"
    }
   },
   "outputs": [],
   "source": [
    "x_trn.shape, x_val.shape, y_trn.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:17:11.760780Z",
     "start_time": "2018-03-22T22:17:11.715897Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train, df, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:17:16.641901Z",
     "start_time": "2018-03-22T22:17:16.595163Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle(pred, targ):\n",
    "    # pred and targs are both log1p values already\n",
    "    mean_diff = np.square(pred - targ).mean()\n",
    "    return round(math.sqrt(mean_diff), 4)\n",
    "\n",
    "def print_score(m):\n",
    "    res = [rmsle(m.predict(x_trn), y_trn), rmsle(m.predict(x_val), y_val),\n",
    "                round(m.score(x_trn, y_trn),4), round(m.score(x_val, y_val),4)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)\n",
    "    \n",
    "# m.score => coefficient of determination (R^2)\n",
    "#   proportion of the variance in the dependent variable that is predictable from the independent variable(s)\n",
    "#   ratio of how much better the model is than the mean prediction (0);  1: perfect;  -*: worse than the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:28:52.573083Z",
     "start_time": "2018-03-22T21:28:52.536750Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:28:59.901406Z",
     "start_time": "2018-03-22T21:28:59.865053Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_rf_samples(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:29:42.510939Z",
     "start_time": "2018-03-22T21:29:05.473512Z"
    }
   },
   "outputs": [],
   "source": [
    "m = RandomForestRegressor()\n",
    "%time m.fit(x_trn, y_trn)\n",
    "print_score(m)    #=> [0.2952, 0.2656, 0.67486495050828088, 0.73733977357618774]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T17:21:46.729955Z",
     "start_time": "2018-03-16T17:20:57.065368Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=20, min_samples_leaf=3, n_jobs=-1)\n",
    "%time m.fit(x_trn, y_trn)\n",
    "print_score(m)    #=> [0.2857, 0.2547, 0.6956, 0.75860000000000005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T17:27:16.218361Z",
     "start_time": "2018-03-16T17:25:44.097129Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=20, min_samples_leaf=3, max_features=0.5, n_jobs=-1)\n",
    "%time m.fit(x_trn, y_trn)\n",
    "print_score(m)    #=> [0.2856, 0.2536, 0.69569999999999999, 0.76060000000000005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:30:43.729266Z",
     "start_time": "2018-03-22T21:30:13.026884Z"
    }
   },
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=50, min_samples_leaf=5, max_features=0.5, n_jobs=-1)\n",
    "%time m.fit(x_trn, y_trn)\n",
    "print_score(m)    #=> [0.2825, 0.2498, 0.70220000000000005, 0.76770000000000005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:22:05.344421Z",
     "start_time": "2018-03-22T22:17:35.750759Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_rf_samples()\n",
    "# set_rf_samples(250000)\n",
    "\n",
    "m = RandomForestRegressor(n_estimators=50, min_samples_leaf=5, max_features=0.5, n_jobs=-1)\n",
    "%time m.fit(x_trn, y_trn)\n",
    "print_score(m)    #=> [0.2769, 0.2488, 0.71409999999999996, 0.76949999999999996]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Variable importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:34:49.546721Z",
     "start_time": "2018-03-22T21:34:49.390134Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "features = list(x_trn.columns)\n",
    "\n",
    "# Get numerical feature importances\n",
    "importances = list(m.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(features, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:37:36.379404Z",
     "start_time": "2018-03-22T21:37:36.037415Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "least_important_features = [feature[0] for feature in feature_importances[12:]]\n",
    "\n",
    "x_trn.drop(least_important_features, axis=1, inplace=True)\n",
    "x_val.drop(least_important_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T21:39:46.410384Z",
     "start_time": "2018-03-22T21:38:43.347380Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_rf_samples()\n",
    "set_rf_samples(500000)\n",
    "\n",
    "m = RandomForestRegressor(n_estimators=50, min_samples_leaf=5, max_features=0.5, n_jobs=-1)\n",
    "%time m.fit(x_trn, y_trn)\n",
    "print_score(m)\n",
    "#=> [0.2769, 0.2488, 0.71409999999999996, 0.76949999999999996]\n",
    "#=> [0.2732, 0.2487, 0.72150000000000003, 0.76970000000000005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:22:05.847319Z",
     "start_time": "2018-03-22T22:22:05.592250Z"
    }
   },
   "outputs": [],
   "source": [
    "features = list(x_trn.columns)\n",
    "\n",
    "# Get numerical feature importances\n",
    "importances = list(m.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(features, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:30:04.074150Z",
     "start_time": "2018-03-22T22:22:06.020895Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_rf_samples()\n",
    "# full dataset - need to run on GPU\n",
    "\n",
    "m = RandomForestRegressor(n_estimators=100, min_samples_leaf=25, max_features=0.5, n_jobs=8)\n",
    "%time m.fit(x_trn, y_trn)\n",
    "print_score(m)\n",
    "#=> [0.2769, 0.2488, 0.71409999999999996, 0.76949999999999996]\n",
    "#=> [0.1931, 0.248, 0.8609, 0.7711]  -- overfit?!   (n_est=50, min_leaf=5, 23min)\n",
    "#=> [0.2484, 0.2466, 0.7699, 0.7737]  (37min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Feature Reduction / Data Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T22:05:17.601565Z",
     "start_time": "2018-03-13T22:04:57.387733Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_feather(f'{PATH}rf_rnn/train_w_categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T17:41:40.681046Z",
     "start_time": "2018-03-16T17:41:40.642796Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Extract the names of the least important features\n",
    "# least_important_features = [feature[0] for feature in feature_importances[15:]]\n",
    "\n",
    "least_important_features = list(train.columns)[11:-1]\n",
    "least_important_features.extend(list(['Year', 'Month']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T17:45:29.166454Z",
     "start_time": "2018-03-16T17:45:28.245913Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.drop(columns=least_important_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T22:12:35.814558Z",
     "start_time": "2018-03-13T22:11:27.126762Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df, y, nas = proc_df(train, 'unit_sales', subset=30000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T22:13:32.161589Z",
     "start_time": "2018-03-13T22:13:32.145956Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del train  # need to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T22:14:54.740518Z",
     "start_time": "2018-03-13T22:14:47.297747Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Using Scikit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_trn, x_val, y_trn, y_val = train_test_split(df, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T22:15:55.911754Z",
     "start_time": "2018-03-13T22:15:55.897022Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del df,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T22:24:45.132415Z",
     "start_time": "2018-03-13T22:16:24.506566Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_jobs=-1)\n",
    "%time m.fit(x_trn, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T22:27:59.356731Z",
     "start_time": "2018-03-13T22:24:45.228610Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print_score(m)   #=> [0.24, 0.5684, 0.946675430780943, 0.7008898192311388]\n",
    "\n",
    "# slight increase in accuracy (increased data)\n",
    "# large decrease in duration (feature reduction & split over multiple cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Apply to Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T23:51:25.429449Z",
     "start_time": "2018-03-13T23:51:25.205074Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_feather(f'{PATH}rf_rnn/test_w_categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T23:51:26.291320Z",
     "start_time": "2018-03-13T23:51:26.182376Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test.drop(columns=least_important_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T23:51:27.736286Z",
     "start_time": "2018-03-13T23:51:27.026198Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add in y value to test: 'unit sales'\n",
    "test['unit_sales'] = 0.0\n",
    "\n",
    "df_test, _, nas = proc_df(test, 'unit_sales', skip_flds=['id'], na_dict=nas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T23:51:41.505547Z",
     "start_time": "2018-03-13T23:51:33.025144Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# use rf to predict on test df\n",
    "log_preds = m.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T23:51:47.334450Z",
     "start_time": "2018-03-13T23:51:47.235520Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test['unit_sales'] = np.expm1(log_preds) # re-scale predictions and add to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T23:52:30.951342Z",
     "start_time": "2018-03-13T23:52:04.656918Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SUBM = f'{PATH}rf_rnn/subm/'\n",
    "os.makedirs(SUBM, exist_ok=True)\n",
    "\n",
    "test.to_csv(f'{SUBM}rf_v3.csv.gz', columns=['id','unit_sales'], index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T23:52:55.942289Z",
     "start_time": "2018-03-13T23:52:40.785457Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c favorita-grocery-sales-forecasting -f {SUBM}rf_v3.csv.gz -m \"random forest version 3\"\n",
    "# v1 => 1.223 -- throwaway\n",
    "# v2 => 0.581\n",
    "# v3 => 0.865 (last 3 months) -- throwaway\n",
    "# v4 => 0.544 (last 3 months)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Train only on last ~3 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T17:40:06.327496Z",
     "start_time": "2018-03-19T17:40:03.967387Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_feather(f'{PATH}rf_rnn/train_w_categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T23:01:43.065562Z",
     "start_time": "2018-03-13T23:01:43.040053Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Extract the names of the least important features\n",
    "# least_important_features = [feature[0] for feature in feature_importances[9:]]\n",
    "\n",
    "least_important_features = list(train.columns)[11:-1]\n",
    "least_important_features.extend(list(['Year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T17:40:09.266288Z",
     "start_time": "2018-03-19T17:40:08.780376Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.drop(columns=least_important_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T17:40:31.339919Z",
     "start_time": "2018-03-19T17:40:27.511730Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df, y, nas = proc_df(train, 'unit_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T17:40:32.696335Z",
     "start_time": "2018-03-19T17:40:32.680335Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del train  # need to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T18:30:56.871321Z",
     "start_time": "2018-03-19T17:40:43.730797Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=100, min_samples_leaf=25, max_features=0.5, n_jobs=8, oob_score=True)\n",
    "%time m.fit(df, y);\n",
    "\n",
    "res = [rmsle(m.predict(df), y), round(m.score(df, y),4), m.oob_score_]\n",
    "print(res)\n",
    "#=> [0.2453, 0.7755]  do_scale=True\n",
    "#=> [0.2453, 0.7756, 0.7388747115547389] do_scale=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:31:03.647139Z",
     "start_time": "2018-03-22T22:31:03.603137Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del x_trn, x_val, y_trn, y_val\n",
    "# del df, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T18:38:43.647335Z",
     "start_time": "2018-03-19T18:38:43.309109Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_feather(f'{PATH}rf_rnn/test_w_categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T18:38:44.591804Z",
     "start_time": "2018-03-19T18:38:44.502851Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.drop(columns=least_important_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:31:16.523937Z",
     "start_time": "2018-03-22T22:31:16.443854Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add in y value to test: 'unit sales'\n",
    "test['unit_sales'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:31:23.446810Z",
     "start_time": "2018-03-22T22:31:22.085358Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test, _, nas, mapper = proc_df(test, 'unit_sales', do_scale=True, skip_flds=['id'], na_dict=nas, mapper=mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T19:39:07.187540Z",
     "start_time": "2018-03-16T19:39:06.767619Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to drop columns after scaling because mapper includes all columns\n",
    "# df_test.drop(columns=least_important_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:32:53.160801Z",
     "start_time": "2018-03-22T22:32:44.484334Z"
    }
   },
   "outputs": [],
   "source": [
    "test['unit_sales'] = m.predict(df_test)  # log1p values\n",
    "test['unit_sales'] = test['unit_sales'].apply(pd.np.expm1) # restoring unit values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:33:17.154377Z",
     "start_time": "2018-03-22T22:33:17.116897Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SUBM = f'{PATH}rf_rnn/subm/'\n",
    "csv = f'{SUBM}rf_v8.csv.gz'\n",
    "os.makedirs(SUBM, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:33:34.658723Z",
     "start_time": "2018-03-22T22:33:17.765489Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv(csv, columns=['id','unit_sales'], index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:34:08.836612Z",
     "start_time": "2018-03-22T22:33:52.524320Z"
    }
   },
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c favorita-grocery-sales-forecasting -f {csv} -m \"RF version 8 - no store_nbr or item_nbr\"\n",
    "# v4 => 0.544 (last 3 months)\n",
    "# v5 => 0.803\n",
    "# v6 => 0.801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T22:37:32.280539Z",
     "start_time": "2018-03-22T22:37:32.061475Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_feather(f'{PATH}rf_rnn/test_final_no_items_stores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1048px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
