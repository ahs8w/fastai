{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:11:24.622670Z",
     "start_time": "2018-06-22T21:11:24.289765Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:11:27.090437Z",
     "start_time": "2018-06-22T21:11:24.642843Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "French/English parallel texts from http://www.statmt.org/wmt15/translation-task.html .  It was created by Chris Callison-Burch, who crawled millions of web pages and then used *a set of simple heuristics to transform French URLs onto English URLs (i.e. replacing \"fr\" with \"en\" and about 40 other hand-written rules), and assume that these documents are translations of each other*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:11:29.935241Z",
     "start_time": "2018-06-22T21:11:29.898162Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH = Path('data/translate')\n",
    "TMP_PATH = PATH/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)\n",
    "fname='giga-fren.release2.fixed'\n",
    "en_fname = PATH/f'{fname}.en'\n",
    "fr_fname = PATH/f'{fname}.fr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only using question texts to limit how long training takes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:08:30.695974Z",
     "start_time": "2018-06-19T18:05:59.076361Z"
    }
   },
   "outputs": [],
   "source": [
    "re_eq = re.compile('^(Wh[^?.!]+\\?)')\n",
    "re_fq = re.compile('^([^?.!]+\\?)')\n",
    "\n",
    "# lines -> generator object\n",
    "lines = ((re_eq.search(eq), re_fq.search(fq)) \n",
    "         for eq, fq in zip(open(en_fname, encoding='utf-8'), open(fr_fname, encoding='utf-8')))\n",
    "\n",
    "qs = [(e.group(), f.group()) for e,f in lines if e and f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:10:44.900842Z",
     "start_time": "2018-06-19T18:10:44.851977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('What is light ?', 'Qu’est-ce que la lumière?'),\n",
       "  ('Who are we?', 'Où sommes-nous?'),\n",
       "  ('Where did we come from?', \"D'où venons-nous?\"),\n",
       "  ('What would we do without it?', 'Que ferions-nous sans elle ?'),\n",
       "  ('What is the absolute location (latitude and longitude) of Badger, Newfoundland and Labrador?',\n",
       "   'Quelle sont les coordonnées (latitude et longitude) de Badger, à Terre-Neuve-etLabrador?')],\n",
       " 52331)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs[:5], len(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:11:09.970564Z",
     "start_time": "2018-06-19T18:11:09.861958Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(qs, (PATH/'fr-en-qs.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qs = pickle.load((PATH/'fr-en-qs.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:11:18.210243Z",
     "start_time": "2018-06-19T18:11:18.062406Z"
    }
   },
   "outputs": [],
   "source": [
    "en_qs,fr_qs = zip(*qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:11:27.444918Z",
     "start_time": "2018-06-19T18:11:23.628065Z"
    }
   },
   "outputs": [],
   "source": [
    "en_tok = Tokenizer.proc_all_mp(partition_by_cores(en_qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:14:46.899385Z",
     "start_time": "2018-06-19T18:14:23.598100Z"
    }
   },
   "outputs": [],
   "source": [
    "fr_tok = Tokenizer.proc_all_mp(partition_by_cores(fr_qs), 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:15:01.335178Z",
     "start_time": "2018-06-19T18:15:01.285696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['what', 'is', 'light', '?'],\n",
       " ['qu’', 'est', '-ce', 'que', 'la', 'lumière', '?'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tok[0], fr_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:16:09.686257Z",
     "start_time": "2018-06-19T18:16:09.619919Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.percentile([len(o) for o in en_tok], 96), np.percentile([len(o) for o in fr_tok], 91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:17:38.958048Z",
     "start_time": "2018-06-19T18:17:38.901815Z"
    }
   },
   "outputs": [],
   "source": [
    "keep = np.array([len(o)<30 for o in en_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:18:02.727687Z",
     "start_time": "2018-06-19T18:18:02.678558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52331, 52331)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_tok), len(fr_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:18:14.853990Z",
     "start_time": "2018-06-19T18:18:14.661479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50260, 50260)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tok = np.array(en_tok)[keep]\n",
    "fr_tok = np.array(fr_tok)[keep]\n",
    "len(en_tok), len(fr_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:18:52.962474Z",
     "start_time": "2018-06-19T18:18:52.607271Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(en_tok, (PATH/'en_tok.pkl').open('wb'))\n",
    "pickle.dump(fr_tok, (PATH/'fr_tok.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = pickle.load((PATH/'en_tok.pkl').open('rb'))\n",
    "fr_tok = pickle.load((PATH/'fr_tok.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:23:01.629009Z",
     "start_time": "2018-06-19T18:23:01.569962Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def toks2ids(tok,pre):\n",
    "    freq = Counter(p for o in tok for p in o)\n",
    "    itos = [o for o,c in freq.most_common(40000)]\n",
    "    itos.insert(0, '_bos_')\n",
    "    itos.insert(1, '_pad_')\n",
    "    itos.insert(2, '_eos_')\n",
    "    itos.insert(3, '_unk')\n",
    "    \n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    ids = np.array([[0] + ([stoi[o] for o in p] + [2]) for p in tok])\n",
    "    np.save(TMP_PATH/f'{pre}_ids.npy', ids)\n",
    "    pickle.dump(itos, open(TMP_PATH/f'{pre}_itos.pkl', 'wb'))\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:23:04.762365Z",
     "start_time": "2018-06-19T18:23:03.928651Z"
    }
   },
   "outputs": [],
   "source": [
    "en_ids,en_itos,en_stoi = toks2ids(en_tok,'en')\n",
    "fr_ids,fr_itos,fr_stoi = toks2ids(fr_tok,'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:39:01.478897Z",
     "start_time": "2018-06-22T21:39:01.454051Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_ids(pre):\n",
    "    ids = np.load(TMP_PATH/f'{pre}_ids.npy')\n",
    "    itos = pickle.load(open(TMP_PATH/f'{pre}_itos.pkl', 'rb'))\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:39:02.102916Z",
     "start_time": "2018-06-22T21:39:01.834498Z"
    }
   },
   "outputs": [],
   "source": [
    "en_ids,en_itos,en_stoi = load_ids('en')\n",
    "fr_ids,fr_itos,fr_stoi = load_ids('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:39:03.592136Z",
     "start_time": "2018-06-22T21:39:03.557394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['_bos_', 'qu’', 'est', '-ce', 'que', 'la', 'lumière', '?', '_eos_'],\n",
       " 17573,\n",
       " 24793)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fr_itos[o] for o in fr_ids[0]], len(en_itos), len(fr_itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fasttext word vectors available from https://fasttext.cc/docs/en/english-vectors.html  \n",
    "\n",
    "Why use word vectors instead of pretrained language models??  Because Jeremy hasn't tried it yet.  Should work better and something to potentially try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:24:34.174405Z",
     "start_time": "2018-06-19T18:24:00.108683Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ! pip install git+https://github.com/facebookresearch/fastText.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T20:28:34.082715Z",
     "start_time": "2018-06-22T20:28:34.050315Z"
    }
   },
   "outputs": [],
   "source": [
    "import fastText as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the fastText library, you'll need to download [fasttext word vectors](https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md) for your language (download the 'bin plus text' ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:50:53.138849Z",
     "start_time": "2018-06-19T18:33:06.487509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-06-20 13:38:57--  https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.en.zip\n",
      "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 54.231.237.33\n",
      "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|54.231.237.33|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10356881291 (9.6G) [application/zip]\n",
      "Saving to: ‘data/translate/wiki.en.zip’\n",
      "\n",
      "wiki.en.zip         100%[===================>]   9.65G  22.2MB/s    in 5m 42s  \n",
      "\n",
      "2018-06-20 13:44:40 (28.9 MB/s) - ‘data/translate/wiki.en.zip’ saved [10356881291/10356881291]\n",
      "\n",
      "Archive:  data/translate/wiki.en.zip\n",
      "  inflating: data/translate/wiki.en.vec  \n",
      "  inflating: data/translate/wiki.en.bin  \n",
      "en done\n",
      "--2018-06-20 13:47:15--  https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.fr.zip\n",
      "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.24.25\n",
      "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.24.25|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5975701653 (5.6G) [application/zip]\n",
      "Saving to: ‘data/translate/wiki.fr.zip’\n",
      "\n",
      "wiki.fr.zip         100%[===================>]   5.56G  51.0MB/s    in 2m 35s  \n",
      "\n",
      "2018-06-20 13:49:50 (36.9 MB/s) - ‘data/translate/wiki.fr.zip’ saved [5975701653/5975701653]\n",
      "\n",
      "Archive:  data/translate/wiki.fr.zip\n",
      "  inflating: data/translate/wiki.fr.vec  \n",
      "  inflating: data/translate/wiki.fr.bin  \n",
      "fr done\n"
     ]
    }
   ],
   "source": [
    "for lang in ['en', 'fr']:\n",
    "    fname = f'wiki.{lang}.zip'\n",
    "    !wget -P {PATH} https://s3-us-west-1.amazonaws.com/fasttext-vectors/{fname}\n",
    "    !unzip {PATH/fname} -d {PATH}\n",
    "    print(f'{lang} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T20:32:11.990592Z",
     "start_time": "2018-06-22T20:28:37.567Z"
    }
   },
   "outputs": [],
   "source": [
    "en_vecs = ft.load_model(str((PATH/'wiki.en.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T20:32:11.992345Z",
     "start_time": "2018-06-22T20:28:38.318Z"
    }
   },
   "outputs": [],
   "source": [
    "fr_vecs = ft.load_model(str((PATH/'wiki.fr.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T16:58:53.727719Z",
     "start_time": "2018-06-20T16:58:53.674962Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_vecs(lang, ft_vecs):\n",
    "    vecd = {w:ft_vecs.get_word_vector(w) for w in ft_vecs.get_words()}\n",
    "    pickle.dump(vecd, open(PATH/f'wiki.{lang}.pkl','wb'))\n",
    "    return vecd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-20T16:59:01.147Z"
    }
   },
   "outputs": [],
   "source": [
    "en_vecd = get_vecs('en', en_vecs)\n",
    "fr_vecd = get_vecs('fr', fr_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T20:24:31.287889Z",
     "start_time": "2018-06-22T20:24:07.255158Z"
    }
   },
   "outputs": [],
   "source": [
    "en_vecd = pickle.load(open(PATH/'wiki.en.pkl','rb'))\n",
    "fr_vecd = pickle.load(open(PATH/'wiki.fr.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T20:19:22.852183Z",
     "start_time": "2018-06-22T20:17:52.327Z"
    }
   },
   "outputs": [],
   "source": [
    "len(en_vecd), len(fr_vecd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ft_words = ft_vecs.get_words(include_freq=True)\n",
    "# ft_word_dict = {k:v for k,v in zip(*ft_words)}\n",
    "# ft_words = sorted(ft_word_dict.keys(), key=lambda x: ft_word_dict[x])\n",
    "\n",
    "# len(ft_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T20:32:16.974498Z",
     "start_time": "2018-06-22T20:32:16.953072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_en_vec = len(en_vecd[','])\n",
    "dim_fr_vec = len(fr_vecd[','])\n",
    "dim_en_vec,dim_fr_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:39:30.277216Z",
     "start_time": "2018-06-22T21:39:30.254470Z"
    }
   },
   "outputs": [],
   "source": [
    "dim_en_vec,dim_fr_vec = 300,300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T20:32:37.981850Z",
     "start_time": "2018-06-22T20:32:19.871Z"
    }
   },
   "outputs": [],
   "source": [
    "en_vecs = np.stack(list(en_vecd.values()))\n",
    "en_vecs.mean(),en_vecs.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:39:39.915374Z",
     "start_time": "2018-06-22T21:39:39.848994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 39)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enlen_90 = int(np.percentile([len(o) for o in en_ids], 99))\n",
    "frlen_90 = int(np.percentile([len(o) for o in fr_ids], 99))\n",
    "enlen_90,frlen_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:39:41.429766Z",
     "start_time": "2018-06-22T21:39:41.126515Z"
    }
   },
   "outputs": [],
   "source": [
    "en_ids_tr = np.array([o[:30] for o in en_ids])\n",
    "fr_ids_tr = np.array([o[:30] for o in fr_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:39:42.015274Z",
     "start_time": "2018-06-22T21:39:41.990915Z"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __getitem__(self, idx): return A(self.x[idx], self.y[idx])  # A() => ensures arguments are numpy arrays\n",
    "    def __len__(self): return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:39:42.297713Z",
     "start_time": "2018-06-22T21:39:42.265299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45219, 5041)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clever way to seperate out a validation set w/ random numbers\n",
    "\n",
    "np.random.seed(42)\n",
    "trn_keep = np.random.rand(len(en_ids_tr))>0.1   # check list of random numbers for greater than .1 => list of bools\n",
    "en_trn,fr_trn = en_ids_tr[trn_keep],fr_ids_tr[trn_keep]   # index into data set w/ list of bools => training\n",
    "en_val,fr_val = en_ids_tr[~trn_keep],fr_ids_tr[~trn_keep] # index into data set w/ opposite => validation\n",
    "len(en_trn),len(en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:39:42.790042Z",
     "start_time": "2018-06-22T21:39:42.758737Z"
    }
   },
   "outputs": [],
   "source": [
    "# translating french to english; reverse them to go the opposite direction\n",
    "trn_ds = Seq2SeqDataset(fr_trn,en_trn)\n",
    "val_ds = Seq2SeqDataset(fr_val,en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:39:43.553327Z",
     "start_time": "2018-06-22T21:39:43.525487Z"
    }
   },
   "outputs": [],
   "source": [
    "bs=125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:39:43.866647Z",
     "start_time": "2018-06-22T21:39:43.831197Z"
    }
   },
   "outputs": [],
   "source": [
    "trn_samp = SortishSampler(en_trn, key=lambda x: len(en_trn[x]), bs=bs)\n",
    "val_samp = SortSampler(en_val, key=lambda x: len(en_val[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:39:44.351775Z",
     "start_time": "2018-06-22T21:39:44.325273Z"
    }
   },
   "outputs": [],
   "source": [
    "# why do we need to transpose?\n",
    "# already done all of the pre-processing so limit num_workers to 1 to save time\n",
    "# pad_idx=1 - different length inputs, fastai automatically pads \n",
    "# for classifier we want the padding at the start -> final token to represent last word of review\n",
    "# for a decoder we want the padding at the end\n",
    "# sampler - sentences of different lengths need to be batched together, use a sampler to save time/memory!!\n",
    "\n",
    "trn_dl = DataLoader(trn_ds, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, int(bs*1.6), transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:39:48.589029Z",
     "start_time": "2018-06-22T21:39:45.462330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([30, 125]), torch.Size([30, 125]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(trn_dl))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24793, 300])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_embedding.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097 ['l’', \"d'\", 't_up', 'd’', \"qu'\"]\n",
      "1285 [\"'s\", '’s', \"n't\", 'n’t', ':']\n"
     ]
    }
   ],
   "source": [
    "# creating embedding early to use on osx machine because saving/loading pickle vectors doesn't work\n",
    "\n",
    "enc_embedding = create_emb(fr_vecd, fr_itos, dim_fr_vec)\n",
    "dec_embedding = create_emb(en_vecd, en_itos, dim_en_vec)\n",
    "\n",
    "# torch.save(enc_embedding.weight.data, PATH/'enc_embedding.pt')\n",
    "# torch.save(dec_embedding.weight.data, PATH/'dec_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:40:11.485773Z",
     "start_time": "2018-06-22T21:40:11.267831Z"
    }
   },
   "outputs": [],
   "source": [
    "# enc_embedding = enc_embedding.weight.data\n",
    "# dec_embedding = dec_embedding.weight.data\n",
    "\n",
    "enc_embedding = torch.load(PATH/'enc_embedding.pt')\n",
    "dec_embedding = torch.load(PATH/'dec_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T20:17:12.645745Z",
     "start_time": "2018-06-22T20:17:12.623847Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    # embedding: simple lookup table - input=index; output=word vector\n",
    "    # embeddings: rows = vocab size, columns = determined by fasttext word vectors (300)\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    # learnable pytorch module has a 'weight' attribute => Variable\n",
    "    # 'weight' attribute has a 'data' attribute => Tensor\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    # iterate through vocabulary and replace found words w/ pretrained vector weights if available\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[w]*3)  # *3 => wgts have std_dev of 1; vector has std_dev of .3\n",
    "        except: miss.append(w)\n",
    "    print(len(miss),miss[5:10])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:40:17.438292Z",
     "start_time": "2018-06-22T21:40:17.408252Z"
    }
   },
   "outputs": [],
   "source": [
    "nh,nl = 256,2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoder**  \n",
    "- Embedding                      ->  (24793, 300)\n",
    "- Dropout 0.15\n",
    "- h_t, h_n = GRU(input, h_0)     ->  ([300, 256, 2])\n",
    "- out = Linear(h_t)              ->  ([256, 300])\n",
    "\n",
    "\n",
    "**Decoder**  \n",
    "- Embedding                      ->  (17573, 300)\n",
    "- Dropout 0.15\n",
    "- h_t, h_n GRU(input, h_0)       ->  ([300, 300, 2])\n",
    "- res = Linear(h_t)              ->  ([300, 17573])\n",
    "\n",
    "\n",
    "**Loss**\n",
    "- crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T22:15:36.346394Z",
     "start_time": "2018-06-22T22:15:36.313779Z"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2SeqRNN(nn.Module):\n",
    "    def __init__(self, pre_enc, itos_enc, em_sz_enc, pre_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl   #=> 2, 256, 30\n",
    "        self.emb_enc = nn.Embedding.from_pretrained(pre_enc) #=> Embedding(24793, 300)\n",
    "        # self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25) #=> ([300, 256, 2])\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        \n",
    "        self.emb_dec = nn.Embedding.from_pretrained(pre_dec) #=> Embedding(17573, 300)\n",
    "        self.emb_dec_drop = nn.Dropout(0.15)\n",
    "        # self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=out_sl, dropout=0.35) #=> ([300, 300, 30])\n",
    "#         self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec)) #=> ([300, 17573])\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "    def forward(self, inp):        \n",
    "        ### Encoder ###\n",
    "        sl,bs = inp.size() #=> ([30, 125])\n",
    "        # initialize previous hidden state - _bos_ tokens\n",
    "        h = self.initHidden(bs) #=> ([2, 125, 256])\n",
    "        # get input vectors from embedding and apply dropout\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp)) #=> ([30, 125, 300])\n",
    "        # run above through gru w/ previous hidden state\n",
    "        # enc_out.shape dependent on input size!!!!\n",
    "        enc_out, h = self.gru_enc(emb, h) #=> ([30, 125, 256]), ([2, 125, 256])\n",
    "        # output vector to be fed to decoder\n",
    "        h = self.out_enc(enc_out) #=> ([30, 125, 300])\n",
    "\n",
    "        # initialize decoder input - _bos_ tokens\n",
    "        dec_inp = V(torch.zeros(bs).long()) #=> ([30, 125])\n",
    "        res = []\n",
    "        # loop through ~30 times -> for each word in output\n",
    "        for i in range(self.out_sl):\n",
    "            # .unsqueeze(0) - add leading unit axis -> treat as a sequence of length 1\n",
    "            # gru works on an entire sequence at a time but we're iterating through each part separately...\n",
    "            # not really taking advantage of rnn at all; could re-write using linear layer\n",
    "            # dec_inp - input to the embedding - previous result\n",
    "            emb = self.emb_dec_drop(self.emb_dec(dec_inp).unsqueeze(0))  # embedding => ([1, 125, 300])\n",
    "            outp, h = self.gru_dec(emb, h)            # rnn => ([1, 125, 300]),  ([2, 125, 300])\n",
    "            outp = self.out(outp[0])   # dropout, linear layer => ([125, 17571])\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])  #=> ([125])\n",
    "            if (dec_inp==1).all(): break    # 1: padding token => stop, we're done (padding at the end)\n",
    "        return torch.stack(res)   # stack up list of results into single tensor and return it\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN(nn.Module):\n",
    "    def __init__(self, pre_enc, itos_enc, em_sz_enc, pre_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl   #=> 2, 256, 30\n",
    "        self.emb_enc = nn.Embedding.from_pretrained(pre_enc) #=> Embedding(24793, 300)\n",
    "        # self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25) #=> ([300, 256, 2])\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        \n",
    "        self.emb_dec = nn.Embedding.from_pretrained(pre_dec) #=> Embedding(17573, 300)\n",
    "        # self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1) #=> ([300, 300, 2])\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec)) #=> ([300, 17573])\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "    def forward(self, inp):        \n",
    "        ### Encoder ###\n",
    "        sl,bs = inp.size() #=> ([30, 125])\n",
    "        # initialize previous hidden state - _bos_ tokens\n",
    "        h = self.initHidden(bs) #=> ([2, 125, 256])\n",
    "        # get input vectors from embedding and apply dropout\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp)) #=> ([30, 125, 300])\n",
    "        # run above through gru w/ previous hidden state\n",
    "        enc_out, h = self.gru_enc(emb, h) #=> ([30, 125, 256]), ([2, 125, 256])\n",
    "        # output vector to be fed to decoder\n",
    "        h = self.out_enc(h) #=> ([2, 125, 300])\n",
    "\n",
    "        # initialize decoder input - _bos_ tokens\n",
    "        dec_inp = V(torch.zeros(bs).long()) #=> ([125])\n",
    "        res = []\n",
    "        # loop through ~30 times -> for each word in output\n",
    "        for i in range(self.out_sl):\n",
    "            # .unsqueeze(0) - add leading unit axis -> treat as a sequence of length 1\n",
    "            # gru works on an entire sequence at a time but we're iterating through each part separately...\n",
    "            # not really taking advantage of rnn at all; could re-write using linear layer\n",
    "            # dec_inp - input to the embedding - previous result\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)  # embedding => ([1, 125, 300])\n",
    "            outp, h = self.gru_dec(emb, h)            # rnn => ([1, 125, 300]),  ([2, 125, 300])\n",
    "            outp = self.out(self.out_drop(outp[0]))   # dropout, linear layer => ([125, 17571])\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])  #=> ([125])\n",
    "            if (dec_inp==1).all(): break    # 1: padding token => stop, we're done (padding at the end)\n",
    "        return torch.stack(res)   # stack up list of results into single tensor and return it\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:56:50.889610Z",
     "start_time": "2018-06-22T21:56:50.860745Z"
    }
   },
   "outputs": [],
   "source": [
    "# categorical cross entropy loss\n",
    "# list of probabilities for each word in vocab; target is correct word\n",
    "\n",
    "def seq2seq_loss(input, target):    \n",
    "    sl,bs = target.size()   #=> ([30,125])\n",
    "    sl_in,bs_in,nc = input.size()  #=> ([30, 125, 17573])\n",
    "    \n",
    "    # tweak 1: we may have stopped early; if seq length is less than target, add some padding\n",
    "    # necessary if difference in length btw target and input sl (french longer than english)\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in)) # rank3 tensor requires 6 padding values (before and after)\n",
    "    # 3rd dimension (sequence length??) add as much padding as necessary at the end\n",
    "        \n",
    "    input = input[:sl]\n",
    "    # cross_entropy expects rank2 tensor but we have sl * bs so we need to flatten out both\n",
    "    # combination of LogSoftmax and NLLLoss\n",
    "    return F.cross_entropy(input.view(-1,nc), target.view(-1))  #=> ([3750, 17573]), ([3750])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:56:52.780202Z",
     "start_time": "2018-06-22T21:56:52.745474Z"
    }
   },
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T22:15:39.805766Z",
     "start_time": "2018-06-22T22:15:39.408627Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnn = Seq2SeqRNN(enc_embedding, fr_itos, dim_fr_vec, dec_embedding, en_itos, dim_en_vec, nh, enlen_90)\n",
    "# SingleModel => way to handle learning rate groups -> treats whole thing as single group\n",
    "# easy way to turn pytorch module into fastai model\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3c31040360493da0d981da7c3abd26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 272/362 [00:29<00:09,  9.07it/s, loss=33.7]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(start_lr=1e-7)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:57:00.684957Z",
     "start_time": "2018-06-22T21:57:00.650540Z"
    }
   },
   "outputs": [],
   "source": [
    "lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf81c21d2f24a2cb56beb1b63ecab01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/362 [00:00<?, ?it/s]> <ipython-input-40-9fd215cc88af>(8)seq2seq_loss()\n",
      "-> sl,bs = target.size()\n",
      "(Pdb) l\n",
      "  3  \t\n",
      "  4  \tdef seq2seq_loss(input, target):\n",
      "  5  \t    pdb.set_trace()\n",
      "  6  \t\n",
      "  7  \t\n",
      "  8  ->\t    sl,bs = target.size()\n",
      "  9  \t    sl_in,bs_in,nc = input.size()\n",
      " 10  \t    # tweak 1: we may have stopped early; if seq length is less than target, add some padding\n",
      " 11  \t    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in)) # rank3 tensor requires 6 padding values (before and after)\n",
      " 12  \t        # 3rd dimension (sequence length??) add as much padding as necessary at the end\n",
      " 13  \t    input = input[:sl]\n",
      "(Pdb) target.size()\n",
      "torch.Size([30, 125])\n",
      "(Pdb) input.size()\n",
      "torch.Size([30, 125, 17573])\n",
      "(Pdb) n\n",
      "> <ipython-input-40-9fd215cc88af>(9)seq2seq_loss()\n",
      "-> sl_in,bs_in,nc = input.size()\n",
      "(Pdb) n\n",
      "> <ipython-input-40-9fd215cc88af>(11)seq2seq_loss()\n",
      "-> if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in)) # rank3 tensor requires 6 padding values (before and after)\n",
      "(Pdb) l\n",
      "  6  \t\n",
      "  7  \t\n",
      "  8  \t    sl,bs = target.size()\n",
      "  9  \t    sl_in,bs_in,nc = input.size()\n",
      " 10  \t    # tweak 1: we may have stopped early; if seq length is less than target, add some padding\n",
      " 11  ->\t    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in)) # rank3 tensor requires 6 padding values (before and after)\n",
      " 12  \t        # 3rd dimension (sequence length??) add as much padding as necessary at the end\n",
      " 13  \t    input = input[:sl]\n",
      " 14  \t    # tweak 2: cross_entropy expects rank2 tensor but we have seq_length * bs so we need to flatten out both\n",
      " 15  \t    return F.cross_entropy(input.view(-1,nc), target.view(-1))#, ignore_index=1)\n",
      "[EOF]\n",
      "(Pdb) sl\n",
      "30\n",
      "(Pdb) sl_in\n",
      "30\n",
      "(Pdb) n\n",
      "> <ipython-input-40-9fd215cc88af>(13)seq2seq_loss()\n",
      "-> input = input[:sl]\n",
      "(Pdb) input\n",
      "tensor([[[ 1.7217e+00, -7.9203e-03, -8.1278e-01,  ...,  9.5595e-01,\n",
      "           4.6555e-01, -1.6013e-01],\n",
      "         [ 1.7821e+00, -7.9203e-03, -1.5938e+00,  ...,  3.4927e+00,\n",
      "           1.6133e+00, -1.5461e+00],\n",
      "         [-7.7429e-01, -7.9203e-03,  2.1957e+00,  ...,  1.8688e+00,\n",
      "           6.6166e-01, -9.6681e-01],\n",
      "         ...,\n",
      "         [-1.0914e+00, -7.9203e-03,  8.8468e-02,  ..., -1.7982e+00,\n",
      "           1.6907e+00, -2.4737e+00],\n",
      "         [ 2.9809e+00, -7.9203e-03,  2.0379e-01,  ...,  3.6459e-01,\n",
      "          -4.3854e-01, -5.1247e+00],\n",
      "         [ 1.6351e+00, -7.9203e-03,  4.3491e+00,  ...,  4.8173e-01,\n",
      "           1.2756e+00, -1.1865e+00]],\n",
      "\n",
      "        [[ 3.3496e+00, -7.9203e-03,  1.0010e+00,  ...,  2.3428e+00,\n",
      "           1.0841e+00, -9.3675e-01],\n",
      "         [ 2.1772e+00, -7.9203e-03,  2.8551e-01,  ...,  3.2936e+00,\n",
      "           2.3797e+00, -1.9020e+00],\n",
      "         [ 2.0618e+00, -7.9203e-03,  6.6688e-01,  ...,  2.1195e+00,\n",
      "           2.3542e-01,  1.2489e+00],\n",
      "         ...,\n",
      "         [ 2.2101e+00, -7.9203e-03,  2.6181e+00,  ...,  4.1571e-01,\n",
      "           8.0805e-01, -2.9954e+00],\n",
      "         [ 4.1665e+00, -7.9203e-03, -2.0056e+00,  ...,  9.3711e-01,\n",
      "          -8.9531e-01, -5.7582e+00],\n",
      "         [ 4.8110e-01, -7.9203e-03,  1.3329e+00,  ...,  3.9834e+00,\n",
      "          -6.4706e-01,  8.0802e-01]],\n",
      "\n",
      "        [[ 2.2005e+00, -7.9203e-03,  4.6497e-01,  ...,  5.0748e+00,\n",
      "           1.0962e+00,  3.7231e+00],\n",
      "         [ 2.0702e+00, -7.9203e-03,  3.6123e+00,  ...,  1.9969e+00,\n",
      "           3.3284e+00, -1.7387e+00],\n",
      "         [ 2.7200e+00, -7.9203e-03, -7.2847e-02,  ...,  1.2991e+00,\n",
      "           2.1942e-01,  1.5073e+00],\n",
      "         ...,\n",
      "         [ 3.9089e+00, -7.9203e-03,  5.9587e+00,  ...,  1.8145e+00,\n",
      "          -9.4036e-01, -1.5572e+00],\n",
      "         [ 2.8956e+00, -7.9203e-03, -2.6658e+00,  ...,  2.4933e+00,\n",
      "           1.2831e+00,  2.0596e+00],\n",
      "         [ 2.2117e+00, -7.9203e-03, -1.7127e-01,  ...,  2.2442e-01,\n",
      "          -2.1111e+00,  3.6099e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.9078e+00, -7.9203e-03,  3.1394e-01,  ..., -2.8841e-01,\n",
      "          -7.3024e+00,  6.6720e+00],\n",
      "         [-1.0976e+00, -7.9203e-03, -2.7078e+00,  ...,  5.0537e+00,\n",
      "          -6.5358e+00,  7.2281e+00],\n",
      "         [-3.8608e-01, -7.9203e-03,  1.2620e+00,  ...,  7.2622e+00,\n",
      "           4.9294e+00,  3.6412e+00],\n",
      "         ...,\n",
      "         [ 1.9738e+00, -7.9203e-03, -1.1918e+00,  ...,  6.9085e-01,\n",
      "           6.7954e-01,  3.0532e+00],\n",
      "         [-5.0127e+00, -7.9203e-03, -3.7851e+00,  ...,  4.8277e+00,\n",
      "           1.9418e+00,  3.5943e+00],\n",
      "         [ 1.2996e+00, -7.9203e-03,  9.7242e-01,  ...,  2.7639e+00,\n",
      "           7.8034e-01, -5.2190e-01]],\n",
      "\n",
      "        [[-1.2107e+00, -7.9203e-03, -2.6972e+00,  ...,  2.4674e-01,\n",
      "          -1.0314e+00,  5.0008e+00],\n",
      "         [ 1.0854e+00, -7.9203e-03, -5.3817e+00,  ...,  3.2862e+00,\n",
      "           3.2661e-02,  1.1172e+01],\n",
      "         [ 2.6138e+00, -7.9203e-03, -6.0132e+00,  ...,  4.9543e+00,\n",
      "          -3.5624e+00,  5.1415e+00],\n",
      "         ...,\n",
      "         [ 3.4739e+00, -7.9203e-03, -1.8471e+00,  ...,  8.5993e-01,\n",
      "           2.4569e-01,  3.7615e+00],\n",
      "         [-1.5164e+00, -7.9203e-03, -3.8792e+00,  ...,  2.5763e+00,\n",
      "           1.4872e+00,  2.6951e+00],\n",
      "         [-1.9939e+00, -7.9203e-03,  2.5503e-01,  ...,  5.1171e+00,\n",
      "           6.3956e-02,  6.4177e+00]],\n",
      "\n",
      "        [[ 6.1611e-01, -7.9203e-03,  2.2319e+00,  ...,  2.0395e+00,\n",
      "          -7.1061e-01, -1.9869e+00],\n",
      "         [ 2.4082e+00, -7.9203e-03, -3.8217e+00,  ...,  2.2866e+00,\n",
      "          -1.4833e-01,  2.8678e+00],\n",
      "         [ 3.5346e+00, -7.9203e-03,  3.8607e+00,  ...,  6.0134e+00,\n",
      "          -7.0014e-01,  4.9284e+00],\n",
      "         ...,\n",
      "         [ 1.0922e+00, -7.9203e-03, -2.9080e+00,  ..., -1.1044e+00,\n",
      "          -1.5010e+00,  7.2642e+00],\n",
      "         [-1.1379e+00, -7.9203e-03,  8.9534e-01,  ..., -1.9841e+00,\n",
      "           1.8097e+00,  1.1134e+01],\n",
      "         [-8.9698e-01, -7.9203e-03, -2.4719e+00,  ...,  2.6084e+00,\n",
      "           3.2779e-01,  4.2755e+00]]], device='cuda:0')\n",
      "(Pdb) n\n",
      "> <ipython-input-40-9fd215cc88af>(15)seq2seq_loss()\n",
      "-> return F.cross_entropy(input.view(-1,nc), target.view(-1))#, ignore_index=1)\n",
      "(Pdb) input.shape\n",
      "torch.Size([30, 125, 17573])\n",
      "(Pdb) l\n",
      " 10  \t    # tweak 1: we may have stopped early; if seq length is less than target, add some padding\n",
      " 11  \t    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in)) # rank3 tensor requires 6 padding values (before and after)\n",
      " 12  \t        # 3rd dimension (sequence length??) add as much padding as necessary at the end\n",
      " 13  \t    input = input[:sl]\n",
      " 14  \t    # tweak 2: cross_entropy expects rank2 tensor but we have seq_length * bs so we need to flatten out both\n",
      " 15  ->\t    return F.cross_entropy(input.view(-1,nc), target.view(-1))#, ignore_index=1)\n",
      "[EOF]\n",
      "(Pdb) nc\n",
      "17573\n",
      "(Pdb) target.view(-1).shape\n",
      "torch.Size([3750])\n",
      "(Pdb) 30*125\n",
      "3750\n",
      "(Pdb) input.view(-1,nc).shape\n",
      "torch.Size([3750, 17573])\n",
      "(Pdb) c\n",
      "  0%|          | 1/362 [03:48<22:53:19, 228.25s/it, loss=18.2]> <ipython-input-40-9fd215cc88af>(8)seq2seq_loss()\n",
      "-> sl,bs = target.size()\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-73017c7e0d99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_crit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-9fd215cc88af>\u001b[0m in \u001b[0;36mseq2seq_loss\u001b[0;34m(input, target)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0msl_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# tweak 1: we may have stopped early; if seq length is less than target, add some padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-9fd215cc88af>\u001b[0m in \u001b[0;36mseq2seq_loss\u001b[0;34m(input, target)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0msl_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# tweak 1: we may have stopped early; if seq length is less than target, add some padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831aaab9b0c64f5c9c882f13c997b1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=11), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      5.965458   6.010027  \n",
      "    1      4.604166   4.892848                              \n",
      "    2      4.088986   4.278022                              \n",
      "    3      3.828717   3.993507                              \n",
      "    4      3.703301   3.883787                              \n",
      "    5      3.351877   3.777268                              \n",
      "    6      3.324167   3.724023                              \n",
      "    7      3.357103   3.669032                              \n",
      "    8      3.469063   3.687872                              \n",
      "    9      3.105404   3.642561                              \n",
      "    10     3.144482   3.605386                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.6053855804620434]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# w/out _bos_, _eos_ tokens\n",
    "learn.fit(lr, 1, cycle_len=11, use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      5.124279   4.897236  \n",
      "    1      4.103417   4.174995                              \n",
      "    2      3.777021   3.959338                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.9593378492490423]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as-is w/ _bos_, _eos_ tokens\n",
    "learn.fit(lr, 1, cycle_len=3, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      5.388616   4.829743  \n",
      "    1      3.983127   4.134926                              \n",
      "    2      3.748682   3.88019                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.880190259477161]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# w/out tweak 1 in loss function\n",
    "learn.fit(lr, 1, cycle_len=3, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47240048f6eb486ea37240b3d7a92c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      5.18976    5.898132  \n",
      "    1      4.419343   4.290398                              \n",
      "    2      3.952332   4.098109                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.09810851353829]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fr: 40, en: 30\n",
    "learn.fit(lr, 1, cycle_len=3, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T22:15:46.592261Z",
     "start_time": "2018-06-22T22:15:43.497678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589ebc2d6016430eac053e05eb426db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 5/362 [00:03<03:34,  1.66it/s, loss=9.81]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden size (30, 125, 300), got (28, 125, 300)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-2c56e74c8581>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# rearrange stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_clr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_crit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-a9f9f2759391>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# dec_inp - input to the embedding - previous result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_dec_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# embedding => ([30, 125, 300])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0moutp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m# rnn => ([1, 125, 300]),  ([2, 125, 300])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0moutp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# dropout, linear layer => ([125, 17571])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mflat_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         func = self._backend.RNN(\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    149\u001b[0m                               'Expected hidden[1] size {}, got {}')\n\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Expected hidden size {}, got {}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden size (30, 125, 300), got (28, 125, 300)"
     ]
    }
   ],
   "source": [
    "# rearrange stuff\n",
    "learn.fit(lr, 1, cycle_len=3, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-22T22:16:58.587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m(143)\u001b[0;36mcheck_hidden_size\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    141 \u001b[0;31m        \u001b[0;32mdef\u001b[0m \u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Expected hidden size {}, got {}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 143 \u001b[0;31m                \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    144 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    145 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m(151)\u001b[0;36mcheck_forward_args\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    149 \u001b[0;31m                              'Expected hidden[1] size {}, got {}')\n",
      "\u001b[0m\u001b[0;32m    150 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 151 \u001b[0;31m            \u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    152 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    153 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m(178)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    176 \u001b[0;31m            \u001b[0mflat_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    177 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 178 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    179 \u001b[0;31m        func = self._backend.RNN(\n",
      "\u001b[0m\u001b[0;32m    180 \u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m(491)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    489 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    490 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 491 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    492 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    493 \u001b[0;31m            \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m<ipython-input-49-a9f9f2759391>\u001b[0m(41)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     39 \u001b[0;31m            \u001b[0;31m# dec_inp - input to the embedding - previous result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     40 \u001b[0;31m            \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_dec_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# embedding => ([30, 125, 300])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 41 \u001b[0;31m            \u001b[0moutp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m# rnn => ([1, 125, 300]),  ([2, 125, 300])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     42 \u001b[0;31m            \u001b[0moutp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# dropout, linear layer => ([125, 17571])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     43 \u001b[0;31m            \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> oupt.shape\n",
      "*** NameError: name 'oupt' is not defined\n",
      "ipdb> outp.shape\n",
      "*** NameError: name 'outp' is not defined\n",
      "ipdb> emb.shape\n",
      "torch.Size([1, 125, 300])\n",
      "ipdb> !h.shape\n",
      "torch.Size([28, 125, 300])\n",
      "ipdb> p\n",
      "*** SyntaxError: unexpected EOF while parsing\n",
      "ipdb> l\n",
      "\u001b[1;32m     36 \u001b[0m            \u001b[0;31m# .unsqueeze(0) - add leading unit axis -> treat as a sequence of length 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     37 \u001b[0m            \u001b[0;31m# gru works on an entire sequence at a time but we're iterating through each part separately...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     38 \u001b[0m            \u001b[0;31m# not really taking advantage of rnn at all; could re-write using linear layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     39 \u001b[0m            \u001b[0;31m# dec_inp - input to the embedding - previous result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     40 \u001b[0m            \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_dec_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# embedding => ([30, 125, 300])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 41 \u001b[0;31m            \u001b[0moutp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m# rnn => ([1, 125, 300]),  ([2, 125, 300])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     42 \u001b[0m            \u001b[0moutp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# dropout, linear layer => ([125, 17571])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     43 \u001b[0m            \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     44 \u001b[0m            \u001b[0mdec_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#=> ([125])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     45 \u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdec_inp\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m    \u001b[0;31m# 1: padding token => stop, we're done (padding at the end)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     46 \u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# stack up list of results into single tensor and return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "ipdb> enc_out.shape\n",
      "torch.Size([28, 125, 256])\n",
      "ipdb> sl\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('initial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.load('initial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_bos_ quelles composantes des différents aspects de la performance devraient être mesurées , quelles données pertinentes recueillir et comment ? _eos_\n",
      "_bos_ which components within various performance areas should be measured , whatkinds of data are appropriate to collect , and how should this be done ? _eos_\n",
      "_bos_ what of of of be be be be be ? ? ? ? _eos_ _eos_ _eos_\n",
      "\n",
      "_bos_ le premier ministre doit - il nommer un ministre d’ état à la santé mentale , à la maladie mentale et à la toxicomanie ? _eos_\n",
      "_bos_ what role can the federal government play to ensure that individuals with mental illness and addiction have access to the drug therapy they need ? _eos_\n",
      "_bos_ who is the government to to health health health health ? ? ? ? _eos_ _eos_ _eos_ _eos_\n",
      "\n",
      "_bos_ quelles sont les conséquences de la hausse des formes d’ emploi non conformes aux normes chez les travailleurs hautement qualifiés et chez ceux qui occupent des emplois plus marginaux\n",
      "_bos_ what is the impact of growing forms of non - standard employment for highly skilled workers and for those employed in more marginal occupations ? _eos_\n",
      "_bos_ what are the of of of of and and and and and and and and and and ? ? ? ? _eos_ _eos_ _eos_ _eos_ _eos_ _eos_\n",
      "\n",
      "_bos_ que se produit - il si le gestionnaire n’ est pas en mesure de donner à l’ employé nommé pour une période déterminée un préavis de cessation d’ emploi\n",
      "_bos_ what happens if the manager is unable to or neglects to give a term employee the one - month notice of non - renewal ? _eos_\n",
      "_bos_ what happens if if a a a a a a a a a a ? ? ? ? ? _eos_ _eos_ _eos_\n",
      "\n",
      "_bos_ quelles personnes , communautés ou entités sont considérées comme potentiels i ) bénéficiaires de la protection et ii ) titulaires de droits ? _eos_\n",
      "_bos_ which persons , communities or entities are identified as potential ( i ) beneficiaries of protection and / or ( ii ) rights holders ? _eos_\n",
      "_bos_ who groups or or or or and and and ? ? ? ? _eos_ _eos_ _eos_ _eos_ _eos_\n",
      "\n",
      "_bos_ quelles conditions particulières doivent être remplies pendant l’ examen préliminaire international en ce qui concerne les listages des séquences de nucléotides ou d’ acides aminés ou les tableaux y\n",
      "_bos_ what special requirements apply during the international preliminary examination to nucleotide and / or amino acid sequence listings and / or tables related thereto ? _eos_\n",
      "_bos_ what conditions the be the the the the the the the of the of the ? ? ? ? ? ? ? _eos_ _eos_ _eos_\n",
      "\n",
      "_bos_ pourquoi cette soudaine réticence à promouvoir l’ égalité des genres et à protéger les femmes de ce que , dans la plupart des cas , on peut qualifier de\n",
      "_bos_ why this sudden reluctance to effectively promote gender equality and protect women from what are – in many cases – egregious human rights violations ? _eos_\n",
      "_bos_ why is the to to to to to to and and and and and and and and ? ? ? ? ? ? _eos_ _eos_ _eos_ _eos_ _eos_ _eos_\n",
      "\n",
      "_bos_ pouvez - vous dire comment votre bagage culturel vous a aidée à aborder votre nouvelle vie au canada ( à vous adapter au mode de vie canadien ) ?\n",
      "_bos_ what are some things from your cultural background that have helped you navigate canadian life ( helped you adjust to life in canada ) ? _eos_\n",
      "_bos_ what your you you you you you to to to canada canada to canada to canada ? ? ? ? ? _eos_ _eos_ _eos_\n",
      "\n",
      "_bos_ selon vous , quels seront , dans les dix prochaines années , les cinq enjeux les plus urgents en matière d' environnement et d' avenir viable pour vous et\n",
      "_bos_ which do you think will be the five most pressing environmental and sustainability issues for you and your region in the next ten years ? _eos_\n",
      "_bos_ what would you you the the the the the the the the to to to the the ? ? ? ? ? ? ? _eos_ _eos_\n",
      "\n",
      "_bos_ dans quelle mesure l’ expert est-il motivé et capable de partager ses connaissances , et dans quelle mesure son successeur est-il motivé et capable de recevoir ce savoir ?\n",
      "_bos_ what is the expert ’s level of motivation and capability for sharing knowledge , and the successor ’s motivation and capability of acquiring it ? _eos_\n",
      "_bos_ what is the knowledge knowledge knowledge and and and and and to to to to to to ? ? ? ? ? ? _eos_ _eos_ _eos_ _eos_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs = learn.model(V(x))\n",
    "preds = to_np(probs.max(2)[1])\n",
    "\n",
    "for i in range(180,190):\n",
    "    print(' '.join([fr_itos[o] for o in x[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o!=1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Bidir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_Bidir(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25, bidirectional=True)  # bidir flag\n",
    "        self.out_enc = nn.Linear(nh*2, em_sz_dec, bias=False)  # need to multiply by 2 here  ([512, 300])\n",
    "        self.drop_enc = nn.Dropout(0.05)\n",
    "        \n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h) #=> ([30, 125, 512]), ([4, 125, 256])\n",
    "        \n",
    "        # ([2, 2, 125, 256]) => ([2,125,2,256]) => ([2, 125, 512])\n",
    "        # contiguous() => makes sure that it is stored in a contiguous chunk of memory -> performance\n",
    "        h = h.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(2,bs,-1)\n",
    "        h = self.out_enc(self.drop_enc(h))\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl*2, bs, self.nh))  # need to multiply by 2 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097 ['l’', \"d'\", 't_up', 'd’', \"qu'\"]\n",
      "1285 [\"'s\", '’s', \"n't\", 'n’t', ':']\n"
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqRNN_Bidir(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730b5b27d4474caead0b8478d4b5d950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      4.994749   5.129475  \n",
      "    1      4.105142   3.989798                              \n",
      "    2      3.688282   3.788594                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.7885937128386735]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=3, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('bidir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqStepper(Stepper):\n",
    "    def step(self, xs, y, epoch):\n",
    "        self.m.pr_force = (10-epoch)*0.1 if epoch<10 else 0\n",
    "\n",
    "        xtra = []\n",
    "        output = self.m(*xs, y) # calls the .forward() method here passing in the y\n",
    "        if isinstance(output,tuple): output,*xtra = output\n",
    "        self.opt.zero_grad()\n",
    "        loss = raw_loss = self.crit(output, y)\n",
    "        if self.reg_fn: loss = self.reg_fn(output, xtra, raw_loss)\n",
    "        loss.backward()\n",
    "        if self.clip:   # Gradient clipping\n",
    "            nn.utils.clip_grad_norm(trainable_params_(self.m), self.clip)\n",
    "        self.opt.step()\n",
    "        return raw_loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_TeacherForcing(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        self.pr_force = 1.  # this gets decreased by the Stepper.step() function above\n",
    "        \n",
    "    def forward(self, inp, y=None):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "                \n",
    "            pdb.set_trace()\n",
    "            ## teacher forcing section ##\n",
    "            if (y is not None) and (random.random()<self.pr_force):\n",
    "                if i>=len(y): break\n",
    "                dec_inp = y[i]\n",
    "                \n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097 ['l’', \"d'\", 't_up', 'd’', \"qu'\"]\n",
      "1285 [\"'s\", '’s', \"n't\", 'n’t', ':']\n"
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqRNN_TeacherForcing(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# need to use over 10 epochs here because of teacher_forcing up to 10\n",
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10), stepper=Seq2SeqStepper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('forcing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attentional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_t(*sz): return torch.randn(sz)/math.sqrt(sz[0])\n",
    "def rand_p(*sz): return nn.Parameter(rand_t(*sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqAttnRNN(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "\n",
    "        # setting up Attention Layers\n",
    "        self.W1 = rand_p(nh, em_sz_dec)  #=> ([256, 300])\n",
    "        self.l2 = nn.Linear(em_sz_dec, em_sz_dec) \n",
    "        self.l3 = nn.Linear(em_sz_dec+nh, em_sz_dec) #=> ([556, 300])\n",
    "        self.V = rand_p(em_sz_dec)  #=> ([300])\n",
    "\n",
    "    def forward(self, inp, y=None, ret_attn=False):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)  #=> ([30, 125, 256]), ([2, 125, 256])\n",
    "        # enc_out: final output of encoder layer (shape depends on input size!!)\n",
    "        # h: final state of cell\n",
    "        h = self.out_enc(h)\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res,attns = [],[]\n",
    "        # matrix multiply; hidden state at each time step and a random (learnable) matrix        \n",
    "        w1e = enc_out @ self.W1  #=> ([30, 125, 300])\n",
    "        for i in range(self.out_sl):\n",
    "            # take current hidden state of decoder and put it into a linear layer\n",
    "            w2h = self.l2(h[-1])  #=> ([125, 300])\n",
    "            # non-linear activation\n",
    "            u = F.tanh(w1e + w2h) #=> ([30, 125, 300])\n",
    "            # matrix multiply; softmax ensures all weights add up to 1 and 1 is higher than the rest\n",
    "            a = F.softmax(u @ self.V, 0)  #=> ([30, 125])\n",
    "            attns.append(a)\n",
    "            # a.unsqueeze(2): add axis at index 2 => ([30, 125, 1])\n",
    "            # weighted sum of all of the encoder outputs w/ attention results\n",
    "            Xa = (a.unsqueeze(2) * enc_out).sum(0) #=> ([125, 256])\n",
    "            emb = self.emb_dec(dec_inp)\n",
    "                                #=> ([125, 556])\n",
    "            wgt_enc = self.l3(torch.cat([emb, Xa], 1)) #=> ([125, 300])\n",
    "            \n",
    "            outp, h = self.gru_dec(wgt_enc.unsqueeze(0), h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "            if (y is not None) and (random.random()<self.pr_force):\n",
    "                if i>=len(y): break\n",
    "                dec_inp = y[i]\n",
    "\n",
    "        res = torch.stack(res)\n",
    "        if ret_attn: res = res,torch.stack(attns)\n",
    "        return res\n",
    "\n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097 ['l’', \"d'\", 't_up', 'd’', \"qu'\"]\n",
      "1285 [\"'s\", '’s', \"n't\", 'n’t', ':']\n"
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqAttnRNN(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3 #2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=15, use_clr=(20,10), stepper=Seq2SeqStepper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      4.958338   4.505362  \n",
      "    1      3.921784   3.893936                              \n",
      "    2      3.40713    3.63575                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.635750208646384]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=3, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737349e94ec94abe9d321d909d971153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      5.073933   4.683094  \n",
      "    1      3.844157   4.024905                              \n",
      "    2      3.655679   3.786953                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.7869534358172348]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# additional non-linearity (relu) after l3\n",
    "learn.fit(lr, 1, cycle_len=3, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.save('attn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.load('attn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs,attns = learn.model(V(x),ret_attn=True)\n",
    "preds = to_np(probs.max(2)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(180,190):\n",
    "    print(' '.join([fr_itos[o] for o in x[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o!=1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attn = to_np(attns[...,180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(15, 10))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ax.plot(attn[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-22T20:19:53.475Z"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_All(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25, bidirectional=True)\n",
    "        self.out_enc = nn.Linear(nh*2, em_sz_dec, bias=False)\n",
    "        self.drop_enc = nn.Dropout(0.25)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "\n",
    "        self.W1 = rand_p(nh*2, em_sz_dec)\n",
    "        self.l2 = nn.Linear(em_sz_dec, em_sz_dec)\n",
    "        self.l3 = nn.Linear(em_sz_dec+nh*2, em_sz_dec)\n",
    "        self.V = rand_p(em_sz_dec)\n",
    "\n",
    "    def forward(self, inp, y=None):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = h.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(2,bs,-1)\n",
    "        h = self.out_enc(self.drop_enc(h))\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res,attns = [],[]\n",
    "        w1e = enc_out @ self.W1\n",
    "        for i in range(self.out_sl):\n",
    "            w2h = self.l2(h[-1])\n",
    "            u = F.tanh(w1e + w2h)\n",
    "            a = F.softmax(u @ self.V, 0)\n",
    "            attns.append(a)\n",
    "            Xa = (a.unsqueeze(2) * enc_out).sum(0)\n",
    "            emb = self.emb_dec(dec_inp)\n",
    "            wgt_enc = self.l3(torch.cat([emb, Xa], 1))\n",
    "            \n",
    "            outp, h = self.gru_dec(wgt_enc.unsqueeze(0), h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "            if (y is not None) and (random.random()<self.pr_force):\n",
    "                if i>=len(y): break\n",
    "                dec_inp = y[i]\n",
    "        return torch.stack(res)\n",
    "\n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl*2, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-22T20:19:55.906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097 ['l’', \"d'\", 't_up', 'd’', \"qu'\"]\n",
      "1285 [\"'s\", '’s', \"n't\", 'n’t', ':']\n"
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqRNN_All(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf23b983c6c49cdaaab48a9fee1e5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      3.337701   9.977306  \n",
      "    1      3.018799   5.424579                              \n",
      "    2      4.647929   5.583291                              \n",
      "    3      3.120071   5.153758                              \n",
      "    4      3.04363    4.062732                              \n",
      "    5      2.877421   3.819941                              \n",
      "    6      2.898225   3.838456                              \n",
      "    7      2.642755   3.3822                                \n",
      "    8      2.679801   3.23474                               \n",
      "    9      2.748619   3.156902                              \n",
      "    10     2.79696    3.073594                              \n",
      "    11     2.485905   3.036421                              \n",
      "    12     2.460743   3.010847                              \n",
      "    13     2.397516   2.989805                              \n",
      "    14     2.249187   3.003645                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.0036454057438084]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=15, use_clr=(20,10), stepper=Seq2SeqStepper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('all_15_3.00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_bos_ quelles composantes des différents aspects de la performance devraient être mesurées , quelles données pertinentes recueillir et comment ? _eos_\n",
      "_bos_ which components within various performance areas should be measured , whatkinds of data are appropriate to collect , and how should this be done ? _eos_\n",
      "_bos_ what components of the aspects of be be be be be and and and how how ? ? _eos_\n",
      "\n",
      "_bos_ le premier ministre doit - il nommer un ministre d’ état à la santé mentale , à la maladie mentale et à la toxicomanie ? _eos_\n",
      "_bos_ what role can the federal government play to ensure that individuals with mental illness and addiction have access to the drug therapy they need ? _eos_\n",
      "_bos_ who is the minister minister minister minister minister to health mental mental health mental mental and ? ? _eos_ _eos_\n",
      "\n",
      "_bos_ quelles sont les conséquences de la hausse des formes d’ emploi non conformes aux normes chez les travailleurs hautement qualifiés et chez ceux qui occupent des emplois plus marginaux\n",
      "_bos_ what is the impact of growing forms of non - standard employment for highly skilled workers and for those employed in more marginal occupations ? _eos_\n",
      "_bos_ what are the implications of of of non - employment employment workers workers workers workers and workers workers and workers jobs jobs ? ? ? _eos_ _eos_\n",
      "\n",
      "_bos_ que se produit - il si le gestionnaire n’ est pas en mesure de donner à l’ employé nommé pour une période déterminée un préavis de cessation d’ emploi\n",
      "_bos_ what happens if the manager is unable to or neglects to give a term employee the one - month notice of non - renewal ? _eos_\n",
      "_bos_ what if the manager does not to the employee employee a a a employee of of employment employment employment ? ? _eos_\n",
      "\n",
      "_bos_ quelles personnes , communautés ou entités sont considérées comme potentiels i ) bénéficiaires de la protection et ii ) titulaires de droits ? _eos_\n",
      "_bos_ which persons , communities or entities are identified as potential ( i ) beneficiaries of protection and / or ( ii ) rights holders ? _eos_\n",
      "_bos_ who communities , communities or entities are considered as as as of protection protection protection protection protection ? ? ? _eos_\n",
      "\n",
      "_bos_ quelles conditions particulières doivent être remplies pendant l’ examen préliminaire international en ce qui concerne les listages des séquences de nucléotides ou d’ acides aminés ou les tableaux y\n",
      "_bos_ what special requirements apply during the international preliminary examination to nucleotide and / or amino acid sequence listings and / or tables related thereto ? _eos_\n",
      "_bos_ what special conditions must be be be the international preliminary examination for for the of sequence or amino or or or or or tables tables or tables ? _eos_\n",
      "\n",
      "_bos_ pourquoi cette soudaine réticence à promouvoir l’ égalité des genres et à protéger les femmes de ce que , dans la plupart des cas , on peut qualifier de\n",
      "_bos_ why this sudden reluctance to effectively promote gender equality and protect women from what are – in many cases – egregious human rights violations ? _eos_\n",
      "_bos_ why is this that to to of equality and and and of of in the , , , are can be ? ? ? ? ? ? ?\n",
      "\n",
      "_bos_ pouvez - vous dire comment votre bagage culturel vous a aidée à aborder votre nouvelle vie au canada ( à vous adapter au mode de vie canadien ) ?\n",
      "_bos_ what are some things from your cultural background that have helped you navigate canadian life ( helped you adjust to life in canada ) ? _eos_\n",
      "_bos_ what are your your of your your to your to to canada canada to to life life canadian canadian ? ? ? _eos_ _eos_\n",
      "\n",
      "_bos_ selon vous , quels seront , dans les dix prochaines années , les cinq enjeux les plus urgents en matière d' environnement et d' avenir viable pour vous et\n",
      "_bos_ which do you think will be the five most pressing environmental and sustainability issues for you and your region in the next ten years ? _eos_\n",
      "_bos_ what do you think will be the next next five , , the future future environmental future future and future future and and and and and and and and\n",
      "\n",
      "_bos_ dans quelle mesure l’ expert est-il motivé et capable de partager ses connaissances , et dans quelle mesure son successeur est-il motivé et capable de recevoir ce savoir ?\n",
      "_bos_ what is the expert ’s level of motivation and capability for sharing knowledge , and the successor ’s motivation and capability of acquiring it ? _eos_\n",
      "_bos_ what is the expert of and and and knowledge knowledge and and and and and and and and and and to ? ? ? ? ? ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs = learn.model(V(x))\n",
    "preds = to_np(probs.max(2)[1])\n",
    "\n",
    "for i in range(180,190):\n",
    "    print(' '.join([fr_itos[o] for o in x[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o!=1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {
    "height": "253px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
