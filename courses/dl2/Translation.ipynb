{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T17:10:43.250862Z",
     "start_time": "2018-06-20T17:10:42.873247Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T17:10:45.629835Z",
     "start_time": "2018-06-20T17:10:43.316536Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "French/English parallel texts from http://www.statmt.org/wmt15/translation-task.html .  It was created by Chris Callison-Burch, who crawled millions of web pages and then used *a set of simple heuristics to transform French URLs onto English URLs (i.e. replacing \"fr\" with \"en\" and about 40 other hand-written rules), and assume that these documents are translations of each other*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T17:10:45.799754Z",
     "start_time": "2018-06-20T17:10:45.749114Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH = Path('data/translate')\n",
    "TMP_PATH = PATH/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)\n",
    "fname='giga-fren.release2.fixed'\n",
    "en_fname = PATH/f'{fname}.en'\n",
    "fr_fname = PATH/f'{fname}.fr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only using question texts to limit how long training takes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:08:30.695974Z",
     "start_time": "2018-06-19T18:05:59.076361Z"
    }
   },
   "outputs": [],
   "source": [
    "re_eq = re.compile('^(Wh[^?.!]+\\?)')\n",
    "re_fq = re.compile('^([^?.!]+\\?)')\n",
    "\n",
    "# lines -> generator object\n",
    "lines = ((re_eq.search(eq), re_fq.search(fq)) \n",
    "         for eq, fq in zip(open(en_fname, encoding='utf-8'), open(fr_fname, encoding='utf-8')))\n",
    "\n",
    "qs = [(e.group(), f.group()) for e,f in lines if e and f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:10:44.900842Z",
     "start_time": "2018-06-19T18:10:44.851977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('What is light ?', 'Qu’est-ce que la lumière?'),\n",
       "  ('Who are we?', 'Où sommes-nous?'),\n",
       "  ('Where did we come from?', \"D'où venons-nous?\"),\n",
       "  ('What would we do without it?', 'Que ferions-nous sans elle ?'),\n",
       "  ('What is the absolute location (latitude and longitude) of Badger, Newfoundland and Labrador?',\n",
       "   'Quelle sont les coordonnées (latitude et longitude) de Badger, à Terre-Neuve-etLabrador?')],\n",
       " 52331)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs[:5], len(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:11:09.970564Z",
     "start_time": "2018-06-19T18:11:09.861958Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(qs, (PATH/'fr-en-qs.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qs = pickle.load((PATH/'fr-en-qs.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:11:18.210243Z",
     "start_time": "2018-06-19T18:11:18.062406Z"
    }
   },
   "outputs": [],
   "source": [
    "en_qs,fr_qs = zip(*qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:11:27.444918Z",
     "start_time": "2018-06-19T18:11:23.628065Z"
    }
   },
   "outputs": [],
   "source": [
    "en_tok = Tokenizer.proc_all_mp(partition_by_cores(en_qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:14:46.899385Z",
     "start_time": "2018-06-19T18:14:23.598100Z"
    }
   },
   "outputs": [],
   "source": [
    "fr_tok = Tokenizer.proc_all_mp(partition_by_cores(fr_qs), 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:15:01.335178Z",
     "start_time": "2018-06-19T18:15:01.285696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['what', 'is', 'light', '?'],\n",
       " ['qu’', 'est', '-ce', 'que', 'la', 'lumière', '?'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tok[0], fr_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:16:09.686257Z",
     "start_time": "2018-06-19T18:16:09.619919Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.percentile([len(o) for o in en_tok], 96), np.percentile([len(o) for o in fr_tok], 91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:17:38.958048Z",
     "start_time": "2018-06-19T18:17:38.901815Z"
    }
   },
   "outputs": [],
   "source": [
    "keep = np.array([len(o)<30 for o in en_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:18:02.727687Z",
     "start_time": "2018-06-19T18:18:02.678558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52331, 52331)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_tok), len(fr_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:18:14.853990Z",
     "start_time": "2018-06-19T18:18:14.661479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50260, 50260)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tok = np.array(en_tok)[keep]\n",
    "fr_tok = np.array(fr_tok)[keep]\n",
    "len(en_tok), len(fr_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:18:52.962474Z",
     "start_time": "2018-06-19T18:18:52.607271Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(en_tok, (PATH/'en_tok.pkl').open('wb'))\n",
    "pickle.dump(fr_tok, (PATH/'fr_tok.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_tok = pickle.load((PATH/'en_tok.pkl').open('rb'))\n",
    "fr_tok = pickle.load((PATH/'fr_tok.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:23:01.629009Z",
     "start_time": "2018-06-19T18:23:01.569962Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def toks2ids(tok,pre):\n",
    "    freq = Counter(p for o in tok for p in o)\n",
    "    itos = [o for o,c in freq.most_common(40000)]\n",
    "#     itos.insert(0, '_bos_')\n",
    "    itos.insert(0, '_unk_')\n",
    "    itos.insert(1, '_pad_')\n",
    "#     itos.insert(2, '_eos_')\n",
    "    \n",
    "    stoi = collections.defaultdict(lambda: 0, {v:k for k,v in enumerate(itos)})\n",
    "    ids = np.array([([stoi[o] for o in p]) for p in tok])\n",
    "    np.save(TMP_PATH/f'{pre}_ids.npy', ids)\n",
    "    pickle.dump(itos, open(TMP_PATH/f'{pre}_itos.pkl', 'wb'))\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:23:04.762365Z",
     "start_time": "2018-06-19T18:23:03.928651Z"
    }
   },
   "outputs": [],
   "source": [
    "en_ids,en_itos,en_stoi = toks2ids(en_tok,'en')\n",
    "fr_ids,fr_itos,fr_stoi = toks2ids(fr_tok,'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:47:11.601467Z",
     "start_time": "2018-06-19T22:47:11.551845Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_ids(pre):\n",
    "    ids = np.load(TMP_PATH/f'{pre}_ids.npy')\n",
    "    itos = pickle.load(open(TMP_PATH/f'{pre}_itos.pkl', 'rb'))\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:47:12.456781Z",
     "start_time": "2018-06-19T22:47:12.206401Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_ids,en_itos,en_stoi = load_ids('en')\n",
    "fr_ids,fr_itos,fr_stoi = load_ids('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:47:13.227861Z",
     "start_time": "2018-06-19T22:47:13.174311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['qu’', 'est', '-ce', 'que', 'la', 'lumière', '?'], 17571, 24791)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fr_itos[o] for o in fr_ids[0]], len(en_itos), len(fr_itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fasttext word vectors available from https://fasttext.cc/docs/en/english-vectors.html  \n",
    "\n",
    "Why use word vectors instead of pretrained language models??  Because Jeremy hasn't tried it yet.  Should work better and something to potentially try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:24:34.174405Z",
     "start_time": "2018-06-19T18:24:00.108683Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ! pip install git+https://github.com/facebookresearch/fastText.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T16:58:27.722464Z",
     "start_time": "2018-06-20T16:58:27.662472Z"
    }
   },
   "outputs": [],
   "source": [
    "import fastText as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the fastText library, you'll need to download [fasttext word vectors](https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md) for your language (download the 'bin plus text' ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T18:50:53.138849Z",
     "start_time": "2018-06-19T18:33:06.487509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-06-20 13:38:57--  https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.en.zip\n",
      "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 54.231.237.33\n",
      "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|54.231.237.33|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10356881291 (9.6G) [application/zip]\n",
      "Saving to: ‘data/translate/wiki.en.zip’\n",
      "\n",
      "wiki.en.zip         100%[===================>]   9.65G  22.2MB/s    in 5m 42s  \n",
      "\n",
      "2018-06-20 13:44:40 (28.9 MB/s) - ‘data/translate/wiki.en.zip’ saved [10356881291/10356881291]\n",
      "\n",
      "Archive:  data/translate/wiki.en.zip\n",
      "  inflating: data/translate/wiki.en.vec  \n",
      "  inflating: data/translate/wiki.en.bin  \n",
      "en done\n",
      "--2018-06-20 13:47:15--  https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.fr.zip\n",
      "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.24.25\n",
      "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.24.25|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5975701653 (5.6G) [application/zip]\n",
      "Saving to: ‘data/translate/wiki.fr.zip’\n",
      "\n",
      "wiki.fr.zip         100%[===================>]   5.56G  51.0MB/s    in 2m 35s  \n",
      "\n",
      "2018-06-20 13:49:50 (36.9 MB/s) - ‘data/translate/wiki.fr.zip’ saved [5975701653/5975701653]\n",
      "\n",
      "Archive:  data/translate/wiki.fr.zip\n",
      "  inflating: data/translate/wiki.fr.vec  \n",
      "  inflating: data/translate/wiki.fr.bin  \n",
      "fr done\n"
     ]
    }
   ],
   "source": [
    "for lang in ['en', 'fr']:\n",
    "    fname = f'wiki.{lang}.zip'\n",
    "    !wget -P {PATH} https://s3-us-west-1.amazonaws.com/fasttext-vectors/{fname}\n",
    "    !unzip {PATH/fname} -d {PATH}\n",
    "    print(f'{lang} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T16:58:53.553829Z",
     "start_time": "2018-06-20T16:58:30.544300Z"
    }
   },
   "outputs": [],
   "source": [
    "en_vecs = ft.load_model(str((PATH/'wiki.en.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:48:43.527455Z",
     "start_time": "2018-06-19T22:48:22.226221Z"
    }
   },
   "outputs": [],
   "source": [
    "fr_vecs = ft.load_model(str((PATH/'wiki.fr.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T16:58:53.727719Z",
     "start_time": "2018-06-20T16:58:53.674962Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_vecs(lang, ft_vecs):\n",
    "    vecd = {w:ft_vecs.get_word_vector(w) for w in ft_vecs.get_words()}\n",
    "    pickle.dump(vecd, open(PATH/f'wiki.{lang}.pkl','wb'))\n",
    "    return vecd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T17:23:23.741049Z",
     "start_time": "2018-06-20T17:23:04.695Z"
    }
   },
   "outputs": [],
   "source": [
    "# reads file line by line to avoid memory problems and doesn't pickle\n",
    "def get_vecs_osx(lang):\n",
    "    vecd = {}\n",
    "    with open(PATH/f'wiki.{lang}.vec', encoding='utf-8') as infile:\n",
    "        for line in infile:\n",
    "            word,*vec = line.split()\n",
    "            if len(vec) == 300:\n",
    "                en_vecd[word] = np.array(vec, dtype=np.float32)\n",
    "    return vecd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-20T16:59:01.147Z"
    }
   },
   "outputs": [],
   "source": [
    "en_vecd = get_vecs('en', en_vecs)\n",
    "fr_vecd = get_vecs('fr', fr_vecs)\n",
    "\n",
    "# en_vecd = get_vecs_osx('en')\n",
    "# fr_vecd = get_vecs_osx('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T16:25:43.890937Z",
     "start_time": "2018-06-20T16:25:43.841474Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_vecd = pickle.load(open(PATH/'wiki.en.pkl','rb'))\n",
    "fr_vecd = pickle.load(open(PATH/'wiki.fr.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T17:18:23.897597Z",
     "start_time": "2018-06-20T17:18:23.847623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2519370, 1152449)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_vecd), len(fr_vecd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ft_words = ft_vecs.get_words(include_freq=True)\n",
    "# ft_word_dict = {k:v for k,v in zip(*ft_words)}\n",
    "# ft_words = sorted(ft_word_dict.keys(), key=lambda x: ft_word_dict[x])\n",
    "\n",
    "# len(ft_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_en_vec = len(en_vecd[','])\n",
    "dim_fr_vec = len(fr_vecd[','])\n",
    "dim_en_vec,dim_fr_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0075652334, 0.29283327)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vecs = np.stack(list(en_vecd.values()))\n",
    "en_vecs.mean(),en_vecs.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enlen_90 = int(np.percentile([len(o) for o in en_ids], 99))\n",
    "frlen_90 = int(np.percentile([len(o) for o in fr_ids], 97))\n",
    "enlen_90,frlen_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids_tr = np.array([o[:enlen_90] for o in en_ids])\n",
    "fr_ids_tr = np.array([o[:frlen_90] for o in fr_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __getitem__(self, idx): return A(self.x[idx], self.y[idx])  # A() => ensures arguments are numpy arrays\n",
    "    def __len__(self): return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45219, 5041)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clever way to seperate out a validation set w/ random numbers\n",
    "\n",
    "np.random.seed(42)\n",
    "trn_keep = np.random.rand(len(en_ids_tr))>0.1   # check list of random numbers for greater than .1 => list of bools\n",
    "en_trn,fr_trn = en_ids_tr[trn_keep],fr_ids_tr[trn_keep]   # index into data set w/ list of bools => training\n",
    "en_val,fr_val = en_ids_tr[~trn_keep],fr_ids_tr[~trn_keep] # index into data set w/ opposite => validation\n",
    "len(en_trn),len(en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translating french to english; reverse them to go the opposite direction\n",
    "trn_ds = Seq2SeqDataset(fr_trn,en_trn)\n",
    "val_ds = Seq2SeqDataset(fr_val,en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_samp = SortishSampler(en_trn, key=lambda x: len(en_trn[x]), bs=bs)\n",
    "val_samp = SortSampler(en_val, key=lambda x: len(en_val[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why do we need to transpose?\n",
    "# already done all of the pre-processing so limit num_workers to 1 to save time\n",
    "# pad_idx=1 - different length inputs, fastai automatically pads \n",
    "# for classifier we want the padding at the start -> final token to represent last word of review\n",
    "# for a decoder we want the padding at the end\n",
    "# sampler - sentences of different lengths need to be batched together, use a sampler to save time/memory!!\n",
    "\n",
    "trn_dl = DataLoader(trn_ds, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, int(bs*1.6), transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 28), (20, 6), (20, 7), (32, 12), (32, 20)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(trn_dl)\n",
    "its = [next(it) for i in range(5)]\n",
    "[(len(x),len(y)) for x,y in its]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    # embeddings: number of rows = vocab size, columns = determined by fasttext word vectors (300)\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    # learnable pytorch module has a 'weight' attribute => Variable\n",
    "    # 'weight' attribute has a 'data' attribute => Tensor\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    # iterate through vocabulary and replace found words w/ pretrained vector weights if available\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[w]*3)  # *3 => wgts have std_dev of 1; vector has std_dev of .3\n",
    "        except: miss.append(w)\n",
    "    print(len(miss),miss[5:10])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh,nl = 256,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        \n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())  # start off w/ a batch of beginning of stream tokens (0)\n",
    "        res = []\n",
    "        # out_sl - output sequence length - length of largest english sentence (output)\n",
    "        for i in range(self.out_sl):\n",
    "            # .unsqueeze(0) - add leading unit axis -> treat as a sequence of length 1\n",
    "            # gru works on an entire sequence at a time but we're iterating through each part separately...\n",
    "            # not really taking advantage of rnn at all; could re-write using linear layer\n",
    "            # dec_inp - input to the embedding - previous result\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)  # embedding\n",
    "            outp, h = self.gru_dec(emb, h)            # rnn\n",
    "            outp = self.out(self.out_drop(outp[0]))   # dropout, linear layer\n",
    "            res.append(outp) # outp -> tensor of length => number of words in english vocab w/ probability for each\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break    # 1: padding token => stop, we're done (padding at the end)\n",
    "        return torch.stack(res)   # stack up list of results into single tensor and return it\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical cross entropy loss\n",
    "# list of probabilities for each word in vocab; target is correct word\n",
    "\n",
    "def seq2seq_loss(input, target):\n",
    "    sl,bs = target.size()\n",
    "    sl_in,bs_in,nc = input.size()\n",
    "    # tweak 1: we may have stopped early; if seq length is less than target, add some padding\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in)) # rank3 tensor requires 6 padding values (before and after)\n",
    "        # 3rd dimension (sequence length??) add as much padding as necessary at the end\n",
    "    input = input[:sl]\n",
    "    # tweak 2: cross_entropy expects rank2 tensor but we have seq_length * bs so we need to flatten out both\n",
    "    return F.cross_entropy(input.view(-1,nc), target.view(-1))#, ignore_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3095 ['t_up', 'd’', \"qu'\", '-ce', 'qu’']\n",
      "1283 [\"n't\", 'n’t', ':', '1', '2006']\n"
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqRNN(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "# SingleModel => way to handle learning rate groups -> treats whole thing as single group\n",
    "# easy way to turn pytorch module into fastai model\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3c31040360493da0d981da7c3abd26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 272/362 [00:29<00:09,  9.07it/s, loss=33.7]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(start_lr=1e-7)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831aaab9b0c64f5c9c882f13c997b1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=11), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      5.965458   6.010027  \n",
      "    1      4.604166   4.892848                              \n",
      "    2      4.088986   4.278022                              \n",
      "    3      3.828717   3.993507                              \n",
      "    4      3.703301   3.883787                              \n",
      "    5      3.351877   3.777268                              \n",
      "    6      3.324167   3.724023                              \n",
      "    7      3.357103   3.669032                              \n",
      "    8      3.469063   3.687872                              \n",
      "    9      3.105404   3.642561                              \n",
      "    10     3.144482   3.605386                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.6053855804620434]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=11, use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7236f2d3451a49cb916a295f509166dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      3.312397   3.654379  \n",
      "    1      3.145095   3.622669                              \n",
      "    2      3.087453   3.549286                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.5492862527556324]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=3, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('initial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.load('initial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quelles composantes des différents aspects de la performance devraient être mesurées , quelles données pertinentes recueillir et comment ?\n",
      "which components within various performance areas should be measured , whatkinds of data are appropriate to collect , and how should this be done ?\n",
      "what aspects of the and and and and be be be be be ? ? ?\n",
      "\n",
      "le premier ministre doit - il nommer un ministre d’ état à la santé mentale , à la maladie mentale et à la toxicomanie ?\n",
      "what role can the federal government play to ensure that individuals with mental illness and addiction have access to the drug therapy they need ?\n",
      "who is the minister minister minister of , mental mental mental and mental health\n",
      "\n",
      "quelles sont les conséquences de la hausse des formes d’ emploi non conformes aux normes chez les travailleurs hautement qualifiés et chez ceux qui occupent des emplois plus marginaux ?\n",
      "what is the impact of growing forms of non - standard employment for highly skilled workers and for those employed in more marginal occupations ?\n",
      "what are the implications of unemployment of employment workers workers workers workers workers workers in workers in workers workers ? ? ? ?\n",
      "\n",
      "que se produit - il si le gestionnaire n’ est pas en mesure de donner à l’ employé nommé pour une période déterminée un préavis de cessation d’ emploi d’ un mois\n",
      "what happens if the manager is unable to or neglects to give a term employee the one - month notice of non - renewal ?\n",
      "what if if employee employee is employee a a employee a a a employee a the the the ? ? ?\n",
      "\n",
      "quelles personnes , communautés ou entités sont considérées comme potentiels i ) bénéficiaires de la protection et ii ) titulaires de droits ?\n",
      "which persons , communities or entities are identified as potential ( i ) beneficiaries of protection and / or ( ii ) rights holders ?\n",
      "who communities or or or or or or or or or the of of of ? ? ? ? ?\n",
      "\n",
      "quelles conditions particulières doivent être remplies pendant l’ examen préliminaire international en ce qui concerne les listages des séquences de nucléotides ou d’ acides aminés ou les tableaux y relatifs ?\n",
      "what special requirements apply during the international preliminary examination to nucleotide and / or amino acid sequence listings and / or tables related thereto ?\n",
      "what conditions conditions conditions must to to to with the the amino or amino or or amino the or ? ? ?\n",
      "\n",
      "pourquoi cette soudaine réticence à promouvoir l’ égalité des genres et à protéger les femmes de ce que , dans la plupart des cas , on peut qualifier de violations grossières des\n",
      "why this sudden reluctance to effectively promote gender equality and protect women from what are – in many cases – egregious human rights violations ?\n",
      "why is this this to to of , , , and and and and and and of of of of of and of ? ?\n",
      "\n",
      "pouvez - vous dire comment votre bagage culturel vous a aidée à aborder votre nouvelle vie au canada ( à vous adapter au mode de vie canadien ) ?\n",
      "what are some things from your cultural background that have helped you navigate canadian life ( helped you adjust to life in canada ) ?\n",
      "what is your your of your your to to to to canada to canada to canada canada to canada ? ? ?\n",
      "\n",
      "selon vous , quels seront , dans les dix prochaines années , les cinq enjeux les plus urgents en matière d' environnement et d' avenir viable pour vous et votre région ?\n",
      "which do you think will be the five most pressing environmental and sustainability issues for you and your region in the next ten years ?\n",
      "what do you see see the the future the the the the future the the the future and ? ? ? ? ?\n",
      "\n",
      "dans quelle mesure l’ expert est-il motivé et capable de partager ses connaissances , et dans quelle mesure son successeur est-il motivé et capable de recevoir ce savoir ?\n",
      "what is the expert ’s level of motivation and capability for sharing knowledge , and the successor ’s motivation and capability of acquiring it ?\n",
      "what is the knowledge and and and and and and and and and and and and and to to ? ? ? ? ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs = learn.model(V(x))\n",
    "preds = to_np(probs.max(2)[1])\n",
    "\n",
    "for i in range(180,190):\n",
    "    print(' '.join([fr_itos[o] for o in x[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o!=1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Bidir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_Bidir(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25, bidirectional=True)\n",
    "        self.out_enc = nn.Linear(nh*2, em_sz_dec, bias=False)\n",
    "        self.drop_enc = nn.Dropout(0.05)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = h.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(2,bs,-1)\n",
    "        h = self.out_enc(self.drop_enc(h))\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl*2, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rnn = Seq2SeqRNN_Bidir(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('bidir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqStepper(Stepper):\n",
    "    def step(self, xs, y, epoch):\n",
    "        self.m.pr_force = (10-epoch)*0.1 if epoch<10 else 0\n",
    "        xtra = []\n",
    "        output = self.m(*xs, y)\n",
    "        if isinstance(output,tuple): output,*xtra = output\n",
    "        self.opt.zero_grad()\n",
    "        loss = raw_loss = self.crit(output, y)\n",
    "        if self.reg_fn: loss = self.reg_fn(output, xtra, raw_loss)\n",
    "        loss.backward()\n",
    "        if self.clip:   # Gradient clipping\n",
    "            nn.utils.clip_grad_norm(trainable_params_(self.m), self.clip)\n",
    "        self.opt.step()\n",
    "        return raw_loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_TeacherForcing(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        self.pr_force = 1.\n",
    "        \n",
    "    def forward(self, inp, y=None):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "            if (y is not None) and (random.random()<self.pr_force):\n",
    "                if i>=len(y): break\n",
    "                dec_inp = y[i]\n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn = Seq2SeqRNN_TeacherForcing(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10), stepper=Seq2SeqStepper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.save('forcing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attentional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rand_t(*sz): return torch.randn(sz)/math.sqrt(sz[0])\n",
    "def rand_p(*sz): return nn.Parameter(rand_t(*sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqAttnRNN(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "\n",
    "        self.W1 = rand_p(nh, em_sz_dec)\n",
    "        self.l2 = nn.Linear(em_sz_dec, em_sz_dec)\n",
    "        self.l3 = nn.Linear(em_sz_dec+nh, em_sz_dec)\n",
    "        self.V = rand_p(em_sz_dec)\n",
    "\n",
    "    def forward(self, inp, y=None, ret_attn=False):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res,attns = [],[]\n",
    "        w1e = enc_out @ self.W1\n",
    "        for i in range(self.out_sl):\n",
    "            w2h = self.l2(h[-1])\n",
    "            u = F.tanh(w1e + w2h)\n",
    "            a = F.softmax(u @ self.V, 0)\n",
    "            attns.append(a)\n",
    "            Xa = (a.unsqueeze(2) * enc_out).sum(0)\n",
    "            emb = self.emb_dec(dec_inp)\n",
    "            wgt_enc = self.l3(torch.cat([emb, Xa], 1))\n",
    "            \n",
    "            outp, h = self.gru_dec(wgt_enc.unsqueeze(0), h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "            if (y is not None) and (random.random()<self.pr_force):\n",
    "                if i>=len(y): break\n",
    "                dec_inp = y[i]\n",
    "\n",
    "        res = torch.stack(res)\n",
    "        if ret_attn: res = res,torch.stack(attns)\n",
    "        return res\n",
    "\n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn = Seq2SeqAttnRNN(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr=2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=15, use_clr=(20,10), stepper=Seq2SeqStepper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.save('attn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.load('attn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs,attns = learn.model(V(x),ret_attn=True)\n",
    "preds = to_np(probs.max(2)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(180,190):\n",
    "    print(' '.join([fr_itos[o] for o in x[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o!=1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "attn = to_np(attns[...,180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(15, 10))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ax.plot(attn[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_All(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25, bidirectional=True)\n",
    "        self.out_enc = nn.Linear(nh*2, em_sz_dec, bias=False)\n",
    "        self.drop_enc = nn.Dropout(0.25)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "\n",
    "        self.W1 = rand_p(nh*2, em_sz_dec)\n",
    "        self.l2 = nn.Linear(em_sz_dec, em_sz_dec)\n",
    "        self.l3 = nn.Linear(em_sz_dec+nh*2, em_sz_dec)\n",
    "        self.V = rand_p(em_sz_dec)\n",
    "\n",
    "    def forward(self, inp, y=None):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = h.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(2,bs,-1)\n",
    "        h = self.out_enc(self.drop_enc(h))\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res,attns = [],[]\n",
    "        w1e = enc_out @ self.W1\n",
    "        for i in range(self.out_sl):\n",
    "            w2h = self.l2(h[-1])\n",
    "            u = F.tanh(w1e + w2h)\n",
    "            a = F.softmax(u @ self.V, 0)\n",
    "            attns.append(a)\n",
    "            Xa = (a.unsqueeze(2) * enc_out).sum(0)\n",
    "            emb = self.emb_dec(dec_inp)\n",
    "            wgt_enc = self.l3(torch.cat([emb, Xa], 1))\n",
    "            \n",
    "            outp, h = self.gru_dec(wgt_enc.unsqueeze(0), h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "            if (y is not None) and (random.random()<self.pr_force):\n",
    "                if i>=len(y): break\n",
    "                dec_inp = y[i]\n",
    "        return torch.stack(res)\n",
    "\n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl*2, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn = Seq2SeqRNN_All(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=15, use_clr=(20,10), stepper=Seq2SeqStepper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs = learn.model(V(x))\n",
    "preds = to_np(probs.max(2)[1])\n",
    "\n",
    "for i in range(180,190):\n",
    "    print(' '.join([fr_itos[o] for o in x[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o!=1]))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {
    "height": "253px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
