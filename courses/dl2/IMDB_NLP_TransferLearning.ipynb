{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T20:59:00.615164Z",
     "start_time": "2018-06-13T20:58:57.246921Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T20:59:00.630068Z",
     "start_time": "2018-06-13T20:59:00.627227Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = Path('data/aclImdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data in standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T20:59:03.444312Z",
     "start_time": "2018-06-13T20:59:03.439361Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clas_path = Path('data/imdb_clas/')\n",
    "os.makedirs(clas_path, exist_ok=True)\n",
    "\n",
    "lm_path = Path('data/imdb_lm/')\n",
    "os.makedirs(lm_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T17:49:08.547694Z",
     "start_time": "2018-06-13T17:48:56.687061Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['pos', 'neg', 'unsup']\n",
    "\n",
    "def get_text(path):\n",
    "    texts,labels = [],[]\n",
    "    for idx,label in enumerate(classes):\n",
    "        for fname in Path(path/label).glob('*.txt'):\n",
    "            texts.append(fname.open('r').read())\n",
    "            labels.append(idx)\n",
    "    return np.array(texts), np.array(labels)\n",
    "\n",
    "trn_texts, trn_labels = get_text(PATH/'train')\n",
    "val_texts, val_labels = get_text(PATH/'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T17:49:15.354767Z",
     "start_time": "2018-06-13T17:49:15.349678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 25000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_texts), len(val_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T17:49:17.652001Z",
     "start_time": "2018-06-13T17:49:17.645338Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_idxs = np.random.permutation(len(trn_texts))\n",
    "val_idxs = np.random.permutation(len(val_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T17:49:22.699638Z",
     "start_time": "2018-06-13T17:49:18.766261Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_texts = trn_texts[trn_idxs]\n",
    "trn_labels = trn_labels[trn_idxs]\n",
    "\n",
    "val_texts = val_texts[val_idxs]\n",
    "val_labels = val_labels[val_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T18:01:45.304241Z",
     "start_time": "2018-06-13T18:01:45.301246Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['labels','text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T17:49:24.723243Z",
     "start_time": "2018-06-13T17:49:23.470174Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_trn = pd.DataFrame({'text': trn_texts, 'labels': trn_labels}, columns=cols)\n",
    "df_val = pd.DataFrame({'text': val_texts, 'labels': val_labels}, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T17:53:15.402082Z",
     "start_time": "2018-06-13T17:53:13.928071Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove unsup labels for classifier\n",
    "df_trn[df_trn['labels'] != 2].to_csv(clas_path/'train.csv', header=False, index=False)\n",
    "df_val.to_csv(clas_path/'test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T17:54:45.397525Z",
     "start_time": "2018-06-13T17:54:45.392508Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save classes.txt \n",
    "(clas_path/'classes.txt').open('w').writelines(f'{o}\\n' for o in classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language Model  \n",
    "Language model doesn't need any labels and can be trained on combination of trn/val data.  Predicts next word only..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T18:00:16.627827Z",
     "start_time": "2018-06-13T18:00:02.280645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 10000)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_texts,val_texts = sklearn.model_selection.train_test_split(np.concatenate([trn_texts,val_texts]), test_size=0.1)\n",
    "len(trn_texts), len(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T18:03:39.278261Z",
     "start_time": "2018-06-13T18:03:32.861038Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_trn = pd.DataFrame({'text': trn_texts, 'labels': [0]*len(trn_texts)}, columns=cols)\n",
    "df_val = pd.DataFrame({'text': val_texts, 'labels': [0]*len(val_texts)}, columns=cols)\n",
    "\n",
    "df_trn.to_csv(lm_path/'train.csv', header=False, index=False)\n",
    "df_val.to_csv(lm_path/'test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T18:32:16.902809Z",
     "start_time": "2018-06-13T18:32:16.899152Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chunksize=24000\n",
    "\n",
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T18:32:17.489184Z",
     "start_time": "2018-06-13T18:32:17.482032Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T18:32:18.294152Z",
     "start_time": "2018-06-13T18:32:18.282123Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_texts(df, n_lbls=1):\n",
    "    labels = df.iloc[:,range(n_lbls)].values.astype(np.int64)\n",
    "    texts = f'\\n{BOS} {FLD} 1 ' + df[n_lbls].astype(str)\n",
    "    for i in range(n_lbls+1, len(df.columns)): texts += f' {FLD} {i-n_lbls} ' + df[i].astype(str)\n",
    "    texts = texts.apply(fixup).values.astype(str)\n",
    "\n",
    "    # process all multiprocessing -> parallelization\n",
    "    # partition_by_cores -> takes a list and splits into number of sublists = to number of cores in computer\n",
    "    tok = Tokenizer().proc_all_mp(partition_by_cores(texts))\n",
    "    return tok, list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T18:32:19.217176Z",
     "start_time": "2018-06-13T18:32:19.210035Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this loops through the chunks of the dataframe.  see *chunksize* below\n",
    "def get_all(df, n_lbls):\n",
    "    tok, labels = [], []\n",
    "    for i, r in enumerate(df):\n",
    "        print(i)\n",
    "        tok_, labels_ = get_texts(r, n_lbls)\n",
    "        tok += tok_;\n",
    "        labels += labels_\n",
    "    return tok, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T18:32:22.361287Z",
     "start_time": "2018-06-13T18:32:22.355208Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read csv one chunk at a time\n",
    "df_trn = pd.read_csv(lm_path/'train.csv', header=None, chunksize=chunksize)\n",
    "df_val = pd.read_csv(lm_path/'test.csv', header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T18:34:33.964336Z",
     "start_time": "2018-06-13T18:32:23.801894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "tok_trn, trn_labels = get_all(df_trn, 1)\n",
    "tok_val, val_labels = get_all(df_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T18:34:47.180559Z",
     "start_time": "2018-06-13T18:34:47.175237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n xbos xfld 1 before god awful pieces of trash like the punisher , there was another film that showed a man who \\'s wife was murdered by a gang and wanted justice , but wanted to deliver it in his own way . that film was death wish . and instead of a hero that did n\\'t seem to care too much about this killing ( though it was mostly just the actor , tom jane)we had the cool three dimensional charles bronson . you may ask yourself , \" three dimensional ? \" . and i say \" sure \" he cried about his wife before he went on to kill a great many scum bags on the streets of new york . the bottom line is that bronson was a bad ass in this film and all the rest of the death wish films which i also enjoy very much . we know that this movie will be great from the beginning when bronson cashes in a 20 dollar bill for two rolls of quarters so that he can stuff them in a sock and smash it across some dude \\'s face . it \\'s brilliant . they do n\\'t do they kind of raw action in movies anymore , and i guess that \\'s why this movie can be so refreshing even if it was made in the seventies . there \\'s no doubt that anyone who appreciates good action flicks with a bad ass main character will appreciate t_up this movie the way i do .'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(tok_trn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T18:37:31.340272Z",
     "start_time": "2018-06-13T18:37:20.927322Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(lm_path/'tmp').mkdir(exist_ok=True)\n",
    "\n",
    "np.save(lm_path/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(lm_path/'tmp'/'tok_val.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tok_trn = np.load(lm_path/'tmp'/'tok_trn.npy')\n",
    "# tok_val = np.load(lm_path/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numericalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T18:40:18.745360Z",
     "start_time": "2018-06-13T18:40:13.995658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1208855),\n",
       " ('.', 992627),\n",
       " (',', 986565),\n",
       " ('and', 588519),\n",
       " ('a', 584215),\n",
       " ('of', 525176),\n",
       " ('to', 485727),\n",
       " ('is', 394350),\n",
       " ('it', 342020),\n",
       " ('in', 337720),\n",
       " ('i', 308300),\n",
       " ('this', 270423),\n",
       " ('that', 261431),\n",
       " ('\"', 237416),\n",
       " (\"'s\", 221363),\n",
       " ('-', 188066),\n",
       " ('was', 180206),\n",
       " ('\\n\\n', 178828),\n",
       " ('as', 165606),\n",
       " ('with', 159370),\n",
       " ('for', 158626),\n",
       " ('movie', 157843),\n",
       " ('but', 150587),\n",
       " ('film', 144151),\n",
       " ('you', 124511)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# o - text, p - word\n",
    "freq = Counter(p for o in tok_trn for p in o)\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T18:54:20.299418Z",
     "start_time": "2018-06-13T18:54:20.296220Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_vocab=60000\n",
    "min_freq=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T18:55:46.639511Z",
     "start_time": "2018-06-13T18:55:46.462119Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itos = [word for word,count in freq.most_common(max_vocab) if count>min_freq]\n",
    "itos.insert(0, '_unk_')\n",
    "itos.insert(1, '_pad_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T18:58:12.014320Z",
     "start_time": "2018-06-13T18:58:11.982646Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stoi = collections.defaultdict(lambda: 0, {v:k for k,v in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T18:58:23.454526Z",
     "start_time": "2018-06-13T18:58:23.450149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T19:01:52.274677Z",
     "start_time": "2018-06-13T19:01:45.390907Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# call stoi for every word in every sentence\n",
    "trn_lm = np.array([[stoi[word] for word in sentence] for sentence in tok_trn])\n",
    "val_lm = np.array([[stoi[word] for word in sentence] for sentence in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T19:02:40.101884Z",
     "start_time": "2018-06-13T19:02:39.198464Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(lm_path/'tmp'/'trn_ids.npy', trn_lm)\n",
    "np.save(lm_path/'tmp'/'val_ids.npy', val_lm)\n",
    "pickle.dump(itos, open(lm_path/'tmp'/'itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T21:20:32.512322Z",
     "start_time": "2018-06-13T21:20:30.553632Z"
    }
   },
   "outputs": [],
   "source": [
    "trn_lm = np.load(lm_path/'tmp'/'trn_ids.npy')\n",
    "val_lm = np.load(lm_path/'tmp'/'val_ids.npy')\n",
    "itos = pickle.load(open(lm_path/'tmp'/'itos.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T21:20:51.311029Z",
     "start_time": "2018-06-13T21:20:51.305615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60002, 90000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs = len(itos)\n",
    "vs, len(trn_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load Wikitext103 pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T21:09:44.113715Z",
     "start_time": "2018-06-13T21:09:44.110401Z"
    }
   },
   "outputs": [],
   "source": [
    "em_sz,nh,nl = 400,1150,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T21:12:58.560123Z",
     "start_time": "2018-06-13T21:12:58.556461Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_path = PATH/'models'/'wt103'\n",
    "pre_lm_path = pre_path/'fwd_wt103.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T21:22:32.037538Z",
     "start_time": "2018-06-13T21:22:16.213995Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.encoder.weight',\n",
       "              tensor([[-1.2274e-01,  2.7886e-01, -3.8850e-01,  ..., -1.0404e-01,\n",
       "                        1.9580e-02,  1.8548e-01],\n",
       "                      [ 1.4854e-05, -2.3424e-05,  1.9693e-05,  ...,  2.1349e-05,\n",
       "                        2.1776e-05, -1.2394e-05],\n",
       "                      [ 1.8070e-01,  1.5874e+00, -1.1738e-01,  ..., -4.5935e-02,\n",
       "                       -8.1352e-02,  1.8054e-01],\n",
       "                      ...,\n",
       "                      [-1.8595e-03, -6.8529e-03,  1.6999e-03,  ...,  1.7039e-03,\n",
       "                        4.1632e-03, -1.3171e-03],\n",
       "                      [-2.3120e-03, -6.9001e-03,  1.8772e-03,  ...,  5.0309e-04,\n",
       "                        4.6596e-03, -2.5850e-03],\n",
       "                      [-2.2463e-03, -9.1512e-03,  1.3927e-03,  ...,  1.2296e-03,\n",
       "                        5.8085e-03, -1.8940e-03]])),\n",
       "             ('0.encoder_with_dropout.embed.weight',\n",
       "              tensor([[-1.2274e-01,  2.7886e-01, -3.8850e-01,  ..., -1.0404e-01,\n",
       "                        1.9580e-02,  1.8548e-01],\n",
       "                      [ 1.4854e-05, -2.3424e-05,  1.9693e-05,  ...,  2.1349e-05,\n",
       "                        2.1776e-05, -1.2394e-05],\n",
       "                      [ 1.8070e-01,  1.5874e+00, -1.1738e-01,  ..., -4.5935e-02,\n",
       "                       -8.1352e-02,  1.8054e-01],\n",
       "                      ...,\n",
       "                      [-1.8595e-03, -6.8529e-03,  1.6999e-03,  ...,  1.7039e-03,\n",
       "                        4.1632e-03, -1.3171e-03],\n",
       "                      [-2.3120e-03, -6.9001e-03,  1.8772e-03,  ...,  5.0309e-04,\n",
       "                        4.6596e-03, -2.5850e-03],\n",
       "                      [-2.2463e-03, -9.1512e-03,  1.3927e-03,  ...,  1.2296e-03,\n",
       "                        5.8085e-03, -1.8940e-03]])),\n",
       "             ('0.rnns.0.module.weight_ih_l0',\n",
       "              tensor([[-8.1208e-02, -8.1070e-02, -9.3667e-02,  ..., -2.5917e-02,\n",
       "                       -1.4032e-01, -3.2470e-01],\n",
       "                      [ 1.1539e-01,  1.1424e-01,  9.3782e-02,  ..., -7.1087e-02,\n",
       "                        1.6688e-01, -3.8713e-02],\n",
       "                      [-5.1495e-03,  1.0075e-01,  2.0714e-01,  ..., -8.5995e-02,\n",
       "                       -2.8766e-02, -8.9380e-02],\n",
       "                      ...,\n",
       "                      [ 5.4658e-03,  1.5655e-02,  2.9896e-01,  ...,  6.1618e-02,\n",
       "                        1.1594e-01, -4.7367e-01],\n",
       "                      [ 1.8077e-02,  4.2556e-02,  1.1295e-01,  ...,  3.5287e-01,\n",
       "                       -1.1401e-02, -1.2511e-02],\n",
       "                      [-1.6681e-02, -1.3277e-01,  1.7413e-01,  ...,  5.4776e-02,\n",
       "                       -4.5065e-03,  1.6884e-01]])),\n",
       "             ('0.rnns.0.module.bias_ih_l0',\n",
       "              tensor([ 0.1503, -0.4701, -0.1885,  ..., -0.5919, -0.2172, -0.1207])),\n",
       "             ('0.rnns.0.module.bias_hh_l0',\n",
       "              tensor([ 0.1503, -0.4701, -0.1885,  ..., -0.5919, -0.2172, -0.1207])),\n",
       "             ('0.rnns.0.module.weight_hh_l0_raw',\n",
       "              tensor([[-1.0128e-01,  1.7864e-01, -5.2847e-02,  ...,  7.4101e-02,\n",
       "                        3.0610e-02,  2.4666e-01],\n",
       "                      [ 1.7796e-01, -8.5314e-02, -2.4329e-02,  ..., -1.1286e-01,\n",
       "                       -1.3102e-01, -1.4975e-01],\n",
       "                      [ 6.6133e-02, -4.9570e-02,  9.2117e-02,  ...,  1.8295e-01,\n",
       "                        5.3332e-02, -1.5251e-01],\n",
       "                      ...,\n",
       "                      [-3.2194e-02, -7.0374e-02,  1.6533e-01,  ...,  2.1417e-01,\n",
       "                       -5.5782e-02,  3.1469e-02],\n",
       "                      [-1.6511e-01, -2.8984e-02,  1.7478e-01,  ..., -4.4581e-02,\n",
       "                        5.4444e-01,  6.1595e-02],\n",
       "                      [ 9.0453e-02, -1.7044e-01, -5.3422e-03,  ..., -5.7082e-03,\n",
       "                        2.2690e-01,  3.2815e-02]])),\n",
       "             ('0.rnns.1.module.weight_ih_l0',\n",
       "              tensor([[ 3.3072e-01,  3.8498e-02,  8.6008e-02,  ...,  6.8523e-02,\n",
       "                       -4.4404e-02,  5.3939e-02],\n",
       "                      [ 7.1970e-02,  1.6074e-01,  5.6188e-02,  ...,  2.7634e-02,\n",
       "                        6.1305e-02,  1.6321e-01],\n",
       "                      [-1.5653e-01, -1.1684e-01,  1.8969e-01,  ..., -3.5720e-02,\n",
       "                        2.9590e-02,  9.6059e-02],\n",
       "                      ...,\n",
       "                      [-8.9671e-02, -1.4640e-01, -7.6023e-02,  ...,  5.3618e-02,\n",
       "                        4.2188e-02, -5.7987e-02],\n",
       "                      [ 1.1660e-01, -1.5339e-01, -1.7843e-01,  ..., -6.8916e-02,\n",
       "                        2.1696e-01,  1.4607e-01],\n",
       "                      [-4.1288e-02,  6.8910e-02,  5.8062e-02,  ..., -6.4028e-02,\n",
       "                       -1.7028e-01, -9.4468e-02]])),\n",
       "             ('0.rnns.1.module.bias_ih_l0',\n",
       "              tensor([-0.8577, -0.6784, -0.7249,  ..., -0.6782,  0.0567, -0.5026])),\n",
       "             ('0.rnns.1.module.bias_hh_l0',\n",
       "              tensor([-0.8577, -0.6784, -0.7249,  ..., -0.6782,  0.0567, -0.5026])),\n",
       "             ('0.rnns.1.module.weight_hh_l0_raw',\n",
       "              tensor([[-2.7305e-02, -2.2773e-01,  7.8205e-02,  ...,  1.3548e-01,\n",
       "                       -1.2822e-01,  1.6686e-01],\n",
       "                      [ 1.2180e-01,  1.6703e-03, -9.9806e-02,  ..., -2.0854e-01,\n",
       "                       -6.8582e-02, -1.3887e-01],\n",
       "                      [-3.8784e-01, -4.9834e-02, -1.7484e-01,  ..., -4.0139e-01,\n",
       "                        1.9860e-01, -4.4002e-01],\n",
       "                      ...,\n",
       "                      [-2.0972e-01, -4.2982e-01,  3.5514e-01,  ...,  3.1637e-02,\n",
       "                       -1.1981e-01,  1.2664e-01],\n",
       "                      [ 3.7252e-03, -2.2282e-02,  3.1754e-03,  ..., -2.6722e-01,\n",
       "                       -3.0926e-01, -3.6104e-02],\n",
       "                      [-4.6356e-02,  1.6639e-01, -1.3476e-01,  ...,  1.6005e-01,\n",
       "                       -1.1384e-01,  8.4547e-02]])),\n",
       "             ('0.rnns.2.module.weight_ih_l0',\n",
       "              tensor([[-7.4091e-02,  4.4678e-02, -7.4389e-02,  ..., -4.1946e-02,\n",
       "                        1.5998e-01, -5.5267e-02],\n",
       "                      [ 2.6980e-02,  1.1813e-02,  4.4894e-02,  ...,  1.1648e-01,\n",
       "                       -1.0802e-01, -6.8053e-02],\n",
       "                      [-1.0232e-01, -1.6619e-01, -2.2867e-02,  ...,  1.6523e-01,\n",
       "                       -1.0696e-01,  9.6976e-02],\n",
       "                      ...,\n",
       "                      [-9.8934e-02, -4.4246e-01, -3.4288e-02,  ..., -1.4339e-01,\n",
       "                        5.8510e-01, -2.9106e-02],\n",
       "                      [ 8.0247e-02, -1.0668e-01,  2.7895e-01,  ..., -9.1596e-02,\n",
       "                       -2.2399e-01,  1.0198e-01],\n",
       "                      [-4.0775e-01,  7.2197e-01,  1.1417e-01,  ...,  5.2866e-01,\n",
       "                        2.0347e-01, -1.8112e-01]])),\n",
       "             ('0.rnns.2.module.bias_ih_l0',\n",
       "              tensor([-3.6805e-01, -9.0794e-01, -1.9982e-01,  ...,  8.5325e-01,\n",
       "                       3.2018e-01,  1.2172e+00])),\n",
       "             ('0.rnns.2.module.bias_hh_l0',\n",
       "              tensor([-3.6805e-01, -9.0792e-01, -1.9983e-01,  ...,  8.5325e-01,\n",
       "                       3.2018e-01,  1.2172e+00])),\n",
       "             ('0.rnns.2.module.weight_hh_l0_raw',\n",
       "              tensor([[-9.6611e-02,  2.3588e-02, -1.5181e-02,  ...,  3.8787e-02,\n",
       "                       -5.3053e-02, -3.9452e-02],\n",
       "                      [-3.2793e-02, -2.2166e-01,  2.8448e-03,  ...,  1.4332e-02,\n",
       "                       -3.6839e-02, -8.4808e-03],\n",
       "                      [ 1.6733e-02, -8.0697e-03, -5.6141e-02,  ...,  1.2456e-02,\n",
       "                        4.4213e-02, -1.3931e-02],\n",
       "                      ...,\n",
       "                      [-2.1206e-02, -1.0345e-01, -1.0618e-02,  ..., -5.6113e-02,\n",
       "                        1.9981e-02, -1.5685e-02],\n",
       "                      [ 1.8295e-02,  3.6436e-02, -2.5082e-02,  ..., -2.3954e-02,\n",
       "                       -1.1496e-01,  4.5665e-03],\n",
       "                      [ 9.9655e-03, -1.8239e-01,  1.0762e-01,  ..., -2.6931e-02,\n",
       "                        2.7332e-01,  1.8456e-01]])),\n",
       "             ('1.decoder.weight',\n",
       "              tensor([[-1.2274e-01,  2.7886e-01, -3.8850e-01,  ..., -1.0404e-01,\n",
       "                        1.9580e-02,  1.8548e-01],\n",
       "                      [ 1.4854e-05, -2.3424e-05,  1.9693e-05,  ...,  2.1349e-05,\n",
       "                        2.1776e-05, -1.2394e-05],\n",
       "                      [ 1.8070e-01,  1.5874e+00, -1.1738e-01,  ..., -4.5935e-02,\n",
       "                       -8.1352e-02,  1.8054e-01],\n",
       "                      ...,\n",
       "                      [-1.8595e-03, -6.8529e-03,  1.6999e-03,  ...,  1.7039e-03,\n",
       "                        4.1632e-03, -1.3171e-03],\n",
       "                      [-2.3120e-03, -6.9001e-03,  1.8772e-03,  ...,  5.0309e-04,\n",
       "                        4.6596e-03, -2.5850e-03],\n",
       "                      [-2.2463e-03, -9.1512e-03,  1.3927e-03,  ...,  1.2296e-03,\n",
       "                        5.8085e-03, -1.8940e-03]]))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgts = torch.load(pre_lm_path, map_location=lambda storage, loc: storage )\n",
    "wgts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T21:23:10.381559Z",
     "start_time": "2018-06-13T21:23:10.343468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238462, 400)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_wgts = to_np(wgts['0.encoder.weight'])\n",
    "row_mean = enc_wgts.mean(0)\n",
    "enc_wgts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T21:19:36.692274Z",
     "start_time": "2018-06-13T21:19:36.554699Z"
    }
   },
   "outputs": [],
   "source": [
    "wiki_itos = pickle.load((pre_path/'itos_wt103.pkl').open('rb'))\n",
    "wiki_stoi = collections.defaultdict(lambda: -1, {v:k for k,v in enumerate(wiki_itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T21:29:34.099774Z",
     "start_time": "2018-06-13T21:29:33.922554Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map weights from pretrained wikitext103 model onto our itos; filling unmatched values with the mean weight\n",
    "new_w = np.zeros((vs, em_sz), dtype=np.float32)\n",
    "for idx,word in enumerate(itos):\n",
    "    wiki_int = wiki_stoi[word]\n",
    "    new_w[idx] = enc_wgts[wiki_int] if wiki_int >= 0 else row_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T21:30:33.466556Z",
     "start_time": "2018-06-13T21:30:33.201242Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wgts['0.encoder.weight'] = T(new_w)\n",
    "# weight tying\n",
    "wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(new_w))\n",
    "wgts['1.decoder.weight'] = T(np.copy(new_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T21:33:46.890449Z",
     "start_time": "2018-06-13T21:33:46.886490Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wd = 1e-7\n",
    "bptt = 70\n",
    "bs = 52\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T21:36:43.148917Z",
     "start_time": "2018-06-13T21:36:40.582883Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)\n",
    "md = LanguageModelData(PATH, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T21:36:59.577301Z",
     "start_time": "2018-06-13T21:36:59.573819Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T21:42:05.093683Z",
     "start_time": "2018-06-13T21:42:05.075480Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'bias'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8780180ea16d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m learner= md.get_model(opt_fn, em_sz, nh, nl, \n\u001b[0;32m----> 2\u001b[0;31m     dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/DeepLearning/fastai/courses/dl2/fastai/text.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(self, opt_fn, emb_sz, n_hid, n_layers, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_language_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_tok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLanguageModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mRNN_Learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/DeepLearning/fastai/courses/dl2/fastai/lm_rnn.py\u001b[0m in \u001b[0;36mget_language_model\u001b[0;34m(n_tok, emb_sz, nhid, nlayers, pad_token, dropout, dropouth, dropouti, dropoute, wdrop, tie_weights, qrnn, bias)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     rnn_enc = RNN_Encoder(n_tok, emb_sz, nhid=nhid, nlayers=nlayers, pad_token=pad_token,\n\u001b[0;32m--> 236\u001b[0;31m                  dropouth=dropouth, dropouti=dropouti, dropoute=dropoute, wdrop=wdrop, qrnn=qrnn, bias=bias)\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtie_weights\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSequentialRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_tok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtie_encoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'bias'"
     ]
    }
   ],
   "source": [
    "learner= md.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "learner.metrics = [accuracy]\n",
    "learner.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "186px",
    "left": "1004px",
    "right": "20px",
    "top": "129px",
    "width": "408px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
