{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Prelims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.text import *\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PATH = Path('data/IAM_handwriting')\n",
    "TMP_PATH = PATH/'tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Loss and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def loss_prep(input, target):\n",
    "    \"equalize input/target sl; combine bs/sl dimensions\"\n",
    "    bs,tsl = target.shape\n",
    "    _ ,sl,vocab = input.shape\n",
    "        \n",
    "    # F.pad( front,back for dimensions: 1,0,2 )\n",
    "    if sl>tsl: target = F.pad(target, (0,sl-tsl))\n",
    "        \n",
    "    # this should only be used when testing for small seq_lens\n",
    "    # if tsl>sl: target = target[:,:sl]\n",
    "    \n",
    "    if tsl>sl: input = F.pad(input, (0,0,0,tsl-sl))\n",
    "    # not ideal => adds 82 logits all 0s...\n",
    "        \n",
    "    targ = target.contiguous().view(-1).long()\n",
    "    pred = input.contiguous().view(-1, vocab)\n",
    "    return pred, targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        pred,targ = loss_prep(pred, target)\n",
    "        pred = F.log_softmax(pred, dim=-1)  # need this for KLDivLoss\n",
    "        true_dist = pred.data.clone()\n",
    "        true_dist.fill_(self.smoothing / pred.size(1))                  # fill with 0.0012\n",
    "        true_dist.scatter_(1, targ.data.unsqueeze(1), self.confidence)  # [0.0012, 0.0012, 0.90, 0.0012]\n",
    "        return F.kl_div(pred, true_dist, reduction='sum')/bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import Levenshtein as Lev\n",
    "\n",
    "class CER(Callback):\n",
    "    def __init__(self, itos):\n",
    "        super().__init__()\n",
    "        self.name = 'cer'\n",
    "        self.itos = itos\n",
    "\n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.errors, self.total = 0, 0\n",
    "    \n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        error,size = self._cer(last_output, last_target)\n",
    "        self.errors += error\n",
    "        self.total += size\n",
    "    \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        return add_metrics(last_metrics, self.errors/self.total)\n",
    "\n",
    "    def _cer(self, preds, targs):\n",
    "        bs,sl = targs.size()\n",
    "        \n",
    "        res = torch.argmax(preds, dim=2)\n",
    "        error = 0\n",
    "        for i in range(bs):\n",
    "            p = self._char_label_text(res[i])   #.replace(' ', '')\n",
    "            t = self._char_label_text(targs[i]) #.replace(' ', '')\n",
    "            error += Lev.distance(t, p)/len(t)\n",
    "        return error, bs\n",
    "\n",
    "    def _char_label_text(self, pred):\n",
    "#         return self.sp.DecodeIds(pred.tolist())\n",
    "        ints = to_np(pred).astype(int)\n",
    "        nonzero = ints[np.nonzero(ints)]\n",
    "        return ''.join([self.itos[i] for i in nonzero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rshift(tgt, bos_token=1):\n",
    "    \"Shift y to the right by prepending token\"\n",
    "    bos = torch.zeros((tgt.size(0),1), device=device).type_as(tgt) + bos_token\n",
    "    return torch.cat((bos, tgt[:,:-1]), dim=-1)\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    return torch.tril(torch.ones((size,size), device=device).byte()).unsqueeze(0)\n",
    "\n",
    "class TeacherForce(LearnerCallback):\n",
    "    def __init__(self, learn:Learner, bos_token:int=1):\n",
    "        super().__init__(learn)\n",
    "        self.bos_token = bos_token\n",
    "        \n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        s = rshift(last_target, self.bos_token).long()\n",
    "        mask = subsequent_mask(s.size(-1))\n",
    "        return {'last_input':(last_input, s, mask), 'last_target':last_target}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sm synth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname = 'edited_sm_synth.csv' #'small_synth_words.csv'\n",
    "CSV = PATH/fname\n",
    "FOLDER = 'edited_sm_synth'\n",
    "\n",
    "df = pd.read_csv(CSV)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sz,bs = 128,100\n",
    "# sz,bs = 256,100\n",
    "\n",
    "seq_len = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Concat Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nums = '3-6'   #'7-10'  #'11-14'\n",
    "CSV = PATH/f'cat_lines_{nums}.csv'\n",
    "FOLDER = 'resized_cat_lines'\n",
    "\n",
    "csv = pd.read_csv(CSV)\n",
    "test = pd.read_csv(PATH/'test_pg.csv')\n",
    "\n",
    "len(csv), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lengths = np.array([len(i.split(' ')) for i in csv.char_ids.values])\n",
    "lengths.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sz,bs = 512,20   #1000,5  #800,8   #512,20\n",
    "seq_len = 600 #600 #450  #300\n",
    "stats = (np.array([0.941, 0.941, 0.941], dtype=np.float32), np.array([0.128, 0.128, 0.128], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Concat All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = pd.read_csv(PATH/'cat_lines_3.csv').sample(1000)\n",
    "b = pd.read_csv(PATH/'cat_lines_4.csv').sample(1000)\n",
    "c = pd.read_csv(PATH/'cat_lines_5.csv').sample(1000)\n",
    "d = pd.read_csv(PATH/'cat_lines_6.csv').sample(1000)\n",
    "e = pd.read_csv(PATH/'cat_lines_7.csv').sample(1000)\n",
    "f = pd.read_csv(PATH/'cat_lines_8.csv').sample(1000)\n",
    "g = pd.read_csv(PATH/'cat_lines_9.csv').sample(1000)\n",
    "h = pd.read_csv(PATH/'cat_lines_10.csv').sample(1000)\n",
    "i = pd.read_csv(PATH/'cat_lines_11.csv').sample(1000)\n",
    "j = pd.read_csv(PATH/'cat_lines_12.csv').sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "k = pd.read_csv(PATH/'paragraph_chars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_idxs = np.array(k.sample(frac=0.15, random_state=42).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn = k[~k.index.isin(val_idxs)]\n",
    "test = k[k.index.isin(val_idxs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new = pd.concat([a,b,c,d,e,f,g,h,i,j,trn], ignore_index=True)\n",
    "len(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# new.to_csv(PATH/'cat_lines_pg.csv', index=False)\n",
    "# test.to_csv(PATH/'test_pg.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname = 'edited_pg.csv' #'paragraphs.csv'\n",
    "CSV = PATH/fname\n",
    "FOLDER = 'paragraphs'\n",
    "\n",
    "df = pd.read_csv(CSV)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sz,bs = 1000,5  #1024,5  #1000,5   #~2000x1000 full size\n",
    "# sz,bs = 800,8\n",
    "sz,bs = 512,10\n",
    "\n",
    "seq_len = 700   #~400 chars/paragraph - max: 705\n",
    "# stats = (np.array([0.941, 0.941, 0.941], dtype=np.float32), np.array([0.128, 0.128, 0.128], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Downloaded Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CSV = PATH/'downloaded_images.csv'\n",
    "FOLDER = 'downloaded_images'\n",
    "\n",
    "csv = pd.read_csv(CSV)\n",
    "len(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# csv['filename'] = csv['filename'].apply(lambda x: f\"dl_{x}\")\n",
    "# csv.head()\n",
    "# csv.to_csv(CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sz,bs = 1000,5  #1024,5  #1000,5   #~2000x1000 full size\n",
    "# sz,bs = 800,8\n",
    "sz,bs = 512,20\n",
    "\n",
    "seq_len = 700   #~400 chars/paragraph - max: 705\n",
    "stats = (np.array([0.941, 0.941, 0.941], dtype=np.float32), np.array([0.128, 0.128, 0.128], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname = 'test_pg.csv'\n",
    "CSV = PATH/fname\n",
    "FOLDER = 'paragraphs'\n",
    "\n",
    "df = pd.read_csv(CSV)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sz,bs = 512,15\n",
    "\n",
    "seq_len = 700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname = 'mix.csv'\n",
    "CSV = PATH/fname\n",
    "FOLDER = 'mix'\n",
    "\n",
    "df = pd.read_csv(CSV)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sz,bs = 512,15\n",
    "# sz,bs = 400,20\n",
    "\n",
    "seq_len = 800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tfms = get_transforms(do_flip=False, max_zoom=1, max_rotate=2.0, max_warp=0.1)\n",
    "tfms = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def label_collater(samples:BatchSamples, pad_idx:int=0):\n",
    "    \"Function that collect samples and pads end of labels.\"\n",
    "    data = to_data(samples)\n",
    "    ims, lbls = zip(*data)\n",
    "    imgs = torch.stack(list(ims))\n",
    "    if len(data) is 1:\n",
    "        labels = torch.zeros(1,1).long()\n",
    "        return imgs, labels\n",
    "    max_len = max([len(s) for s in lbls])\n",
    "    labels = torch.zeros(len(data), max_len).long() + pad_idx\n",
    "    for i,lbl in enumerate(lbls):\n",
    "        labels[i,:len(lbl)] = torch.from_numpy(lbl)  #padding end    \n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SPMProcessor(PreProcessor):\n",
    "    def __init__(self, ds:ItemList=None):\n",
    "        self.sp = ds.sp if ds is not None else None\n",
    "\n",
    "    def process_one(self,item): return self.sp.EncodeAsIds(item)\n",
    "    def process(self, ds): super().process(ds)\n",
    "    \n",
    "class SPMList(ItemList):\n",
    "    _processor = [SPMProcessor]\n",
    "\n",
    "    def __init__(self, items:Iterator, sp_processor, **kwargs):\n",
    "        super().__init__(items, **kwargs)\n",
    "        self.sp = sp_processor\n",
    "        self.copy_new += ['sp']\n",
    "\n",
    "    def get(self, i):\n",
    "        o = super().get(i)\n",
    "        return Text(o, self.sp.DecodeIds(o))\n",
    "\n",
    "    def reconstruct(self, t:Tensor):\n",
    "        return Text(t, self.sp.DecodeIds(t.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(PATH/'spm_train.model'))\n",
    "sp.SetEncodeExtraOptions(\"bos:eos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = (ImageList.from_df(df, path=PATH, folder=FOLDER)\n",
    "        .split_by_rand_pct(valid_pct=0.15, seed=42)\n",
    "        .label_from_df(label_cls=SPMList, sp_processor=sp)\n",
    "        .transform(tfms, size=sz, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=bs, device=device, collate_fn=label_collater)\n",
    "        .normalize()\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "itos = pickle.load(open(PATH/'itos.pkl', 'rb'))  #'char_itos.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class CharTokenizer():\n",
    "    def __init__(self, n_cpus:int=None):\n",
    "        self.n_cpus = ifnone(n_cpus, defaults.cpus)\n",
    "\n",
    "    def tokenize(self, t:str): return ['xxbos']+list(t)+['xxeos']\n",
    "\n",
    "    def _process_all_1(self, texts:Collection[str]) -> List[List[str]]:\n",
    "        \"Process a list of `texts` in one process.\"\n",
    "        return [self.tokenize(str(t)) for t in texts]\n",
    "\n",
    "    def process_all(self, texts:Collection[str]) -> List[List[str]]:\n",
    "        \"Process a list of `texts`.\"\n",
    "        if self.n_cpus <= 1: return self._process_all_1(texts)\n",
    "        with ProcessPoolExecutor(self.n_cpus) as e:\n",
    "            return sum(e.map(self._process_all_1, partition_by_cores(texts, self.n_cpus)), [])\n",
    "\n",
    "class CharVocab(Vocab):\n",
    "    def __init__(self, itos:Collection[str]):\n",
    "        self.itos = itos\n",
    "        self.stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(self.itos)})\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=''):\n",
    "        nums = nums[1:-1]  #remove bos,eos tokens\n",
    "        return sep.join([self.itos[i] for i in nums]) if sep is not None else [self.itos[i] for i in nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def reverse_image(image): return PIL.ImageOps.invert(image)\n",
    "\n",
    "vocab = CharVocab(itos)\n",
    "procs = [TokenizeProcessor(tokenizer=CharTokenizer(), include_bos=False),\n",
    "         NumericalizeProcessor(vocab=vocab)]\n",
    "\n",
    "data = (ImageList.from_df(df, path=PATH, folder=FOLDER, after_open=reverse_image)\n",
    "        #.split_none()\n",
    "        .split_by_rand_pct(valid_pct=0.15, seed=42)\n",
    "        .label_from_df(label_cls=TextList, sep='', pad_idx=0, vocab=vocab, processor=procs)\n",
    "        .transform(tfms, size=sz, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=bs, device=device, collate_fn=label_collater)\n",
    "        .normalize()\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SequenceList (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df['lens'] = df.label.map(len)\n",
    "# df.sort_values('lens', ascending=False, inplace=True)\n",
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "itos = pickle.load(open(PATH/'itos.pkl', 'rb'))  #'char_itos.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SequenceItem(ItemBase):\n",
    "    def __init__(self,data,vocab): self.data,self.vocab = data,vocab        \n",
    "    def __str__(self): return self.textify(self.data)\n",
    "    def __hash__(self): return hash(str(self))\n",
    "    def textify(self, data): return ''.join([self.vocab[i] for i in data[:-1]])\n",
    "        \n",
    "class ArrayProcessor(PreProcessor):\n",
    "    \"Convert df column (string of ints) into np.array\"\n",
    "    def __init__(self, ds:ItemList=None): None\n",
    "    def process_one(self,item): return np.array(item.split(), dtype=np.int64)\n",
    "    def process(self, ds): super().process(ds)\n",
    "        \n",
    "class ItosProcessor(PreProcessor):\n",
    "    def __init__(self, ds:ItemList=None): self.itos = ds.itos\n",
    "    def process(self, ds:ItemList): ds.itos = self.itos\n",
    "        \n",
    "class SequenceList(ItemList):\n",
    "    _processor = [ItosProcessor, ArrayProcessor]\n",
    "    \n",
    "    def __init__(self, items:Iterator, itos:List[str]=None, **kwargs):\n",
    "        super().__init__(items, **kwargs)\n",
    "        self.itos = itos\n",
    "        self.copy_new += ['itos']\n",
    "        self.c = len(self.items)\n",
    "\n",
    "    def get(self, i):\n",
    "        o = super().get(i)\n",
    "        return SequenceItem(o, self.itos)\n",
    "\n",
    "    def reconstruct(self,t):\n",
    "        # Converting padded tensor back into np.array\n",
    "        o = t.numpy()\n",
    "        o = o[np.nonzero(o)]                  # remove 0 padding\n",
    "        return SequenceItem(o, self.itos)\n",
    "    \n",
    "    def analyze_pred(self,pred):\n",
    "        return torch.argmax(pred, dim=-1)\n",
    "        # method called in learn.predict() or learn.show_results()\n",
    "        # to transform predictions in an output tensor suitable for reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = (ImageList.from_df(df, path=PATH, folder=FOLDER)\n",
    "        .split_by_rand_pct(valid_pct=0.15, seed=42)\n",
    "        .label_from_df(label_cls=SequenceList, itos=itos)\n",
    "        .transform(tfms, size=sz, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=bs, device=device, collate_fn=custom_collater)\n",
    "        .normalize()\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # This slows down training...\n",
    "# class CustomSampler(Sampler):\n",
    "#     \"sort dataset by longest y sequences\"\n",
    "#     def __init__(self, dataset):\n",
    "#         self.dataset = dataset\n",
    "#         self.lengths = [len(i) for i in dataset.y.items]\n",
    "#         self.sorted_idxs = np.flip(np.argsort(self.lengths))\n",
    "#     def __len__(self): return len(self.dataset)\n",
    "#     def __iter__(self): return iter(self.sorted_idxs)\n",
    "\n",
    "# ds = data.train_ds\n",
    "# tfms = data.train_dl.tfms\n",
    "# sampler = CustomSampler(ds)\n",
    "# dl = DataLoader(ds, bs, shuffle=False, sampler=sampler, num_workers=num_cpus(), collate_fn=custom_collater, drop_last=True)\n",
    "# ddl = DeviceDataLoader(dl, device, tfms, custom_collater)\n",
    "# data.train_dl = ddl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.batch_stats()\n",
    "# no normalization: [tensor([0.9403, 0.9403, 0.9403]), tensor([0.1604, 0.1604, 0.1604])]\n",
    "# imagenet_stats:   [tensor([1.9973, 2.1714, 2.3839]), tensor([0.6974, 0.7130, 0.7098])]\n",
    "# normalize():      [tensor([0.0225, 0.0225, 0.0225]), tensor([0.9676, 0.9676, 0.9676])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.show_batch(rows=2, ds_type=DatasetType.Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Transformer Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "LayerNorm = partial(nn.LayerNorm, eps=1e-4)  # accomodates mixed precision training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"A residual connection followed by a layer norm.  Note: (for code simplicity) norm is first.\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder: self-attn and feed forward\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, src, tgt_mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder: self-attn, src-attn, and feed forward\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)  # wraps layer in residual,dropout,norm\n",
    " \n",
    "    def forward(self, x, src, tgt_mask=None):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, src, src))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    depth = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(depth)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e4)  #changed from: -1e9 to accomodate mixed precision  \n",
    "    p_attn = F.softmax(scores, dim=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SingleHeadedAttention(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.2):\n",
    "        super(SingleHeadedAttention, self).__init__()\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):        \n",
    "        query, key, value = [l(x) for l, x in zip(self.linears, (query, key, value))]\n",
    "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, d_model, h=8, dropout=0.2):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        self.d_k = d_model // h        # assume d_v always equals d_k\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        if mask is not None: mask = mask.unsqueeze(1)\n",
    "        bs = q.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        q, k, v = [l(x).view(bs, -1, self.h, self.d_k).transpose(1,2) for l, x in zip(self.linears, (q, k, v))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(q, k, v, mask=mask, dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous().view(bs, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class GeLU(nn.Module):\n",
    "    def forward(self, x): return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.2):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_model*4)\n",
    "        self.w_2 = nn.Linear(d_model*4, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = GeLU() #nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(self.activation(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=2000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0.0, max_len).unsqueeze(1)\n",
    "        log_increment = math.log(1e4) / d_model\n",
    "        div_term = torch.exp(torch.arange(0.0, d_model, 2) * -log_increment)  \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe.unsqueeze_(0)\n",
    "\n",
    "        self.register_buffer('pe', pe)    #(1,max_len,d_model)\n",
    "        # registered buffers are Tensors (not Variables)\n",
    "        # not a parameter but still want in the state_dict\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, tgt, tgt_mask=None):\n",
    "        return self.decode(self.encode(src), tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src):\n",
    "        return self.encoder(src)\n",
    "    \n",
    "    def decode(self, src, tgt, tgt_mask=None):\n",
    "        return self.decoder(self.tgt_embed(tgt), src, tgt_mask)\n",
    "    \n",
    "    def generate(self, outs):\n",
    "        return self.generator(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ResnetBase(nn.Module):\n",
    "    def __init__(self, em_sz, d_model):\n",
    "        super().__init__()\n",
    "        \n",
    "        slices = {128: -4, 256: -3, 512: -2}\n",
    "        s = slices[em_sz]\n",
    "\n",
    "        net = models.resnet34(False)\n",
    "        modules = list(net.children())[:s]\n",
    "        self.base = nn.Sequential(*modules)\n",
    "        \n",
    "        self.linear = nn.Linear(em_sz, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.base(x).flatten(2,3).permute(0,2,1)\n",
    "        x = self.linear(x) * 8\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_full_model(vocab, d_model, N=4, drops=0.2):\n",
    "    c = deepcopy\n",
    "    attn = SingleHeadedAttention(d_model)\n",
    "#     attn = MultiHeadedAttention(d_model, 4)\n",
    "    ff = PositionwiseFeedForward(d_model, drops)\n",
    "\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), drops), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), drops), N),\n",
    "        nn.Sequential(\n",
    "            Embeddings(d_model, vocab), PositionalEncoding(d_model, drops, 2000)\n",
    "        ),\n",
    "        nn.Linear(d_model, vocab),\n",
    "    )\n",
    "        \n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "                    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Img2Seq(nn.Module):\n",
    "    def __init__(self, img_encoder, transformer, seq_len=500):\n",
    "        super(Img2Seq, self).__init__()\n",
    "        self.img_enc = img_encoder\n",
    "        self.transformer = transformer\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    def forward(self, src, tgt=None, tgt_mask=None):\n",
    "        # inference (greedy decode)\n",
    "        if tgt is None:\n",
    "            with torch.no_grad():\n",
    "                feats = self.transformer.encode(self.img_enc(src))\n",
    "                bs = src.size(0)\n",
    "                tgt = torch.ones((bs,1), dtype=torch.long, device=device)\n",
    "\n",
    "                res = []\n",
    "                for i in progress_bar(range(self.seq_len)):\n",
    "                    mask = subsequent_mask(tgt.size(-1))\n",
    "                    dec_outs = self.transformer.decode(feats, tgt, mask)\n",
    "                    prob = self.transformer.generate(dec_outs[:,-1])\n",
    "                    res.append(prob)\n",
    "                    pred = torch.argmax(prob, dim=-1, keepdim=True)\n",
    "                    if (pred==0).all(): break\n",
    "                    tgt = torch.cat([tgt,pred], dim=-1)\n",
    "                out = torch.stack(res).transpose(1,0).contiguous()\n",
    "                \n",
    "        #training\n",
    "        else:\n",
    "            feats = self.img_enc(src)\n",
    "            dec_outs = self.transformer(feats, tgt, tgt_mask)    # ([bs, sl, d_model])\n",
    "            out = self.transformer.generate(dec_outs)            # ([bs, sl, vocab])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "em_sz = 256\n",
    "img_encoder = ResnetBase(em_sz, d_model)\n",
    "transformer = make_full_model(len(itos), d_model)  #len(itos)\n",
    "net = Img2Seq(img_encoder, transformer, seq_len)\n",
    "\n",
    "# AdamW16 = partial(optim.Adam, betas=(0.9,0.99), eps=1e-4)  ->  #.to_fp16(max_scale=256)\n",
    "# partial: way to always call a function with a given set of arguments or keywords\n",
    "\n",
    "learn = Learner(data, net, loss_func=LabelSmoothing(smoothing=0.1),\n",
    "                metrics=[CER(itos)], callback_fns=TeacherForce)\n",
    "learn.clip_grad(0.25)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# DenseNet Arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, tgt, tgt_mask=None):\n",
    "        return self.decode(self.encode(src), tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src):\n",
    "        return self.encoder(src)\n",
    "    \n",
    "    def decode(self, src, tgt, tgt_mask=None):\n",
    "        return self.decoder(self.tgt_embed(tgt), src, tgt_mask)\n",
    "    \n",
    "    def generate(self, outs):\n",
    "        return self.generator(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torchvision.models import mobilenet_v2, densenet201, densenet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "net = densenet201(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def replace_pooling_layers(m):\n",
    "    # replace MaxPool2d w/ AdaptiveAvgPool2d\n",
    "    pool_layers = [i for i,o in enumerate(m.modules()) if isinstance(o,nn.MaxPool2d)]\n",
    "    conv_outs = [m[i-3].out_channels for i in pool_layers]\n",
    "\n",
    "    for c,o in zip(pool_layers, conv_outs):\n",
    "        m[c] = nn.AdaptiveAvgPool2d(o)\n",
    "    return m\n",
    "\n",
    "\n",
    "# find all the layers before maxpool layers -> typically the best representation available at that grid size\n",
    "block_ends = [i-1 for i,o in enumerate(children(m_vgg)) if isinstance(o,nn.AdaptiveAvgPool2d)]\n",
    "block_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "head = Lambda(lambda x: pdb.set_trace())\n",
    "\n",
    "m = nn.Sequential(*list(children(net)[0]), head)\n",
    "# m = nn.Sequential(*flatten_model(net)[:-1], head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i,layer in enumerate(m):\n",
    "    if isinstance(layer, nn.AvgPool2d):\n",
    "        print(layer, i)\n",
    "#         m[i] = nn.AvgPool2d((2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m[5][3] = nn.AvgPool2d((2,1))\n",
    "# bs, 1920, 4, 32 => [5,7,9][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l = Learner(data, m, loss_func=LabelSmoothing(smoothing=0.1))\n",
    "l.fit_one_cycle(1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i,layer in enumerate(list(net.modules())):\n",
    "    if isinstance(layer, nn.AvgPool2d): print(layer, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for layer in list(net.features):\n",
    "    if isinstance(layer, nn.AvgPool2d): print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class CNNBase(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "\n",
    "        net = densenet201(True)\n",
    "        modules = list(net.children())[0] #[:-3]\n",
    "        # [0] => bs,1920,4,4\n",
    "        self.base = nn.Sequential(*modules)\n",
    "        \n",
    "        self.linear = nn.Linear(1920, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = x.flatten(2,3).permute(0,2,1)\n",
    "        x = self.linear(x) #* 2 #8\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_full_model(vocab, d_model, N=4, drops=0.2):\n",
    "    c = deepcopy\n",
    "    attn = SingleHeadedAttention(d_model)\n",
    "#     attn = MultiHeadedAttention(d_model, 4)\n",
    "    ff = PositionwiseFeedForward(d_model, drops)\n",
    "\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), drops), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), drops), N),\n",
    "        nn.Sequential(\n",
    "            Embeddings(d_model, vocab), PositionalEncoding(d_model, drops, 2000)\n",
    "        ),\n",
    "        nn.Linear(d_model, vocab),\n",
    "    )\n",
    "        \n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "                    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Img2Seq(nn.Module):\n",
    "    def __init__(self, img_encoder, transformer, seq_len=500):\n",
    "        super(Img2Seq, self).__init__()\n",
    "        self.img_enc = img_encoder\n",
    "        self.transformer = transformer\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    def forward(self, src, tgt=None, tgt_mask=None):\n",
    "        # inference (greedy decode)\n",
    "        if tgt is None:\n",
    "            with torch.no_grad():\n",
    "                feats = self.transformer.encode(self.img_enc(src))\n",
    "                bs = src.size(0)\n",
    "                tgt = torch.ones((bs,1), dtype=torch.long, device=device)\n",
    "\n",
    "                res = []\n",
    "                for i in progress_bar(range(self.seq_len)):\n",
    "                    mask = subsequent_mask(tgt.size(-1))\n",
    "                    dec_outs = self.transformer.decode(feats, tgt, mask)\n",
    "                    prob = self.transformer.generate(dec_outs[:,-1])\n",
    "                    res.append(prob)\n",
    "                    pred = torch.argmax(prob, dim=-1, keepdim=True)\n",
    "                    if (pred==0).all(): break\n",
    "                    tgt = torch.cat([tgt,pred], dim=-1)\n",
    "                out = torch.stack(res).transpose(1,0).contiguous()\n",
    "                \n",
    "        #training\n",
    "        else:\n",
    "            feats = self.img_enc(src)\n",
    "            dec_outs = self.transformer(feats, tgt, tgt_mask)    # ([bs, sl, d_model])\n",
    "            out = self.transformer.generate(dec_outs)            # ([bs, sl, vocab])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "\n",
    "img_encoder = CNNBase(d_model)\n",
    "transformer = make_full_model(len(itos), d_model)\n",
    "net = Img2Seq(img_encoder, transformer, seq_len)\n",
    "\n",
    "# AdamW16 = partial(optim.Adam, betas=(0.9,0.99), eps=1e-4)  ->  #.to_fp16(max_scale=256)\n",
    "# AMSGrad = partial(optim.Adam, amsgrad=True, eps=1e-4)\n",
    "# partial: way to always call a function with a given set of arguments or keywords\n",
    "\n",
    "learn = Learner(data, net, loss_func=LabelSmoothing(smoothing=0.1),\n",
    "                metrics=[CER(itos)], callback_fns=TeacherForce)\n",
    "learn.clip_grad(0.25)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(3, max_lr=1e-3)\n",
    "# 3 cycles; 1e-3\n",
    "# sm_synth, sz:128, bs: 100\n",
    "# 15.269251\t13.785835\t0.106348   base arch - (gelu, single attn, pre-resnet34)\n",
    "# 16.347567\t14.436943\t0.111617   \"\", reversed images - doesn't perform well from pretraining???\n",
    "#     normal images, resnet34 (no pretraining)\n",
    "# 25.128386\t21.791134\t0.185044   reversed_images, resnet34 (no pretraining) - not sure what the initialization is like yet...\n",
    "#    densenet201 (no pretraining)\n",
    "#    modified densenet201\n",
    "#    pre-densenet201\n",
    "\n",
    "\n",
    "\n",
    "### Training - Edited Data - GeLU, singlehead attn\n",
    "# sm\n",
    "# 10.841042\t9.550449\t0.071475   sz:128, bs:100, lr:1e-3  'v1_gelu_128'\n",
    "# 2.631370\t2.669811\t0.020308   sz:256, bs:100, lr:1e-3  'v1_gelu_256'\n",
    "# mix\n",
    "# 18.652050\t14.330537\t0.021167   sz:400, bs:20, lr:1e-3   'v1_edited_gelu_400'\n",
    "# 11.513125\t8.577786\t0.016521   sz:512, bs:15, lr:5e-5, 3cycle   'v1_edited_gelu_512'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('v1_edited_gelu_512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# learn = load_learner(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "k=16\n",
    "\n",
    "def torch_scale_attns(attns):\n",
    "    bs,sl,hw = attns.shape\n",
    "    num = int(math.sqrt(hw))   # sz // k\n",
    "    mod = attns.view(bs,sl,num,num)\n",
    "    scaled = F.interpolate(mod, size=sz)\n",
    "    return scaled  #([bs, sl, h, w])\n",
    "\n",
    "def g_filter(att):\n",
    "    return gaussian_filter(att, sigma=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def self_attn(layer=-1): return learn.model.transformer.decoder.layers[layer].self_attn.attn.data.cpu()\n",
    "def source_attn(layer=-1): return learn.model.transformer.decoder.layers[layer].src_attn.attn.data.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cer(preds, targs):\n",
    "    bs,sl = targs.size()\n",
    "    \n",
    "    res = torch.argmax(preds, dim=2)\n",
    "    error = 0\n",
    "    for i in range(bs):\n",
    "        p = char_label_text(res[i])   #.replace(' ', '')\n",
    "        t = char_label_text(targs[i]) #.replace(' ', '')\n",
    "        error += Lev.distance(t, p)/len(t)\n",
    "    return error/bs\n",
    "\n",
    "def char_label_text(pred):\n",
    "#     return sp.DecodeIds(pred.tolist())\n",
    "    ints = to_np(pred).astype(int)\n",
    "    nonzero = ints[np.nonzero(ints)]\n",
    "    return ''.join([itos[i] for i in nonzero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None, alpha=None, title=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    if im.shape[0] == 3: im = image2np(im.data)\n",
    "    ax.imshow(im, alpha=alpha)\n",
    "    if title: ax.set_title(title)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(learn.data.train_dl))\n",
    "# x,y = learn.data.one_batch(ds_type=DatasetType.Train)\n",
    "imgs = learn.data.denorm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Uploaded Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def thresh_edit(fname, thresh=100, bg=245):\n",
    "    im = Image.open(fname).convert('L')  #grayscale\n",
    "    np_im = np.array(im)\n",
    "    im.close()\n",
    "    thresh_mask = np_im > thresh\n",
    "    np_im[thresh_mask] = bg\n",
    "    return Image.fromarray(np_im, 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "im = thresh_edit(PATH/'test3.png')\n",
    "show_img(im, figsize=(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "e = 'edit_'+str(fname.name)\n",
    "edited_fname = PATH/e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "edited_im.save(edited_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname = PATH/'test/edit_test4.png'\n",
    "im = open_image(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seq,res,preds = learn.predict(im)\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# r = torch.tensor([g_res], dtype=torch.long, device=device)\n",
    "truth = \"This is a test letter. I hope this\\nworks but I'm not sure it will.\\nMy handwriting is not very good.\"\n",
    "Lev.distance(truth, str(seq))/len(truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# x,y = next(v_dl)\n",
    "# imgs = denorm(x)\n",
    "\n",
    "learn.model.eval()\n",
    "\n",
    "shifted_y = rshift(y).long()\n",
    "tgt_mask = subsequent_mask(shifted_y.size(-1))\n",
    "v_preds = learn.model(x, shifted_y, tgt_mask)\n",
    "v_res = torch.argmax(v_preds, dim=-1)\n",
    "# v_attn = source_attn()\n",
    "\n",
    "g_preds = learn.model(x)\n",
    "g_res = torch.argmax(g_preds, dim=-1)\n",
    "# g_attn = source_attn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "v = [learn.loss_func(v_preds, y).item(), cer(v_preds, y)]\n",
    "print(f'valid:     {str(v[0])[:7]}   {str(v[1])[:7]}')\n",
    "\n",
    "g = [learn.loss_func(g_preds, y).item(), cer(g_preds, y)]\n",
    "print(f'greedy:    {str(g[0])[:7]}   {str(g[1])[:7]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#valid\n",
    "fig, axes = plt.subplots(1,3, gridspec_kw={'hspace': 0.4}, figsize=(20, 10))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    p = char_label_text(v_res[i])\n",
    "    ax=show_img(imgs[i], ax=ax, title=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#greedy\n",
    "fig, axes = plt.subplots(1,3, gridspec_kw={'hspace': 0.4}, figsize=(20, 10))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    p = char_label_text(g_res[i])\n",
    "    ax=show_img(imgs[i], ax=ax, title=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tfmr full\n",
    "#             loss       cer       acc\n",
    "# valid:     2.42856   0.02981   0.98177   3x1, 256/60, 'tfmr_full_3x1_single_attn'\n",
    "# greedy:    11.9438   0.02745   0.93385\n",
    "\n",
    "# valid:     1.98831   0.01858   0.98505   3x1, 256/60, 'exp_3x1_256'\n",
    "# greedy:    16.3832   0.02167   0.90944\n",
    "\n",
    "# valid:     1.47604   0.00797   0.99523   3x2, 400/45,  'tfmr_full_3x2'\n",
    "# greedy:    21.4682   0.01097   0.93762\n",
    "\n",
    "# valid:     7.30494   0.01206   0.99086   lg,  512/30,  'tfmr_full_lg'\n",
    "# greedy:    434.610   0.02398   0.69553\n",
    "\n",
    "# valid:     25.4131   0.04500   0.96773   lg, 512/30,   'tfmr_lg_LM_mixer'\n",
    "# greedy:    734.834   0.15256   0.48912\n",
    "\n",
    "# valid:     10.1481   0.00501   0.99602   cat9-12,  800/8,  'tfmr_cat9-12_full_800'\n",
    "# greedy:    1330.63   0.04525   0.53181\n",
    "\n",
    "# valid:     62.0793   0.05716   0.96214   pg,  512/20  'tfmr_full_paragraph'  (cpu)\n",
    "# greedy:    1739.62   0.08347   0.43309\n",
    "# beam:                0.07958\n",
    "# valid:     71.9120   0.06819   0.95457   \"\", 2nd batch (gpu)\n",
    "# greedy:    2027.24   0.11823   0.39238\n",
    "# beam:                0.10697\n",
    "# valid:     36.3009   0.03397   0.97633   \"\", 3rd batch (gpu)\n",
    "# greedy:    1759.59   0.07070   0.40949\n",
    "    \n",
    "# valid:     50.1414   0.04137   0.97004   pg,  1000/5,  'tfmr_pg_1000'\n",
    "# greedy:    2579.24   0.34178   0.18623\n",
    "\n",
    "# valid:     56.2722   0.04167   0.96923   pg,  1000/5,  'tfmr_catpg_1000'\n",
    "# greedy:    2432.54   0.37192   0.26174\n",
    "\n",
    "\n",
    "# valid:     3.43745   0.05444   0.98735   mix(new)  'tfmr_mix_words_400'\n",
    "# greedy:    43.6545   0.06126   0.91407\n",
    "\n",
    "# valid:     2.96891   0.03338   0.98932   mix(new)  'tfmr_mix_words_512'\n",
    "# greedy:    28.9982   0.03949   0.94500\n",
    "# valid:     2.02411   0.02128   0.99302   5 more cycles\n",
    "# greedy:    19.4735   0.02450   0.96104\n",
    "\n",
    "# valid:     41.9800   0.03879   0.97535   pg, 'tfmr_mix_words_512'\n",
    "# greedy:    1602.68   0.06259   0.49110\n",
    "\n",
    "\n",
    "# valid:     53.9049   0.04822   0.96622   pg, 'tfmr_8head_512_mix'\n",
    "# greedy:    1384.72   0.06304   0.51696\n",
    "\n",
    "\n",
    "# valid:     5.24461   0.00634   mix   'v1_gelu_512'\n",
    "# greedy:    217.438   0.02028\n",
    "# valid:     24.3609   0.02405   pg\n",
    "# greedy:    1935.30   0.05970\n",
    "\n",
    "# valid:     12.7074   0.00954   mix   'v1_gelu_512_wiki103_base_lm_last_layer'\n",
    "# greedy:    553.201   0.02814\n",
    "\n",
    "# valid:     11.4251   0.00474   mix   'v1_gelu_512_wiki103_base_lm_full'\n",
    "# greedy:    358.030   0.01187\n",
    "\n",
    "# valid:     12.1104   0.01533   mix   'v1_gelu_multi_512'\n",
    "# greedy:    506.505   0.04229\n",
    "\n",
    "\n",
    "# edited data\n",
    "# valid:     8.21437   0.06576   sm   'v1_gelu_128'\n",
    "# greedy:    185.981   0.12890\n",
    "\n",
    "# valid:     2.25060   0.01731   sm   'v1_gelu_256'\n",
    "# greedy:    149.525   0.06003\n",
    "\n",
    "# valid:     2.37294   0.01383   mix  'v1_edited_gelu_400'\n",
    "# greedy:    30.3637   0.01732\n",
    "# greedy:    1810.14   0.11409   test\n",
    "\n",
    "# valid:     9.09986   0.01656   mix  'v1_edited_gelu_512'\n",
    "# greedy:    529.308   0.03104\n",
    "# greedy:    1675.20   0.10819   test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Multi-Batch Beam Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def beam_cer(preds, targs):\n",
    "    bs = preds.size(0)\n",
    "    error = 0\n",
    "    for i in range(bs):\n",
    "        p = char_label_text(preds[i])\n",
    "        t = char_label_text(targs[i])\n",
    "        error += _cer(t,p)\n",
    "    return error/bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def repeat_interleave(tensor,n):\n",
    "    res = []\n",
    "    for i in range(tensor.size(0)):\n",
    "        for _ in range(n): res.append(tensor[i])\n",
    "    return torch.stack(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def normalize_score(score, i, alpha=0.6):\n",
    "#     length_penalty = math.pow((5 + i)/6, alpha)\n",
    "#     return score/length_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Beam Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class Beam(object):\n",
    "    def __init__(self, beam_width=10):\n",
    "        self.heap = list()\n",
    "        self.beam_width = beam_width\n",
    "        self.best_score = None\n",
    "\n",
    "    def add(self, score, complete, seq):        \n",
    "        heapq.heappush(self.heap, (score, complete, seq))\n",
    "        if len(self.heap) > self.beam_width:\n",
    "            heapq.heappop(self.heap)\n",
    "            \n",
    "    def get_seq(self):\n",
    "        return [b[-1] for b in self.heap]\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return iter(self.heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class BeamSearch(nn.Module):\n",
    "    def __init__(self, net, beam_width, seq_len, end_tok=0):\n",
    "        super(BeamSearch, self).__init__()\n",
    "        self.img_enc = net.img_enc\n",
    "        self.transformer = net.transformer\n",
    "        self.bw = beam_width\n",
    "        self.seq_len = seq_len\n",
    "        self.end_tok = end_tok\n",
    "        self.feats = None\n",
    "        self.beams = []\n",
    "            \n",
    "    def forward(self, src):\n",
    "        with torch.no_grad():\n",
    "            bs = src.size(0)\n",
    "            \n",
    "            # initialize beam per bs\n",
    "            for _ in range(bs):\n",
    "                beam = Beam(self.bw)\n",
    "                beam.add(0.0, False, [1])\n",
    "                self.beams.append(beam)\n",
    "                \n",
    "            # encode src\n",
    "            self.feats = self.transformer.encode(self.img_enc(src))\n",
    "            \n",
    "            for i in tqdm(range(seq_len)):\n",
    "                # gather sequences from beams; combine into tensor (bs*bw)\n",
    "                prev_seq = torch.from_numpy(np.stack([b.get_seq() for b in self.beams])).view(-1,i+1)\n",
    "                \n",
    "                # generate new possibilities\n",
    "                log_probs, chars = self.prob_func(prev_seq.to(device))\n",
    "                log_probs, chars = log_probs.view(bs,-1,self.bw), chars.view(bs,-1,self.bw)\n",
    "                \n",
    "                for j in range(bs):\n",
    "                    curr_beam = Beam(self.bw)\n",
    "                    for k,(score, complete, seq) in enumerate(self.beams[j]):\n",
    "                        for l,c in zip(log_probs[j,k],chars[j,k]):\n",
    "                            log_prob,char = l.item(), c.item()\n",
    "                            curr_beam.add((score+log_prob), (char==self.end_tok), seq+[char])\n",
    "                    self.beams[j] = curr_beam\n",
    "  \n",
    "                # return if all max beams are complete\n",
    "                if (self.top_complete()==True).all(): break\n",
    "                    \n",
    "                # expand feats to match beam size (only on 2nd run)\n",
    "                if i==0: self.feats = repeat_interleave(self.feats, self.bw)\n",
    "\n",
    "            return self.top_seq()\n",
    "\n",
    "    def top_complete(self): return np.stack([max(b)[1] for b in self.beams])\n",
    "    def top_seq(self): return torch.from_numpy(np.stack([max(b)[-1] for b in self.beams]))[:,1:]\n",
    "\n",
    "    def prob_func(self, tgt):\n",
    "        mask = subsequent_mask(tgt.size(-1))\n",
    "        dec_outs = self.transformer.decode(self.feats, tgt, mask)\n",
    "        logits = self.transformer.generate(dec_outs[:,-1])\n",
    "        log_probs = logits - torch.logsumexp(logits, -1, keepdim=True) # more stable than F.softmax(logits,-1).log()\n",
    "        return torch.topk(log_probs, self.bw, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "search = BeamSearch(learn.model, 3, seq_len)\n",
    "b_res = search(x)\n",
    "\n",
    "# bw: 3, sl: 350, ~56s, 0.02491    # no normalized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "beam_cer(b_res,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class BeamSearch(nn.Module):\n",
    "    def __init__(self, net, beam_width, seq_len):\n",
    "        super(BeamSearch, self).__init__()\n",
    "        self.img_enc = net.img_enc\n",
    "        self.transformer = net.transformer\n",
    "        self.bw = beam_width\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.feats = None\n",
    "        self.beam = None\n",
    "        self.scores = None\n",
    "        \n",
    "        net.eval()\n",
    "    \n",
    "    def forward(self, src):\n",
    "        with torch.no_grad():\n",
    "            bs = src.size(0)\n",
    "            \n",
    "            # encode src\n",
    "            self.feats = self.transformer.encode(self.img_enc(src))\n",
    "            \n",
    "            # initialize globals (beam=1 for first iteration; 3 thereafter)\n",
    "            self.beam = torch.ones((bs,1), device=device, dtype=torch.long)\n",
    "            self.scores = torch.zeros((bs,1), device=device, dtype=torch.float)\n",
    "            \n",
    "            for i in tqdm(range(seq_len)):\n",
    "                # generate new topk chars per beam(bs*bw)\n",
    "                log_probs, chars = self.prob_func(self.beam)  #(bs*beam, 3)\n",
    "\n",
    "                # compute local scores\n",
    "                scores = self.scores + log_probs\n",
    "                \n",
    "                # compute new beams per batch\n",
    "                new_scores, idxs = torch.topk(scores.view(bs,-1), self.bw, dim=-1) #(bs, 3)\n",
    "                self.scores = new_scores.view(-1,1)\n",
    "                \n",
    "                # set up new beam:\n",
    "                nxt = torch.stack([c[i] for c,i in zip(chars.view(bs,-1),idxs)]).view(-1,1)\n",
    "                pre = torch.stack([b[i//self.bw] for b,i in zip(self.beam.view(bs,-1,i+1),idxs)]).view(-1,i+1)\n",
    "                                    \n",
    "                # update globals\n",
    "                self.beam = torch.cat([pre,nxt], dim=1)\n",
    "\n",
    "                # end when top of beams are complete\n",
    "                if self.top_complete(): break\n",
    "                                                        \n",
    "                # expand feats to match beam size (only on 2nd run)\n",
    "                if i==0: self.feats = repeat_interleave(self.feats, self.bw) #.repeat(self.bw,1,1)\n",
    "                    \n",
    "            return self.top_sequences(), self.top_scores() \n",
    "\n",
    "\n",
    "    def top_complete(self): return (self.top_sequences()[:,-1]==0).all().item()   #byte tensor\n",
    "    def top_sequences(self): return self.beam.squeeze()[0::self.bw][:,1:]\n",
    "    def top_scores(self): return self.scores.squeeze()[0::self.bw]\n",
    "\n",
    "    def prob_func(self, tgt):\n",
    "        mask = subsequent_mask(tgt.size(-1))\n",
    "        dec_outs = self.transformer.decode(self.feats, tgt, mask)\n",
    "        logits = self.transformer.generate(dec_outs[:,-1])\n",
    "        log_probs = logits - torch.logsumexp(logits, -1, keepdim=True) # more stable than F.softmax(logits,-1).log()\n",
    "        return torch.topk(log_probs, self.bw, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "search = BeamSearch(learn.model, 3, seq_len)\n",
    "b_res,score = search(x)\n",
    "\n",
    "# lg, sl: 250\n",
    "# bw: 1, ~12s, 0.02398\n",
    "# bw: 3, ~28s, 0.02378\n",
    "# bw: 5, ~46s, 0.02378\n",
    "\n",
    "# pg: 1000,5\n",
    "# bs: 3, ~40s, 0.33227  (greedy: 0.28---)\n",
    "# ''   , ~30s, 0.22635  (greedy: 0.23726)\n",
    "\n",
    "# pg: 800,8\n",
    "# bs: 3, ~51s, 0.25424  (greedy: 0.28348)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "beam_cer(b_res,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#beam\n",
    "fig, axes = plt.subplots(1,3, gridspec_kw={'hspace': 0.4}, figsize=(20, 10))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    p = char_label_text(b_res[i], chunk=55)\n",
    "    ax=show_img(imgs[i], ax=ax, title=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Single Beam Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://geekyisawesome.blogspot.com/2016/10/using-beam-search-to-generate-most.html\n",
    "\n",
    "import heapq\n",
    "\n",
    "class Beam(object):\n",
    "    '''\n",
    "    For comparison of prefixes, the tuple (prefix_probability, complete_sentence) is used.\n",
    "    This is so that if two prefixes have equal probabilities then a complete sentence\n",
    "    is preferred over an incomplete one since (0.5, False) < (0.5, True)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, beam_width=10):\n",
    "        self.heap = list()\n",
    "        self.beam_width = beam_width\n",
    "        self.best_score = None\n",
    "\n",
    "    def add(self, score, complete, seq):        \n",
    "        # keep track of best_score so far\n",
    "        if self.best_score is None or score > self.best_score:\n",
    "            self.best_score = score\n",
    "            \n",
    "        # only add to beam if score is not more than beam_width below the best_score\n",
    "        if score > self.best_score-self.beam_width:\n",
    "            heapq.heappush(self.heap, (score, complete, seq))\n",
    "            \n",
    "        # maintain beam_width\n",
    "        if len(self.heap) > self.beam_width:\n",
    "            heapq.heappop(self.heap)\n",
    "                \n",
    "    def __iter__(self):\n",
    "        return iter(self.heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def beamsearch(prob_fn, seq_len, beam_width=5, start_tok=1, end_tok=3):\n",
    "    prev_beam = Beam(beam_width)\n",
    "    prev_beam.add(0.0, False, [start_tok])\n",
    "    \n",
    "    for i in tqdm(range(seq_len)):\n",
    "        curr_beam = Beam(beam_width)\n",
    "        \n",
    "        # iterate over each beam\n",
    "        for (score, complete, seq) in prev_beam:\n",
    "            if complete == True:\n",
    "                None  # only keep the completed best beam!!\n",
    "#                 curr_beam.add(score, True, seq)\n",
    "            else:\n",
    "                # iterate through topk chars, calculating scores and adding to the beam.\n",
    "                log_probs, chars = prob_fn(seq)\n",
    "                for log_prob, char in zip(log_probs, chars): \n",
    "                    log_prob,char = log_prob.item(), char.item()\n",
    "                    score += log_prob   #log probabilities are additive\n",
    "#                     score = score_func(score, len(seq))\n",
    "                    curr_beam.add(score, (char==end_tok), seq+[char])\n",
    "        \n",
    "        (best_score, best_complete, best_seq) = max(curr_beam)\n",
    "        if best_complete == True: return (best_seq[1:], best_score)   # returns first complete beam not best...\n",
    "            \n",
    "        prev_beam = curr_beam\n",
    "        \n",
    "    (best_score, best_complete, best_seq) = max(curr_beam)\n",
    "    return (best_seq[1:], best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def beam_decode(net, src, beam_width, seq_len):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        feats = net.transformer.encode(net.img_enc(src))        \n",
    "        return beamsearch(partial(prob_func, net=net, feats=feats, beam_width=beam_width), seq_len, beam_width)\n",
    "    \n",
    "def prob_func(tgt, net=None, feats=None, beam_width=5):\n",
    "    tgt = torch.tensor([tgt], dtype=torch.long, device=device)\n",
    "    mask = subsequent_mask(tgt.size(-1))\n",
    "    dec_outs = net.transformer.decode(feats, tgt, mask)\n",
    "    logits = net.transformer.generate(dec_outs[:,-1])\n",
    "    \n",
    "    log_probs = logits - torch.logsumexp(logits, 1)  # more numerically stable\n",
    "    # log_probs = F.softmax(logits, -1).log()\n",
    "    \n",
    "    return torch.topk(log_probs.squeeze(0), beam_width, dim=-1)\n",
    "#     return zip(res[0][0].detach(),res[1][0].detach())\n",
    "\n",
    "def score_func(log_probs, i, alpha=0.6):\n",
    "    length_penalty = math.pow((5 + i)/6, alpha)\n",
    "    return log_probs/length_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx = 2\n",
    "x1 = x[idx][None]\n",
    "y1 = y[idx][None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "b_res, score = beam_decode(learn.model, image, 3, seq_len)    #294, 3m18s\n",
    "# 294 - 1m40s\n",
    "# 294 - 1m45s (w/ score_func)\n",
    "# 295 - 22s (beam_width=1 ~ greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r = torch.tensor([b_res], dtype=torch.long, device=device)\n",
    "p = char_label_text(r)\n",
    "\n",
    "_cer(truth, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# valid\n",
    "p = char_label_text(v_res[idx][None])\n",
    "t = char_label_text(y1[0])\n",
    "_cer(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# greedy\n",
    "p = char_label_text(g_res[idx][None])\n",
    "t = char_label_text(y1[0])\n",
    "_cer(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# beam (sz=3)\n",
    "r = torch.tensor([b_res], dtype=torch.long, device=device)\n",
    "p = char_label_text(r)\n",
    "t = char_label_text(y1[0])\n",
    "_cer(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stoi = {k:i for i,k in enumerate(itos)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(char_label_text(g_res[idx][None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "st = ''.join([itos[i] for i in b_res])\n",
    "p = '\\n'.join(textwrap.wrap(st, 70))\n",
    "show_img(denorm(x1)[0], figsize=(10,10), title=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Source Attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "img = imgs[idx]\n",
    "\n",
    "v_chars = v_res[idx]\n",
    "v_attns = to_np(torch_scale_attns(v_attn)[idx])\n",
    "\n",
    "g_chars = g_res[idx]\n",
    "g_attns = to_np(torch_scale_attns(g_attn)[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#valid\n",
    "fig, axes = plt.subplots(5,4, gridspec_kw={'hspace': 0.3}, figsize=(20, 20))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    a = g_filter(vv_attns[i])\n",
    "    ax.imshow(img, alpha=None)\n",
    "    ax.imshow(a, cmap='Blues', interpolation='nearest', alpha=0.3)\n",
    "    ax.set_title(itos[v_chars[i].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#greedy\n",
    "fig, axes = plt.subplots(6,4, gridspec_kw={'hspace': 0.3}, figsize=(20, 20))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    a = g_filter(g_attns[i])\n",
    "    ax.imshow(img, alpha=None)\n",
    "    ax.imshow(a, cmap='Blues', interpolation='nearest', alpha=0.3)\n",
    "    ax.set_title(itos[g_chars[i].item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Attention Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def transparent_cmap(cmap, N=5):\n",
    "    \"Copy colormap and set alpha values\"\n",
    "    mycmap = matplotlib.cm.get_cmap(cmap, N)\n",
    "    mycmap._init()\n",
    "    mycmap._lut[:,-1] = np.linspace(0, 0.6, N+3)\n",
    "    return mycmap\n",
    "\n",
    "#Use base cmap to create transparent\n",
    "# mycmap = transparent_cmap(plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show_attn(img, attns, chars, ax, color, showChars=True):\n",
    "    for i in range(attns.shape[0]):\n",
    "        c = chars[i].item()\n",
    "        if c not in [0,1,2,3]:\n",
    "            a = g_filter(attns[i])\n",
    "            y,x = scipy.ndimage.center_of_mass(a)\n",
    "            #sns.heatmap(a, cmap=mycmap, cbar=False, ax=ax)\n",
    "            ax.imshow(a, cmap=transparent_cmap(color), interpolation='nearest')\n",
    "            if showChars: ax.text(x-8,y-10,itos[c], fontsize=15)\n",
    "\n",
    "    ax.set_title(char_label_text(chars))\n",
    "    ax.imshow(img, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def thresh_attn(attn, thresh=0.1):\n",
    "    zeros = torch.zeros_like(attn)\n",
    "    new = torch.where(attn >= thresh, attn, zeros)\n",
    "    \n",
    "    # some attns will not have a value over the thresh in which case\n",
    "    # we need to insert top k value at appropriate index\n",
    "    vals, idxs = torch.topk(attn, 1, dim=-1)\n",
    "    \n",
    "    # reshape\n",
    "    flat_new = new.flatten(0,1)\n",
    "    vals = vals.flatten()\n",
    "    idxs = idxs.flatten()\n",
    "    \n",
    "    for i in range(flat_new.size(0)):\n",
    "        flat_new[i,idxs[i]] = vals[i]\n",
    "\n",
    "    new = flat_new.view_as(new)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Decoder Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(context=\"notebook\")\n",
    "\n",
    "def draw(data, x, y, ax):\n",
    "    return sns.heatmap(data, xticklabels=x, square=True, yticklabels=y, vmin=0.0, vmax=1.0,\n",
    "                       cmap='YlOrRd', linewidths=0.05, cbar=False, ax=ax)\n",
    "\n",
    "for layer in range(4):\n",
    "    print(\"Decoder Self-Attention Layer\", layer+1)\n",
    "\n",
    "    fig, axes = plt.subplots(1,4, figsize=(20, 10))\n",
    "    for i,ax in enumerate(axes.flat):\n",
    "        # greedy decoding (no access to true values)\n",
    "        pred = char_split_text(g_res[i])[20:40]\n",
    "        shifted_y = rshift(g_res.float()).long()\n",
    "        true = char_split_text(shifted_y[i])[20:40]\n",
    "        g = draw(self_attn(layer)[i].data[20:40, 20:40], true, pred, ax=ax)\n",
    "        g.set_yticklabels(g.get_yticklabels(), rotation=0) \n",
    "        g.set_xticklabels(g.get_xticklabels(), rotation=0) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Decoder Source-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,4, gridspec_kw={'hspace': 0.5}, figsize=(20, 10))\n",
    "    \n",
    "for idx in range(len(axes.flat)//4):\n",
    "    img = imgs[idx]\n",
    "    g_chars = g_res[idx]\n",
    "    \n",
    "    # 4 attn layers\n",
    "    for h in range(4):\n",
    "        attn = source_attn(h)\n",
    "        g_attns = to_np(torch_scale_attns(attn)[idx])\n",
    "\n",
    "        show_attn(img, g_attns, g_chars, axes[idx,h], 'YlGn', showChars=False)\n",
    "        axes[idx,h].set_title(f'layer {h+1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Validation vs Greedy (final layer src-attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "v_scaled_attns = torch_scale_attns(thresh_attn(v_attn))\n",
    "g_scaled_attns = torch_scale_attns(thresh_attn(g_attn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2, gridspec_kw={'hspace': 0.5}, figsize=(20, 20))\n",
    "for idx in range(len(axes.flat)//2):\n",
    "    img = imgs[idx]\n",
    "\n",
    "    v_chars = v_res[idx]\n",
    "    v_attns = to_np(v_scaled_attns[idx])\n",
    "\n",
    "    g_chars = g_res[idx]\n",
    "    g_attns = to_np(g_scaled_attns[idx])\n",
    "    \n",
    "    # valid\n",
    "    show_attn(img, v_attns, v_chars, axes[idx,0], 'YlOrRd')\n",
    "    # greedy\n",
    "    show_attn(img, g_attns, g_chars, axes[idx,1], 'YlGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Individual Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx=0\n",
    "img = imgs[idx]\n",
    "\n",
    "g_chars = g_res[idx]\n",
    "g_scaled_attns = torch_scale_attns(thresh_attn(g_attn)[0:1])  # passing in bs of 1\n",
    "g_attns = to_np(g_scaled_attns[0])  # removing bs\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(20, 20))\n",
    "show_attn(img, g_attns, g_chars, ax, 'YlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(context=\"notebook\")\n",
    "\n",
    "def draw(data, x, y, ax):\n",
    "    mask = np.zeros_like(data)\n",
    "    mask[np.triu_indices_from(mask, k=1)] = True\n",
    "    return sns.heatmap(data, xticklabels=x, square=True, yticklabels=y, vmin=0.0, vmax=1.0,\n",
    "                       mask=mask, cmap='YlOrRd', linewidths=0.05, cbar=False, ax=ax)\n",
    "\n",
    "for layer in range(4):\n",
    "    print(\"Decoder Self-Attention Layer\", layer+1)\n",
    "\n",
    "    fig, ax = plt.subplots(1,1, figsize=(20, 10))\n",
    "    i = 1\n",
    "    # greedy decoding (no access to true values)\n",
    "    pred = char_split_text(g_res[i])[230:280]\n",
    "    shifted_y = rshift(g_res.float()).long()\n",
    "    true = char_split_text(shifted_y[i])[230:280]\n",
    "    g = draw(self_attn(layer)[i].data[230:280, 230:280], true, pred, ax=ax)\n",
    "    g.set_yticklabels(g.get_yticklabels(), rotation=0) \n",
    "    g.set_xticklabels(g.get_xticklabels(), rotation=0) \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
