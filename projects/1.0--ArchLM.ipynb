{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.text import *\n",
    "from fastai.callbacks.tracker import *\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PATH = Path('data/IAM_handwriting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss, Metrics, Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def tensor2im(x):\n",
    "    x = x.detach().numpy() * 255\n",
    "    x = np.uint8(x)[0]\n",
    "    return PIL.Image.fromarray(x, mode='L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        pred,targ = self.loss_prep(pred, target)\n",
    "        pred = F.log_softmax(pred, dim=-1)  # need this for KLDivLoss\n",
    "        true_dist = pred.data.clone()\n",
    "        true_dist.fill_(self.smoothing / pred.size(1))                  # fill with 0.0012\n",
    "        true_dist.scatter_(1, targ.data.unsqueeze(1), self.confidence)  # [0.0012, 0.0012, 0.90, 0.0012]\n",
    "        return F.kl_div(pred, true_dist, reduction='sum')/bs\n",
    "    \n",
    "    def loss_prep(self, pred, target):\n",
    "        \"equalize input/target sl; combine bs/sl dimensions\"\n",
    "        bs,tsl = target.shape\n",
    "        _ ,sl,vocab = pred.shape\n",
    "\n",
    "        # F.pad( front,back for dimensions: 1,0,2 )\n",
    "        if sl>tsl: target = F.pad(target, (0,sl-tsl))\n",
    "\n",
    "        # this should only be used when testing for small seq_lens\n",
    "        # if tsl>sl: target = target[:,:sl]\n",
    "\n",
    "        if tsl>sl: pred = F.pad(pred, (0,0,0,tsl-sl))\n",
    "        # not ideal => adds 96 logits all 0s...\n",
    "\n",
    "        targ = target.contiguous().view(-1).long()\n",
    "        pred = pred.contiguous().view(-1, vocab)\n",
    "        return pred, targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cer(preds, targs):\n",
    "    bs = targs.size(0)\n",
    "    res = torch.argmax(preds, dim=-1)\n",
    "    error = 0\n",
    "    for i in range(bs):\n",
    "        p = char_label_text(res[i])   #.replace(' ', '')\n",
    "        t = char_label_text(targs[i]) #.replace(' ', '')\n",
    "        error += Lev.distance(t, p)/len(t)\n",
    "    return error, bs\n",
    "\n",
    "def char_label_text(pred, sep=''):\n",
    "    ints = to_np(pred).astype(int)\n",
    "    nonzero = ints[np.nonzero(ints)] #[:-1]  #remove eos token\n",
    "    return sep.join([itos[i] for i in nonzero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import Levenshtein as Lev\n",
    "\n",
    "class CER(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = 'cer'\n",
    "\n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.errors, self.total = 0, 0\n",
    "    \n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        error,size = cer(last_output, last_target)\n",
    "        self.errors += error\n",
    "        self.total += size\n",
    "    \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        return add_metrics(last_metrics, self.errors/self.total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rshift(tgt, bos_token=1):\n",
    "    \"Shift y to the right by prepending token\"\n",
    "    bos = torch.zeros((tgt.size(0),1), device=device).type_as(tgt) + bos_token\n",
    "    return torch.cat((bos, tgt[:,:-1]), dim=-1)\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    return torch.tril(torch.ones((1,size,size), device=device).byte())\n",
    "    #return torch.tril(torch.ones((1,1,size,size), device=device).byte())  # complex batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TeacherForce(LearnerCallback):\n",
    "    def __init__(self, learn:Learner):\n",
    "        super().__init__(learn)\n",
    "        \n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        s = rshift(last_target).long()\n",
    "        mask = subsequent_mask(s.size(-1))\n",
    "        return {'last_input':(last_input, s, mask), 'last_target':last_target}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sm synth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname = 'edited_sm_synth.csv' #'small_synth_words.csv'\n",
    "CSV = PATH/fname\n",
    "FOLDER = 'edited_sm_synth'\n",
    "\n",
    "df = pd.read_csv(CSV)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sz,bs = 128,100\n",
    "sz,bs = 256,100\n",
    "\n",
    "num_lines,seq_len = 4,50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname = 'edited_line2.csv'\n",
    "CSV = PATH/fname\n",
    "FOLDER = 'square_lines'\n",
    "\n",
    "df = pd.read_csv(CSV)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sz,bs = 256,100\n",
    "# sz,bs = 256,100\n",
    "\n",
    "seq_len = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Concat Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CSV = PATH/f'edited_cat_lines.csv'\n",
    "FOLDER = 'edited_cat_lines'\n",
    "\n",
    "df = pd.read_csv(CSV)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nums = '3-6'   #'7-10'  #'11-14'\n",
    "CSV = PATH/f'cat_lines_{nums}.csv'\n",
    "\n",
    "FOLDER = 'resized_cat_lines'\n",
    "\n",
    "csv = pd.read_csv(CSV)\n",
    "test = pd.read_csv(PATH/'test_pg.csv')\n",
    "\n",
    "len(csv), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lengths = np.array([len(i.split(' ')) for i in csv.char_ids.values])\n",
    "lengths.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sz,bs = 512,20   #1000,5  #800,8   #512,20\n",
    "seq_len = 600 #600 #450  #300\n",
    "stats = (np.array([0.941, 0.941, 0.941], dtype=np.float32), np.array([0.128, 0.128, 0.128], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Concat All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = pd.read_csv(PATH/'cat_lines_3.csv').sample(1000)\n",
    "b = pd.read_csv(PATH/'cat_lines_4.csv').sample(1000)\n",
    "c = pd.read_csv(PATH/'cat_lines_5.csv').sample(1000)\n",
    "d = pd.read_csv(PATH/'cat_lines_6.csv').sample(1000)\n",
    "e = pd.read_csv(PATH/'cat_lines_7.csv').sample(1000)\n",
    "f = pd.read_csv(PATH/'cat_lines_8.csv').sample(1000)\n",
    "g = pd.read_csv(PATH/'cat_lines_9.csv').sample(1000)\n",
    "h = pd.read_csv(PATH/'cat_lines_10.csv').sample(1000)\n",
    "i = pd.read_csv(PATH/'cat_lines_11.csv').sample(1000)\n",
    "j = pd.read_csv(PATH/'cat_lines_12.csv').sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "k = pd.read_csv(PATH/'paragraph_chars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_idxs = np.array(k.sample(frac=0.15, random_state=42).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn = k[~k.index.isin(val_idxs)]\n",
    "test = k[k.index.isin(val_idxs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new = pd.concat([a,b,c,d,e,f,g,h,i,j,trn], ignore_index=True)\n",
    "len(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# new.to_csv(PATH/'cat_lines_pg.csv', index=False)\n",
    "# test.to_csv(PATH/'test_pg.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname = 'edited_pg.csv' #'paragraphs.csv'\n",
    "CSV = PATH/fname\n",
    "FOLDER = 'paragraphs'\n",
    "\n",
    "df = pd.read_csv(CSV)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sz,bs = 1000,5  #1024,5  #1000,5   #~2000x1000 full size\n",
    "# sz,bs = 800,8\n",
    "sz,bs = 512,10\n",
    "\n",
    "seq_len = 700   #~400 chars/paragraph - max: 705\n",
    "# stats = (np.array([0.941, 0.941, 0.941], dtype=np.float32), np.array([0.128, 0.128, 0.128], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = df[:10]\n",
    "sz,bs,seq_len = 256,10,50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Downloaded Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CSV = PATH/'downloaded_images.csv'\n",
    "FOLDER = 'downloaded_images'\n",
    "\n",
    "df = pd.read_csv(CSV)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# csv['filename'] = csv['filename'].apply(lambda x: f\"dl_{x}\")\n",
    "# csv.head()\n",
    "# csv.to_csv(CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sz,bs = 1000,5  #1024,5  #1000,5   #~2000x1000 full size\n",
    "# sz,bs = 800,8\n",
    "sz,bs = 512,41\n",
    "\n",
    "seq_len = 700   #~400 chars/paragraph - max: 705\n",
    "stats = (np.array([0.941, 0.941, 0.941], dtype=np.float32), np.array([0.128, 0.128, 0.128], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fonts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname = 'edited_font.csv'\n",
    "CSV = PATH/fname\n",
    "FOLDER = 'fonts_resize'\n",
    "\n",
    "df = pd.read_csv(CSV)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df[df.num_lines<5]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sz,bs = 256,20\n",
    "# sz,bs = 400,10\n",
    "sz,bs = 512,50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname = 'mix.csv'\n",
    "CSV = PATH/fname\n",
    "FOLDER = 'mix'\n",
    "\n",
    "df = pd.read_csv(CSV)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sz,bs = 512,10\n",
    "# sz,bs = 800,5\n",
    "\n",
    "seq_len = 800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Combo/Cat Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 6 and fewer\n",
    "fname = 'combo_cat6lines.csv'\n",
    "sz,bs = 512,30\n",
    "seq_len = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 6 and greater of combo/cat lines + all paragraph (2-13 lines)\n",
    "fname = 'combo_cat_pg.csv'\n",
    "sz,bs = 512,10\n",
    "seq_len = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# full mix sorted by num_lines\n",
    "fname = 'combo_cat_pg_dl_sorted.csv'\n",
    "sz,bs = 512,10\n",
    "seq_len = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CSV = PATH/fname\n",
    "FOLDER = 'combo_cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FOLDER = 'uploads'\n",
    "df = pd.read_csv(PATH/'uploads.csv')\n",
    "len(df)\n",
    "\n",
    "sz,bs = 512,14\n",
    "seq_len = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FOLDER = 'paragraphs'\n",
    "df = pd.read_csv(PATH/'test_pg.csv')\n",
    "len(df)\n",
    "\n",
    "sz,bs = 512,15\n",
    "seq_len = 700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = get_transforms(do_flip=False, max_zoom=1, max_rotate=0, max_warp=0.1)\n",
    "\n",
    "def force_gray(image): return image.convert('L').convert('RGB')\n",
    "\n",
    "def label_collater(samples:BatchSamples, pad_idx:int=0):\n",
    "    \"Function that collect samples and pads ends of labels.\"\n",
    "    data = to_data(samples)\n",
    "    ims, lbls = zip(*data)\n",
    "    imgs = torch.stack(list(ims))\n",
    "    if len(data) is 1:\n",
    "        labels = torch.zeros(1,1).long()\n",
    "        return imgs, labels    \n",
    "    max_len = max([len(s) for s in lbls])\n",
    "    labels = torch.zeros(len(data), max_len+1).long() + pad_idx  # add 1 to max_len to account for bos token\n",
    "    for i,lbl in enumerate(lbls):\n",
    "        labels[i,:len(lbl)] = torch.from_numpy(lbl)  #padding end    \n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "itos = pickle.load(open(PATH/'itos.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple batches (BS, Seq Len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class CharTokenizer(BaseTokenizer):\n",
    "    def tokenizer(self, t:str) -> List[str]: return list(t)+['xxeos']\n",
    "            \n",
    "class CharVocab(Vocab):\n",
    "    def __init__(self, itos:Collection[str]):\n",
    "        self.itos = itos\n",
    "        self.stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(self.itos)})\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=''):\n",
    "        return sep.join([self.itos[i] for i in nums]) if sep is not None else [self.itos[i] for i in nums]\n",
    "\n",
    "class SequenceList(TextList):    \n",
    "    def __init__(self, items:Iterator, vocab:Vocab, **kwargs):\n",
    "        toknizr = Tokenizer(tok_func=CharTokenizer, pre_rules=[], post_rules=[], special_cases=[])\n",
    "        procs = [TokenizeProcessor(tokenizer=toknizr, include_bos=False),\n",
    "                 NumericalizeProcessor(vocab=vocab)]\n",
    "        super().__init__(items, vocab, sep='', pad_idx=0, processor=procs)\n",
    "    \n",
    "    def analyze_pred(self, pred:Tensor):\n",
    "        return torch.argmax(pred, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = (ImageList.from_df(df, path=PATH, folder=FOLDER, after_open=force_gray)\n",
    "#         .split_none()\n",
    "        .split_by_rand_pct(valid_pct=0.15, seed=42)\n",
    "        #.label_from_df(label_cls=TextList, sep='', pad_idx=0, vocab=vocab, processor=procs)\n",
    "        .label_from_df(label_cls=SequenceList, vocab=CharVocab(itos))\n",
    "        .transform(tfms, size=sz, resize_method=ResizeMethod.SQUISH)\n",
    "        #.transform(tfms, size=sz, resize_method=ResizeMethod.PAD, padding_mode='border')\n",
    "        # maintains aspect ratio but too small for good results => mostly whitespace\n",
    "        .databunch(bs=bs, device=device, collate_fn=label_collater)\n",
    "        #.normalize() # this sets x values to an odd range (~.3,-6)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Test dataset only!!!\n",
    "\n",
    "data = (ImageList.from_df(df, path=PATH, folder=FOLDER, after_open=force_gray)\n",
    "        .split_none()\n",
    "        .label_from_df(label_cls=SequenceList, vocab=CharVocab(itos))\n",
    "        .transform([], size=sz, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=bs, device=device, collate_fn=label_collater)\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Complex Batches (BS, Lines, Char Sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def split_1d_array_to_2d_tensor(a, split_idx=4):\n",
    "    \"Requires global num_lines variable to be set...\"\n",
    "    b = np.split(a, np.where(a == split_idx)[0])\n",
    "    maxlen = len(max(b,key=len))\n",
    "    res = torch.zeros((maxlen, num_lines))\n",
    "    for i,arr in enumerate(b):\n",
    "        res[:len(arr),i] = torch.from_numpy(arr)\n",
    "    return res\n",
    "\n",
    "def batch_line_collater(samples:BatchSamples, pad_idx:int=0):\n",
    "    \"Function that collect samples and pads ends of labels.\"\n",
    "    data = to_data(samples)\n",
    "    ims, lbls = zip(*data)\n",
    "    imgs = torch.stack(list(ims))\n",
    "    if len(data) is 1:\n",
    "        labels = torch.zeros(1,1,1).long()\n",
    "        return imgs, labels\n",
    "\n",
    "    res = []\n",
    "    for lbl in lbls:\n",
    "        res.append(split_1d_array_to_2d_tensor(lbl))\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(res, batch_first=True)\n",
    "    return imgs, labels.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class CharTokenizer():\n",
    "    def __init__(self, n_cpus:int=None):\n",
    "        self.n_cpus = ifnone(n_cpus, defaults.cpus)\n",
    "\n",
    "    def tokenize(self, t:str): return list(t)+['xxeos']\n",
    "\n",
    "    def _process_all_1(self, texts:Collection[str]) -> List[List[str]]:\n",
    "        \"Process a list of `texts` in one process.\"\n",
    "        return [self.tokenize(str(t)) for t in texts]\n",
    "\n",
    "    def process_all(self, texts:Collection[str]) -> List[List[str]]:\n",
    "        \"Process a list of `texts`.\"\n",
    "        if self.n_cpus <= 1: return self._process_all_1(texts)\n",
    "        with ProcessPoolExecutor(self.n_cpus) as e:\n",
    "            return sum(e.map(self._process_all_1, partition_by_cores(texts, self.n_cpus)), [])\n",
    "\n",
    "class CharVocab(Vocab):\n",
    "    def __init__(self, itos:Collection[str]):\n",
    "        self.itos = itos\n",
    "        self.stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(self.itos)})\n",
    "\n",
    "    def textify(self, nums:Collection[int]):\n",
    "        nums = nums[:-1]  #remove bos/eos tokens\n",
    "        return ''.join([self.itos[i] for i in nums.astype(int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SequenceList(ItemList):\n",
    "    _processor = [partial(TokenizeProcessor, tokenizer=CharTokenizer(), include_bos=False), NumericalizeProcessor]\n",
    "\n",
    "    def __init__(self, items:Iterator, itos:List[str]=None, **kwargs):\n",
    "        super().__init__(items, **kwargs)\n",
    "        self.vocab=CharVocab(itos)\n",
    "        self.pad_idx=0\n",
    "        self.copy_new += ['vocab', 'pad_idx']\n",
    "\n",
    "    def get(self, i):\n",
    "        o = super().get(i)\n",
    "        return o if self.vocab is None else Text(o, self.vocab.textify(o))\n",
    "\n",
    "    def reconstruct(self, t:Tensor):\n",
    "        o = t.numpy()\n",
    "        o = o[np.nonzero(o)].flatten()\n",
    "        return Text(o, self.vocab.textify(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = (ImageList.from_df(df, path=PATH, folder=FOLDER)\n",
    "        .split_by_rand_pct(valid_pct=0.15, seed=42)\n",
    "        .label_from_df(label_cls=SequenceList, itos=itos)\n",
    "        .transform(tfms, size=sz, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=bs, device=device, collate_fn=batch_line_collater)\n",
    "        .normalize()\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SequenceList (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# class CharTokenizer():\n",
    "#     def __init__(self, n_cpus:int=None):\n",
    "#         self.n_cpus = ifnone(n_cpus, defaults.cpus)\n",
    "\n",
    "#     def tokenize(self, t:str): return list(t)+['xxeos']\n",
    "\n",
    "#     def _process_all_1(self, texts:Collection[str]) -> List[List[str]]:\n",
    "#         \"Process a list of `texts` in one process.\"\n",
    "#         return [self.tokenize(str(t)) for t in texts]\n",
    "\n",
    "#     def process_all(self, texts:Collection[str]) -> List[List[str]]:\n",
    "#         \"Process a list of `texts`.\"\n",
    "#         if self.n_cpus <= 1: return self._process_all_1(texts)\n",
    "#         with ProcessPoolExecutor(self.n_cpus) as e:\n",
    "#             return sum(e.map(self._process_all_1, partition_by_cores(texts, self.n_cpus)), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SequenceItem(ItemBase):\n",
    "    def __init__(self,data,vocab): self.data,self.vocab = data,vocab        \n",
    "    def __str__(self): return self.textify(self.data)\n",
    "    def __hash__(self): return hash(str(self))\n",
    "    def textify(self, data): return ''.join([self.vocab[i] for i in data[:-1]])\n",
    "        \n",
    "class ArrayProcessor(PreProcessor):\n",
    "    \"Convert df column (string of ints) into np.array\"\n",
    "    def __init__(self, ds:ItemList=None): None\n",
    "    def process_one(self,item): return np.array(item.split(), dtype=np.int64)\n",
    "    def process(self, ds): super().process(ds)\n",
    "        \n",
    "class ItosProcessor(PreProcessor):\n",
    "    def __init__(self, ds:ItemList=None): self.itos = ds.itos\n",
    "    def process(self, ds:ItemList): ds.itos = self.itos\n",
    "        \n",
    "class SequenceList(ItemList):\n",
    "    _processor = [ItosProcessor, ArrayProcessor]\n",
    "    \n",
    "    def __init__(self, items:Iterator, itos:List[str]=None, **kwargs):\n",
    "        super().__init__(items, **kwargs)\n",
    "        self.itos = itos\n",
    "        self.copy_new += ['itos']\n",
    "        self.c = len(self.items)\n",
    "\n",
    "    def get(self, i):\n",
    "        o = super().get(i)\n",
    "        return SequenceItem(o, self.itos)\n",
    "\n",
    "    def reconstruct(self,t):\n",
    "        # Converting padded tensor back into np.array\n",
    "        o = t.numpy()\n",
    "        o = o[np.nonzero(o)]                  # remove 0 padding\n",
    "        return SequenceItem(o, self.itos)\n",
    "    \n",
    "    def analyze_pred(self,pred):\n",
    "        return torch.argmax(pred, dim=-1)\n",
    "        # method called in learn.predict() or learn.show_results()\n",
    "        # to transform predictions in an output tensor suitable for reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # This slows down training...\n",
    "# class CustomSampler(Sampler):\n",
    "#     \"sort dataset by longest y sequences\"\n",
    "#     def __init__(self, dataset):\n",
    "#         self.dataset = dataset\n",
    "#         self.lengths = [len(i) for i in dataset.y.items]\n",
    "#         self.sorted_idxs = np.flip(np.argsort(self.lengths))\n",
    "#     def __len__(self): return len(self.dataset)\n",
    "#     def __iter__(self): return iter(self.sorted_idxs)\n",
    "\n",
    "# ds = data.train_ds\n",
    "# tfms = data.train_dl.tfms\n",
    "# sampler = CustomSampler(ds)\n",
    "# dl = DataLoader(ds, bs, shuffle=False, sampler=sampler, num_workers=num_cpus(), collate_fn=custom_collater, drop_last=True)\n",
    "# ddl = DeviceDataLoader(dl, device, tfms, custom_collater)\n",
    "# data.train_dl = ddl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.batch_stats()\n",
    "# no normalization: [tensor([0.9403, 0.9403, 0.9403]), tensor([0.1604, 0.1604, 0.1604])]\n",
    "# imagenet_stats:   [tensor([1.9973, 2.1714, 2.3839]), tensor([0.6974, 0.7130, 0.7098])]\n",
    "# normalize():      [tensor([0.0225, 0.0225, 0.0225]), tensor([0.9676, 0.9676, 0.9676])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def char_label_text(pred):\n",
    "    return self.sp.DecodeIds(pred.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SPMProcessor(PreProcessor):\n",
    "    def __init__(self, ds:ItemList=None):\n",
    "        self.sp = ds.sp if ds is not None else None\n",
    "\n",
    "    def process_one(self,item): return self.sp.EncodeAsIds(item)\n",
    "    def process(self, ds): super().process(ds)\n",
    "    \n",
    "class SPMList(ItemList):\n",
    "    _processor = [SPMProcessor]\n",
    "\n",
    "    def __init__(self, items:Iterator, sp_processor, **kwargs):\n",
    "        super().__init__(items, **kwargs)\n",
    "        self.sp = sp_processor\n",
    "        self.copy_new += ['sp']\n",
    "\n",
    "    def get(self, i):\n",
    "        o = super().get(i)\n",
    "        return Text(o, self.sp.DecodeIds(o))\n",
    "\n",
    "    def reconstruct(self, t:Tensor):\n",
    "        return Text(t, self.sp.DecodeIds(t.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(PATH/'spm_train.model'))\n",
    "sp.SetEncodeExtraOptions(\"bos:eos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = (ImageList.from_df(df, path=PATH, folder=FOLDER)\n",
    "        .split_by_rand_pct(valid_pct=0.15, seed=42)\n",
    "        .label_from_df(label_cls=SPMList, sp_processor=sp)\n",
    "        .transform(tfms, size=sz, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=bs, device=device, collate_fn=label_collater)\n",
    "        .normalize()\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word_itos = word_itos[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word_itos = pickle.load(open(PATH/'word_itos_60k.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vocab = Vocab(word_itos)\n",
    "procs = [TokenizeProcessor(include_bos=False, include_eos=True), NumericalizeProcessor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = (ImageList.from_df(df, path=PATH, folder=FOLDER, after_open=force_gray)\n",
    "        .split_by_rand_pct(valid_pct=0.15, seed=42)\n",
    "        .label_from_df(label_cls=TextList, pad_idx=0, vocab=vocab, processor=procs)\n",
    "        .transform(tfms, size=sz, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=bs, device=device, collate_fn=label_collater)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "toknizr = Tokenizer(special_cases=[PAD,UNK,PAD,BOS,EOS,TK_MAJ,TK_UP,TK_REP,TK_WREP])\n",
    "procs = [TokenizeProcessor(tokenizer=toknizr, include_bos=False, include_eos=True), NumericalizeProcessor(max_vocab=10000)]\n",
    "\n",
    "data = (ImageList.from_df(df, path=PATH, folder=FOLDER, after_open=force_gray)\n",
    "        .split_by_rand_pct(valid_pct=0.15, seed=42)\n",
    "        .label_from_df(label_cls=TextList, pad_idx=0, processor=procs)\n",
    "        .transform(tfms, size=sz, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=bs, device=device, collate_fn=label_collater)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word_itos = data.train_ds.vocab.itos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.show_batch(rows=2, ds_type=DatasetType.Train, figsize=(18,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# LayerNorm = nn.LayerNorm\n",
    "LayerNorm = partial(nn.LayerNorm, eps=1e-4)  # accomodates mixed precision training\n",
    "# LayerNorm = partial(nn.BatchNorm2d, eps=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"A residual connection followed by a layer norm.  Note: (for code simplicity) norm is first.\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder: self-attn and feed forward\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, src, tgt_mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder: self-attn, src-attn, and feed forward\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)  # wraps layer in residual,dropout,norm\n",
    " \n",
    "    def forward(self, x, src, tgt_mask=None):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))  # acts as a weak LM\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, src, src))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    depth = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(depth)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e4)  #changed from: -1e9 to accomodate mixed precision  \n",
    "    p_attn = F.softmax(scores, dim=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SingleHeadedAttention(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.2):\n",
    "        super(SingleHeadedAttention, self).__init__()\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):        \n",
    "        query, key, value = [l(x) for l, x in zip(self.linears, (query, key, value))]\n",
    "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, d_model, h=8, dropout=0.2):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        self.d_k = d_model // h        # assume d_v always equals d_k\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        if mask is not None: mask = mask.unsqueeze(1)\n",
    "        bs = q.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        q, k, v = [l(x).view(bs, -1, self.h, self.d_k).transpose(1,2) for l, x in zip(self.linears, (q, k, v))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(q, k, v, mask=mask, dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous().view(bs, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# class GeLU(nn.Module):\n",
    "#     def forward(self, x): return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.2):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_model*4)\n",
    "        self.w_2 = nn.Linear(d_model*4, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "#         self.activation = GeLU() #nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.gelu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=2000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0.0, max_len).unsqueeze(1)\n",
    "        log_increment = math.log(1e4) / d_model\n",
    "        div_term = torch.exp(torch.arange(0.0, d_model, 2) * -log_increment)  \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe.unsqueeze_(0)\n",
    "\n",
    "        self.register_buffer('pe', pe)    #(1,max_len,d_model)\n",
    "        # registered buffers are Tensors (not Variables)\n",
    "        # not a parameter but still want in the state_dict\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, tgt, tgt_mask=None):\n",
    "        return self.decode(self.encode(src), tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src):\n",
    "        return self.encoder(src)\n",
    "    \n",
    "    def decode(self, src, tgt, tgt_mask=None):\n",
    "        return self.decoder(self.tgt_embed(tgt), src, tgt_mask)\n",
    "    \n",
    "    def generate(self, outs):\n",
    "        return self.generator(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ResnetBase(nn.Module):\n",
    "    def __init__(self, em_sz, d_model):\n",
    "        super().__init__()\n",
    "        \n",
    "        slices = {128: -4, 256: -3, 512: -2}\n",
    "        s = slices[em_sz]\n",
    "\n",
    "        net = models.resnet34(True)\n",
    "        modules = list(net.children())[:s]\n",
    "        self.base = nn.Sequential(*modules)\n",
    "        \n",
    "        self.linear = nn.Linear(em_sz, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = x.flatten(2,3).permute(0,2,1)\n",
    "        x = self.linear(x) * 8\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_full_model(vocab, d_model, N=4, drops=0.2, attn_type='multi', attn_heads=8, weight_tying=False):\n",
    "    c = deepcopy\n",
    "    \n",
    "    if attn_type=='multi':\n",
    "        attn = MultiHeadedAttention(d_model, attn_heads)\n",
    "    else:\n",
    "        attn = SingleHeadedAttention(d_model)\n",
    "        \n",
    "    ff = PositionwiseFeedForward(d_model, drops)\n",
    "\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), drops), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), drops), N),\n",
    "        nn.Sequential(\n",
    "            Embeddings(d_model, vocab), PositionalEncoding(d_model, drops, 2000)\n",
    "        ),\n",
    "        nn.Linear(d_model, vocab),\n",
    "    )\n",
    "        \n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "                    \n",
    "    if weight_tying:\n",
    "        model.generator.weight = model.tgt_embed[0].lut.weight\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Img2Seq(nn.Module):\n",
    "    def __init__(self, img_encoder, transformer):\n",
    "        super(Img2Seq, self).__init__()\n",
    "        self.img_enc = img_encoder\n",
    "        self.transformer = transformer\n",
    "        \n",
    "    def forward(self, src, tgt=None, tgt_mask=None, seq_len=700):\n",
    "        # inference (greedy decode)\n",
    "        if tgt is None:\n",
    "            with torch.no_grad():\n",
    "                feats = self.transformer.encode(self.img_enc(src))\n",
    "                bs = src.size(0)\n",
    "                tgt = torch.ones((bs,1), dtype=torch.long, device=device)\n",
    "\n",
    "                res = []\n",
    "                for i in progress_bar(range(seq_len)):\n",
    "                    mask = subsequent_mask(tgt.size(-1))\n",
    "                    dec_outs = self.transformer.decode(feats, tgt, mask)\n",
    "                    prob = self.transformer.generate(dec_outs[:,-1])\n",
    "                    res.append(prob)\n",
    "                    pred = torch.argmax(prob, dim=-1, keepdim=True)\n",
    "                    if (pred==0).all(): break\n",
    "                    tgt = torch.cat([tgt,pred], dim=-1)\n",
    "                out = torch.stack(res).transpose(1,0).contiguous()\n",
    "                \n",
    "        #training\n",
    "        else:\n",
    "            feats = self.img_enc(src)\n",
    "            dec_outs = self.transformer(feats, tgt, tgt_mask)    # ([bs, sl, d_model])\n",
    "            out = self.transformer.generate(dec_outs)            # ([bs, sl, vocab])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_learner(data, d_model, em_sz, N=4, drops=0.2, attn_type='multi', attn_heads=8):\n",
    "    img_encoder = ResnetBase(em_sz, d_model)\n",
    "    transformer = make_full_model(len(itos), d_model, N=N, drops=drops, attn_type=attn_type, attn_heads=attn_heads)\n",
    "    net = Img2Seq(img_encoder, transformer)\n",
    "    return Learner(data, net, loss_func=LabelSmoothing(smoothing=0.1),\n",
    "                    metrics=[CER()], callback_fns=[TeacherForce])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# w/ Transformer LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class DecoderLayerWithLM(nn.Module):\n",
    "    \"Decoder: self-attn, src-attn, and feed forward\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 4)  # wraps layer in residual,dropout,norm\n",
    " \n",
    "    def forward(self, x, src, tgt_mask=None):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))  # shared btw lm and decoder\n",
    "        dec = self.sublayer[1](x, lambda x: self.src_attn(x, src, src))\n",
    "        return self.sublayer[2](dec, self.feed_forward) + self.sublayer[3](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# w/ AWDLSTM LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, tgt_emb, pos_enc, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.tgt_emb = tgt_emb\n",
    "        self.pos_enc = pos_enc\n",
    "        self.generator = generator\n",
    "        self.embed = None\n",
    "        \n",
    "    def forward(self, src, tgt, tgt_mask=None):\n",
    "        return self.decode(self.encode(src), tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src):\n",
    "        return self.encoder(src)\n",
    "    \n",
    "    def decode(self, src, tgt, tgt_mask=None):\n",
    "        self.embed = self.tgt_emb(tgt)\n",
    "        return self.decoder(self.pos_enc(self.embed), src, tgt_mask)\n",
    "    \n",
    "    def generate(self, outs):\n",
    "        return self.generator(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ResnetBase(nn.Module):\n",
    "    def __init__(self, em_sz, d_model):\n",
    "        super().__init__()\n",
    "        \n",
    "        slices = {128: -4, 256: -3, 512: -2}\n",
    "        s = slices[em_sz]\n",
    "\n",
    "        net = models.resnet34(True)\n",
    "        modules = list(net.children())[:s]\n",
    "        self.base = nn.Sequential(*modules)\n",
    "        \n",
    "        self.linear = nn.Linear(em_sz, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = x.flatten(2,3).permute(0,2,1)\n",
    "        x = self.linear(x) * 8   #(cube root of d_model?)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_full_model(vocab, d_model, N=4, drops=0.2, attn_type='multi', attn_heads=8, weight_tying=False):\n",
    "    c = deepcopy\n",
    "    \n",
    "    if attn_type=='multi':\n",
    "        attn = MultiHeadedAttention(d_model, attn_heads)\n",
    "    else:\n",
    "        attn = SingleHeadedAttention(d_model)\n",
    "        \n",
    "    ff = PositionwiseFeedForward(d_model, drops)\n",
    "\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), drops), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), drops), N),\n",
    "        Embeddings(d_model, vocab),\n",
    "        PositionalEncoding(d_model, drops, 2000),\n",
    "        nn.Linear(d_model, vocab),\n",
    "    )\n",
    "        \n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "                    \n",
    "    if weight_tying:\n",
    "        model.generator.weight = model.tgt_embed[0].lut.weight\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LM(nn.Module):\n",
    "    def __init__(self, vocab, d_model, n_hidden, n_layers):\n",
    "        super(LM, self).__init__()\n",
    "        self.lm = AWD_LSTM(vocab, d_model, n_hidden, n_layers, pad_token=0,\n",
    "                           hidden_p=0.1, input_p=0.25, embed_p=0.05, weight_p=0.2)\n",
    "        \n",
    "        #self.mixer = nn.Linear(d_model, d_model)\n",
    "        self.mixer = nn.Sequential(PositionwiseFeedForward(d_model, 0.2), LayerNorm(d_model))\n",
    "        \n",
    "    def forward(self, outs, tgts, decode=False):\n",
    "        res,_ = self.lm(tgts, from_embeddings=True)\n",
    "        lm_outs = res[-1]\n",
    "        if decode: lm_outs = lm_outs[:,-1]\n",
    "        return self.mixer(lm_outs+outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Img2Seq(nn.Module):\n",
    "    def __init__(self, img_encoder, transformer, lm):\n",
    "        super(Img2Seq, self).__init__()\n",
    "        self.img_enc = img_encoder\n",
    "        self.transformer = transformer\n",
    "        self.lm = lm\n",
    "        \n",
    "    def forward(self, src, tgt=None, tgt_mask=None, seq_len=700):\n",
    "        # inference (greedy decode)\n",
    "        if tgt is None:\n",
    "            with torch.no_grad():\n",
    "                feats = self.transformer.encode(self.img_enc(src))\n",
    "                bs = src.size(0)\n",
    "                tgt = torch.ones((bs,1), dtype=torch.long, device=device)\n",
    "\n",
    "                res = []\n",
    "                for i in progress_bar(range(seq_len)):\n",
    "                    mask = subsequent_mask(tgt.size(-1))\n",
    "                    dec_outs = self.transformer.decode(feats, tgt, mask)\n",
    "                    outs = self.lm(dec_outs[:,-1], self.transformer.embed, decode=True)\n",
    "                    prob = self.transformer.generate(outs)\n",
    "                    res.append(prob)\n",
    "                    pred = torch.argmax(prob, dim=-1, keepdim=True)\n",
    "                    if (pred==0).all(): break\n",
    "                    tgt = torch.cat([tgt,pred], dim=-1)\n",
    "                out = torch.stack(res).transpose(1,0).contiguous()\n",
    "                \n",
    "        #training\n",
    "        else:\n",
    "            feats = self.img_enc(src)\n",
    "            dec_outs = self.transformer(feats, tgt, tgt_mask)    # ([bs, sl, d_model])\n",
    "            outs = self.lm(dec_outs, self.transformer.embed)\n",
    "            out = self.transformer.generate(outs)            # ([bs, sl, vocab])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_learner(data, d_model, em_sz, N=4, drops=0.2, attn_type='multi', attn_heads=8):\n",
    "    img_encoder = ResnetBase(em_sz, d_model)\n",
    "    transformer = make_full_model(len(itos), d_model, N=N, drops=drops, attn_type=attn_type, attn_heads=attn_heads)\n",
    "    lm = LM(len(itos), d_model, 1400, 3)\n",
    "    net = Img2Seq(img_encoder, transformer, lm)\n",
    "    return Learner(data, net, loss_func=LabelSmoothing(smoothing=0.1),\n",
    "                    metrics=[CER()], callback_fns=[TeacherForce])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Add LM to model state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sd = torch.load(PATH/'models/combo_512_9.pth', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# update existing model according to LM changes\n",
    "sd['model']['transformer.tgt_emb.lut.weight'] = sd['model']['transformer.tgt_embed.0.lut.weight']\n",
    "sd['model'][\"transformer.pos_enc.pe\"] = sd['model']['transformer.tgt_embed.1.pe']\n",
    "\n",
    "del sd['model']['transformer.tgt_embed.1.pe']\n",
    "del sd['model']['transformer.tgt_embed.0.lut.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lm_sd = torch.load('data/wikitext/models/wiki103_lm_enc.pth', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "new_lm_sd = OrderedDict()\n",
    "for k, v in lm_sd.items():\n",
    "    name = 'lm.lm.'+k\n",
    "    new_lm_sd[name] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sd['model'].update(new_lm_sd)\n",
    "\n",
    "learn.model.load_state_dict(sd['model'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tie weights of transformer embedding and generator w/ lm encodings\n",
    "learn.model.transformer.tgt_emb.lut.weight = learn.model.lm.lm.encoder.weight\n",
    "learn.model.transformer.generator.weight = learn.model.lm.lm.encoder.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('combo_512_9_wiki103_base_lm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## load and split learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('combo_512_9_wiki103_base_lm')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.split([learn.model.img_enc, learn.model.transformer, learn.model.lm.lm, learn.model.lm.mixer])\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.model.lm.lm.encoder.weight.requires_grad, learn.model.lm.mixer.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lrs = slice(2e-5, 2e-4, 2e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment - Chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = make_learner(data, 512, 512, N=4, drops=0.1, attn_type='multi')\n",
    "# Total # of trainable params:\n",
    "# N=6: 65,786,272\n",
    "# N=4: 51,073,440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# true number of trainable params\n",
    "sum(p.numel() for p in learn.model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('combo_512_9')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5, max_lr=1e-3, callbacks=[SaveModelCallback(learn, name='combo_512_10')])\n",
    "#sm\n",
    "#5cycle,1e-3\n",
    "\n",
    "# 2.474220\t4.081600\t0.036482  N:4,F.gelu,sz:256,em_sz:512,single,drop:0  'sm_256_1'\n",
    "# greedy:    1.36697   .066\n",
    "# 4.430638\t4.402001\t0.034730  2nd run, lr:1.5e-5, add tfms, drop:0.2   'sm_256_2'\n",
    "# greedy:    0.37206   .04145\n",
    "\n",
    "# 5.158808\t4.964441\t0.042544  \"\", w/ tfms, drop:0.2   'sm_256_3'\n",
    "# greedy:    0.50646   .04103\n",
    "# 4.266788\t4.694098\t0.039822  2nd run, lr:1.5e-5   'sm_256_4'\n",
    "# greedy:    0.38972   .03879\n",
    "\n",
    "# 3.678168\t3.962710\t0.035466  N:8,tfms   'sm_256_5'\n",
    "# greedy:    0.38097   .04405\n",
    "\n",
    "# 2.840161\t3.429177\t0.030243  N:4,tfms,multi(8)  'sm_256_6'\n",
    "# greedy:    0.32775   .04201\n",
    "\n",
    "# 3.377438\t3.786088\t0.033931   N:6,tfms,drop:0.1,multi(8)   'sm_256_7'\n",
    "# greedy:    0.36201   .04266\n",
    "\n",
    "# combo_cat6 - preload 'sm_256_7'\n",
    "# 7.570516\t6.670641\t0.015070    'combo_512_7'\n",
    "# greedy:    6.29406   .02186\n",
    "\n",
    "# combo_cat_pg - preload 'combo_512_7'\n",
    "# 25.674347\t21.161726\t0.015869    'combo_512_8'\n",
    "# greedy:    114.878   .03654\n",
    "#   test:    115.247   .05014\n",
    "\n",
    "# combo_cat_pg_dl_sorted - preload 'combo_512_8', 5cycle, 1.5e-4\n",
    "# 9.800321\t5.676855\t0.006939    'combo_512_9'\n",
    "# greedy:    34.8757   .01523\n",
    "\n",
    "#   test:    91.3226   .05102\n",
    "#   test:    104.685   .05483\n",
    "#   test:    116.467   .05315\n",
    "\n",
    "# upload:    115.149   .66801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learn.save('combo_512_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Experiment - Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = make_learner(data, 512, 512, N=6, drops=0.1, attn_type='multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('combo_512_9')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(15, max_lr=1e-3, callbacks=[SaveModelCallback(learn, name='word_sm_2')])\n",
    "\n",
    "# word 60k\n",
    "# sm, 5cycle, 1e-3\n",
    "\n",
    "# 22.903589\t22.401066\t0.520125   N:6,em_sz:512,tfms,drop:0.1,multi(8)  'word_sm_1'\n",
    "# 32.389709\t31.828810\t0.746749   N:4,em_sz:512,tfms,drop:0.1,single\n",
    "# 34.492157\t32.719650\t0.776098   \"\",em_sz:256\n",
    "\n",
    "# word 7k (auto-tokenize from data)\n",
    "# sm, 5cycle, 1e-3\n",
    "# 16.987526\t16.639275\t0.421535   N:4,em_sz:512,tfms,drop:0.1,single\n",
    "# 10.224819\t10.781199\t0.297889   2nd run\n",
    "# 6.486265\t7.934221\t0.225055   3rd run    'word_sm_4'\n",
    "\n",
    "# word 10k (itos from larger txt files)\n",
    "# sm, 15cycle, 1e-3\n",
    "# 3.893518\t6.037587\t0.209027   N:4,em_sz:512,tfms,drop:0.1,single   'word_sm_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None, alpha=None, title=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(image2np(im.data), alpha=alpha)\n",
    "    if title: ax.set_title(title)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def full_test(learn, sl, dl=data.valid_dl, batches=20):\n",
    "    learn.model.eval()\n",
    "    iterable = iter(dl)\n",
    "    g_loss,g_cer=0,0\n",
    "    if batches is None:\n",
    "        batches = len(dl.dl.dataset)//bs\n",
    "    for i in progress_bar(range(batches)):\n",
    "        x,y = next(iterable)\n",
    "        g_preds = learn.model(x, seq_len=sl)\n",
    "        g_res = torch.argmax(g_preds, dim=-1)\n",
    "        g = [learn.loss_func(g_preds, y).item()/bs, cer(g_preds, y)[0]/bs]\n",
    "        g_loss+=g[0]\n",
    "        g_cer+=g[1]\n",
    "    return [g_loss/batches, g_cer/batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "g = full_test(learn, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'greedy:    {str(g[0])[:7]}   {str(g[1])[1:7]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# losses = np.array([learn.loss_func(g_preds[i:i+1],y[i:i+1]).item() for i in range(bs)])\n",
    "# cers = np.array([cer(g_preds[i:i+1],y[i:i+1])[0] for i in range(bs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(learn.data.train_dl))\n",
    "\n",
    "g_preds = learn.model(x, seq_len=20)\n",
    "g_res = torch.argmax(g_preds, dim=-1)\n",
    "g = [learn.loss_func(g_preds, y).item()/bs, cer(g_preds, y)[0]/bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#greedy\n",
    "fig, axes = plt.subplots(2,3, gridspec_kw={'hspace': 0.4}, figsize=(18, 20))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    p = char_label_text(g_res[i], sep=' ')\n",
    "    ax=show_img(x[i], ax=ax, title=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(learn.data.train_dl))\n",
    "\n",
    "g_preds = learn.model(x, seq_len=seq_len)\n",
    "g_res = torch.argmax(g_preds, dim=-1)\n",
    "g = [learn.loss_func(g_preds, y).item()/bs, cer(g_preds, y)[0]/bs]\n",
    "\n",
    "print(f'  test:    {str(g[0])[:7]}   {str(g[1])[1:7]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "fig, axes = plt.subplots(2,2, gridspec_kw={'hspace': 0.4}, figsize=(18, 20))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    #i +=8\n",
    "    p = char_label_text(g_res[i])\n",
    "    ax=show_img(x[i], ax=ax, title=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {}
   },
   "source": [
    "## Single Test Image (cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = data.train_ds[2]\n",
    "pred = learn.predict(x)\n",
    "show_img(x, title=str(pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scores, idxs = torch.topk(pred[2], 3, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chars = idxs.numpy()\n",
    "chars.appl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idxs.apply_(lambda x: itos[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    print(char_label_text(idxs[i], sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learn.show_results(ds_type=data.train_ds, rows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "x = xs[i][None]\n",
    "y = ys[i][None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch = data.one_item(xs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xs,ys = data.one_batch(detach=False, denorm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "g_preds = learn.model(x, seq_len=seq_len)\n",
    "g_res = torch.argmax(g_preds, dim=-1)\n",
    "g = [learn.loss_func(g_preds, y).item(), cer(g_preds, y)[0]]\n",
    "\n",
    "print(f'  test:    {str(g[0])[:7]}   {str(g[1])[1:7]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p = char_label_text(g_res[0])\n",
    "show_img(x[0], figsize=(18,10), title=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "im = PATH/'uploads'/'test1.png'\n",
    "img = open_image(im)\n",
    "prediction = learn.predict(img)[0]\n",
    "show_img(img, title=str(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def cer(preds, targs):\n",
    "#     bs = targs.size(0)\n",
    "#     res = torch.argmax(preds, dim=-1)\n",
    "#     error = 0\n",
    "#     for i in range(bs):\n",
    "#         p = char_label_text(res[i])   #.replace(' ', '')\n",
    "#         t = char_label_text(targs[i]) #.replace(' ', '')\n",
    "#         error += Lev.distance(t, p)/len(t)\n",
    "#     return error\n",
    "\n",
    "# def char_label_text(pred):\n",
    "#     ints = to_np(pred).astype(int)\n",
    "#     nonzero = ints[np.nonzero(ints)] #[:-1]  #remove bos/eos token\n",
    "#     return ''.join([itos[i] for i in nonzero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def self_attn(layer=-1): return learn.model.transformer.decoder.layers[layer].self_attn.attn.data.cpu()\n",
    "def source_attn(layer=-1): return learn.model.transformer.decoder.layers[layer].src_attn.attn.data.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None, alpha=None, title=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    if im.shape[0] == 3: im = image2np(im.data)\n",
    "    ax.imshow(im, alpha=alpha)\n",
    "    if title: ax.set_title(title)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(learn.data.valid_dl))\n",
    "# x,y = learn.data.one_batch(ds_type=DatasetType.Train)\n",
    "imgs = x #learn.data.denorm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Uploaded Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def thresh_edit(fname, thresh=100, bg=245):\n",
    "    im = Image.open(fname).convert('L')  #grayscale\n",
    "    np_im = np.array(im)\n",
    "    im.close()\n",
    "    thresh_mask = np_im > thresh\n",
    "    np_im[thresh_mask] = bg\n",
    "    return Image.fromarray(np_im, 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "im = thresh_edit(PATH/'test3.png')\n",
    "show_img(im, figsize=(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "e = 'edit_'+str(fname.name)\n",
    "edited_fname = PATH/e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "edited_im.save(edited_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname = PATH/'test/edit_test4.png'\n",
    "im = open_image(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seq,res,preds = learn.predict(im)\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# r = torch.tensor([g_res], dtype=torch.long, device=device)\n",
    "truth = \"This is a test letter. I hope this\\nworks but I'm not sure it will.\\nMy handwriting is not very good.\"\n",
    "Lev.distance(truth, str(seq))/len(truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# x,y = next(v_dl)\n",
    "# imgs = denorm(x)\n",
    "\n",
    "learn.model.eval()\n",
    "\n",
    "shifted_y = rshift(y).long()\n",
    "tgt_mask = subsequent_mask(shifted_y.size(-1))\n",
    "v_preds = learn.model(x, shifted_y, tgt_mask)\n",
    "v_res = torch.argmax(v_preds, dim=-1)\n",
    "v_attn = source_attn()\n",
    "\n",
    "g_preds = learn.model(x)\n",
    "g_res = torch.argmax(g_preds, dim=-1)\n",
    "g_attn = source_attn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "v = [learn.loss_func(v_preds, y).item(), cer(v_preds, y)]\n",
    "print(f'valid:     {str(v[0])[:7]}   {str(v[1][0])[1:7]}')\n",
    "\n",
    "g = [learn.loss_func(g_preds, y).item(), cer(g_preds, y)]\n",
    "print(f'greedy:    {str(g[0])[:7]}   {str(g[1][0])[1:7]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#valid\n",
    "fig, axes = plt.subplots(1,3, gridspec_kw={'hspace': 0.4}, figsize=(20, 10))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    p = char_label_text(v_res[i])\n",
    "    ax=show_img(imgs[i], ax=ax, title=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#greedy\n",
    "fig, axes = plt.subplots(1,3, gridspec_kw={'hspace': 0.4}, figsize=(18, 10))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    p = char_label_text(g_res[i])\n",
    "    ax=show_img(imgs[i], ax=ax, title=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_data = (ImageList.from_df(test_df, path=PATH, folder=TEST_FOLDER)\n",
    "             .split_none()\n",
    "             .label_from_df(label_cls=TextList, sep='', pad_idx=0, vocab=vocab, processor=procs)\n",
    "             .transform([], size=sz, resize_method=ResizeMethod.SQUISH)\n",
    "             .databunch(bs=bs, device=device, collate_fn=label_collater)\n",
    "             .normalize()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tx,ty = next(iter(test_data.train_dl))\n",
    "t_imgs = test_data.denorm(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t_preds = learn.model(tx)\n",
    "t_res = torch.argmax(t_preds, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = [learn.loss_func(t_preds, ty).item(), cer(t_preds, ty)]\n",
    "print(f'test:      {str(g[0])[:7]}   {str(g[1])[:7]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "fig, axes = plt.subplots(1,3, gridspec_kw={'hspace': 0.4}, figsize=(18, 10))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    p = char_label_text(t_res[i])\n",
    "    ax=show_img(t_imgs[i], ax=ax, title=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tfmr full\n",
    "#             loss       cer       acc\n",
    "# valid:     2.42856   0.02981   0.98177   3x1, 256/60, 'tfmr_full_3x1_single_attn'\n",
    "# greedy:    11.9438   0.02745   0.93385\n",
    "\n",
    "# valid:     1.98831   0.01858   0.98505   3x1, 256/60, 'exp_3x1_256'\n",
    "# greedy:    16.3832   0.02167   0.90944\n",
    "\n",
    "# valid:     1.47604   0.00797   0.99523   3x2, 400/45,  'tfmr_full_3x2'\n",
    "# greedy:    21.4682   0.01097   0.93762\n",
    "\n",
    "# valid:     7.30494   0.01206   0.99086   lg,  512/30,  'tfmr_full_lg'\n",
    "# greedy:    434.610   0.02398   0.69553\n",
    "\n",
    "# valid:     25.4131   0.04500   0.96773   lg, 512/30,   'tfmr_lg_LM_mixer'\n",
    "# greedy:    734.834   0.15256   0.48912\n",
    "\n",
    "# valid:     10.1481   0.00501   0.99602   cat9-12,  800/8,  'tfmr_cat9-12_full_800'\n",
    "# greedy:    1330.63   0.04525   0.53181\n",
    "\n",
    "# valid:     62.0793   0.05716   0.96214   pg,  512/20  'tfmr_full_paragraph'  (cpu)\n",
    "# greedy:    1739.62   0.08347   0.43309\n",
    "# beam:                0.07958\n",
    "# valid:     71.9120   0.06819   0.95457   \"\", 2nd batch (gpu)\n",
    "# greedy:    2027.24   0.11823   0.39238\n",
    "# beam:                0.10697\n",
    "# valid:     36.3009   0.03397   0.97633   \"\", 3rd batch (gpu)\n",
    "# greedy:    1759.59   0.07070   0.40949\n",
    "    \n",
    "# valid:     50.1414   0.04137   0.97004   pg,  1000/5,  'tfmr_pg_1000'\n",
    "# greedy:    2579.24   0.34178   0.18623\n",
    "\n",
    "# valid:     56.2722   0.04167   0.96923   pg,  1000/5,  'tfmr_catpg_1000'\n",
    "# greedy:    2432.54   0.37192   0.26174\n",
    "\n",
    "\n",
    "# valid:     3.43745   0.05444   0.98735   mix(new)  'tfmr_mix_words_400'\n",
    "# greedy:    43.6545   0.06126   0.91407\n",
    "\n",
    "# valid:     2.96891   0.03338   0.98932   mix(new)  'tfmr_mix_words_512'\n",
    "# greedy:    28.9982   0.03949   0.94500\n",
    "# valid:     2.02411   0.02128   0.99302   5 more cycles\n",
    "# greedy:    19.4735   0.02450   0.96104\n",
    "\n",
    "# valid:     41.9800   0.03879   0.97535   pg, 'tfmr_mix_words_512'\n",
    "# greedy:    1602.68   0.06259   0.49110\n",
    "\n",
    "\n",
    "# valid:     53.9049   0.04822   0.96622   pg, 'tfmr_8head_512_mix'\n",
    "# greedy:    1384.72   0.06304   0.51696\n",
    "\n",
    "\n",
    "# valid:     5.24461   0.00634   mix   'v1_gelu_512'\n",
    "# greedy:    217.438   0.02028\n",
    "# valid:     24.3609   0.02405   pg\n",
    "# greedy:    1935.30   0.05970\n",
    "\n",
    "# valid:     12.7074   0.00954   mix   'v1_gelu_512_wiki103_base_lm_last_layer'\n",
    "# greedy:    553.201   0.02814\n",
    "\n",
    "# valid:     11.4251   0.00474   mix   'v1_gelu_512_wiki103_base_lm_full'\n",
    "# greedy:    358.030   0.01187\n",
    "\n",
    "# valid:     12.1104   0.01533   mix   'v1_gelu_multi_512'\n",
    "# greedy:    506.505   0.04229\n",
    "\n",
    "\n",
    "# edited data\n",
    "# valid:     8.21437   0.06576   sm   'v1_gelu_128'\n",
    "# greedy:    185.981   0.12890\n",
    "\n",
    "# valid:     2.25060   0.01731   sm   'v1_gelu_256'\n",
    "# greedy:    149.525   0.06003\n",
    "\n",
    "# valid:     2.37294   0.01383   mix  'v1_edited_gelu_400'\n",
    "# greedy:    30.3637   0.01732\n",
    "# greedy:    1810.14   0.11409   test\n",
    "\n",
    "# valid:     9.09986   0.01656   mix  'v1_edited_gelu_512'\n",
    "# greedy:    529.308   0.03104\n",
    "# greedy:    1675.20   0.10819   test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Multi-Batch Beam Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def beam_cer(preds, targs):\n",
    "    bs = preds.size(0)\n",
    "    error = 0\n",
    "    for i in range(bs):\n",
    "        p = char_label_text(preds[i])\n",
    "        t = char_label_text(targs[i])\n",
    "        error += _cer(t,p)\n",
    "    return error/bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def repeat_interleave(tensor,n):\n",
    "    res = []\n",
    "    for i in range(tensor.size(0)):\n",
    "        for _ in range(n): res.append(tensor[i])\n",
    "    return torch.stack(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def normalize_score(score, i, alpha=0.6):\n",
    "#     length_penalty = math.pow((5 + i)/6, alpha)\n",
    "#     return score/length_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Beam Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class Beam(object):\n",
    "    def __init__(self, beam_width=10):\n",
    "        self.heap = list()\n",
    "        self.beam_width = beam_width\n",
    "        self.best_score = None\n",
    "\n",
    "    def add(self, score, complete, seq):        \n",
    "        heapq.heappush(self.heap, (score, complete, seq))\n",
    "        if len(self.heap) > self.beam_width:\n",
    "            heapq.heappop(self.heap)\n",
    "            \n",
    "    def get_seq(self):\n",
    "        return [b[-1] for b in self.heap]\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return iter(self.heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class BeamSearch(nn.Module):\n",
    "    def __init__(self, net, beam_width, seq_len, end_tok=0):\n",
    "        super(BeamSearch, self).__init__()\n",
    "        self.img_enc = net.img_enc\n",
    "        self.transformer = net.transformer\n",
    "        self.bw = beam_width\n",
    "        self.seq_len = seq_len\n",
    "        self.end_tok = end_tok\n",
    "        self.feats = None\n",
    "        self.beams = []\n",
    "            \n",
    "    def forward(self, src):\n",
    "        with torch.no_grad():\n",
    "            bs = src.size(0)\n",
    "            \n",
    "            # initialize beam per bs\n",
    "            for _ in range(bs):\n",
    "                beam = Beam(self.bw)\n",
    "                beam.add(0.0, False, [1])\n",
    "                self.beams.append(beam)\n",
    "                \n",
    "            # encode src\n",
    "            self.feats = self.transformer.encode(self.img_enc(src))\n",
    "            \n",
    "            for i in tqdm(range(seq_len)):\n",
    "                # gather sequences from beams; combine into tensor (bs*bw)\n",
    "                prev_seq = torch.from_numpy(np.stack([b.get_seq() for b in self.beams])).view(-1,i+1)\n",
    "                \n",
    "                # generate new possibilities\n",
    "                log_probs, chars = self.prob_func(prev_seq.to(device))\n",
    "                log_probs, chars = log_probs.view(bs,-1,self.bw), chars.view(bs,-1,self.bw)\n",
    "                \n",
    "                for j in range(bs):\n",
    "                    curr_beam = Beam(self.bw)\n",
    "                    for k,(score, complete, seq) in enumerate(self.beams[j]):\n",
    "                        for l,c in zip(log_probs[j,k],chars[j,k]):\n",
    "                            log_prob,char = l.item(), c.item()\n",
    "                            curr_beam.add((score+log_prob), (char==self.end_tok), seq+[char])\n",
    "                    self.beams[j] = curr_beam\n",
    "  \n",
    "                # return if all max beams are complete\n",
    "                if (self.top_complete()==True).all(): break\n",
    "                    \n",
    "                # expand feats to match beam size (only on 2nd run)\n",
    "                if i==0: self.feats = repeat_interleave(self.feats, self.bw)\n",
    "\n",
    "            return self.top_seq()\n",
    "\n",
    "    def top_complete(self): return np.stack([max(b)[1] for b in self.beams])\n",
    "    def top_seq(self): return torch.from_numpy(np.stack([max(b)[-1] for b in self.beams]))[:,1:]\n",
    "\n",
    "    def prob_func(self, tgt):\n",
    "        mask = subsequent_mask(tgt.size(-1))\n",
    "        dec_outs = self.transformer.decode(self.feats, tgt, mask)\n",
    "        logits = self.transformer.generate(dec_outs[:,-1])\n",
    "        log_probs = logits - torch.logsumexp(logits, -1, keepdim=True) # more stable than F.softmax(logits,-1).log()\n",
    "        return torch.topk(log_probs, self.bw, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "search = BeamSearch(learn.model, 3, seq_len)\n",
    "b_res = search(x)\n",
    "\n",
    "# bw: 3, sl: 350, ~56s, 0.02491    # no normalized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "beam_cer(b_res,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class BeamSearch(nn.Module):\n",
    "    def __init__(self, net, beam_width, seq_len):\n",
    "        super(BeamSearch, self).__init__()\n",
    "        self.img_enc = net.img_enc\n",
    "        self.transformer = net.transformer\n",
    "        self.bw = beam_width\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.feats = None\n",
    "        self.beam = None\n",
    "        self.scores = None\n",
    "        \n",
    "        net.eval()\n",
    "    \n",
    "    def forward(self, src):\n",
    "        with torch.no_grad():\n",
    "            bs = src.size(0)\n",
    "            \n",
    "            # encode src\n",
    "            self.feats = self.transformer.encode(self.img_enc(src))\n",
    "            \n",
    "            # initialize globals (beam=1 for first iteration; 3 thereafter)\n",
    "            self.beam = torch.ones((bs,1), device=device, dtype=torch.long)\n",
    "            self.scores = torch.zeros((bs,1), device=device, dtype=torch.float)\n",
    "            \n",
    "            for i in tqdm(range(seq_len)):\n",
    "                # generate new topk chars per beam(bs*bw)\n",
    "                log_probs, chars = self.prob_func(self.beam)  #(bs*beam, 3)\n",
    "\n",
    "                # compute local scores\n",
    "                scores = self.scores + log_probs\n",
    "                \n",
    "                # compute new beams per batch\n",
    "                new_scores, idxs = torch.topk(scores.view(bs,-1), self.bw, dim=-1) #(bs, 3)\n",
    "                self.scores = new_scores.view(-1,1)\n",
    "                \n",
    "                # set up new beam:\n",
    "                nxt = torch.stack([c[i] for c,i in zip(chars.view(bs,-1),idxs)]).view(-1,1)\n",
    "                pre = torch.stack([b[i//self.bw] for b,i in zip(self.beam.view(bs,-1,i+1),idxs)]).view(-1,i+1)\n",
    "                                    \n",
    "                # update globals\n",
    "                self.beam = torch.cat([pre,nxt], dim=1)\n",
    "\n",
    "                # end when top of beams are complete\n",
    "                if self.top_complete(): break\n",
    "                                                        \n",
    "                # expand feats to match beam size (only on 2nd run)\n",
    "                if i==0: self.feats = repeat_interleave(self.feats, self.bw) #.repeat(self.bw,1,1)\n",
    "                    \n",
    "            return self.top_sequences(), self.top_scores() \n",
    "\n",
    "\n",
    "    def top_complete(self): return (self.top_sequences()[:,-1]==0).all().item()   #byte tensor\n",
    "    def top_sequences(self): return self.beam.squeeze()[0::self.bw][:,1:]\n",
    "    def top_scores(self): return self.scores.squeeze()[0::self.bw]\n",
    "\n",
    "    def prob_func(self, tgt):\n",
    "        mask = subsequent_mask(tgt.size(-1))\n",
    "        dec_outs = self.transformer.decode(self.feats, tgt, mask)\n",
    "        logits = self.transformer.generate(dec_outs[:,-1])\n",
    "        log_probs = logits - torch.logsumexp(logits, -1, keepdim=True) # more stable than F.softmax(logits,-1).log()\n",
    "        return torch.topk(log_probs, self.bw, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "search = BeamSearch(learn.model, 3, seq_len)\n",
    "b_res,score = search(x)\n",
    "\n",
    "# lg, sl: 250\n",
    "# bw: 1, ~12s, 0.02398\n",
    "# bw: 3, ~28s, 0.02378\n",
    "# bw: 5, ~46s, 0.02378\n",
    "\n",
    "# pg: 1000,5\n",
    "# bs: 3, ~40s, 0.33227  (greedy: 0.28---)\n",
    "# ''   , ~30s, 0.22635  (greedy: 0.23726)\n",
    "\n",
    "# pg: 800,8\n",
    "# bs: 3, ~51s, 0.25424  (greedy: 0.28348)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "beam_cer(b_res,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#beam\n",
    "fig, axes = plt.subplots(1,3, gridspec_kw={'hspace': 0.4}, figsize=(20, 10))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    p = char_label_text(b_res[i], chunk=55)\n",
    "    ax=show_img(imgs[i], ax=ax, title=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Single Beam Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://geekyisawesome.blogspot.com/2016/10/using-beam-search-to-generate-most.html\n",
    "\n",
    "import heapq\n",
    "\n",
    "class Beam(object):\n",
    "    '''\n",
    "    For comparison of prefixes, the tuple (prefix_probability, complete_sentence) is used.\n",
    "    This is so that if two prefixes have equal probabilities then a complete sentence\n",
    "    is preferred over an incomplete one since (0.5, False) < (0.5, True)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, beam_width=10):\n",
    "        self.heap = list()\n",
    "        self.beam_width = beam_width\n",
    "        self.best_score = None\n",
    "\n",
    "    def add(self, score, complete, seq):        \n",
    "        # keep track of best_score so far\n",
    "        if self.best_score is None or score > self.best_score:\n",
    "            self.best_score = score\n",
    "            \n",
    "        # only add to beam if score is not more than beam_width below the best_score\n",
    "        if score > self.best_score-self.beam_width:\n",
    "            heapq.heappush(self.heap, (score, complete, seq))\n",
    "            \n",
    "        # maintain beam_width\n",
    "        if len(self.heap) > self.beam_width:\n",
    "            heapq.heappop(self.heap)\n",
    "                \n",
    "    def __iter__(self):\n",
    "        return iter(self.heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def beamsearch(prob_fn, seq_len, beam_width=5, start_tok=1, end_tok=3):\n",
    "    prev_beam = Beam(beam_width)\n",
    "    prev_beam.add(0.0, False, [start_tok])\n",
    "    \n",
    "    for i in tqdm(range(seq_len)):\n",
    "        curr_beam = Beam(beam_width)\n",
    "        \n",
    "        # iterate over each beam\n",
    "        for (score, complete, seq) in prev_beam:\n",
    "            if complete == True:\n",
    "                None  # only keep the completed best beam!!\n",
    "#                 curr_beam.add(score, True, seq)\n",
    "            else:\n",
    "                # iterate through topk chars, calculating scores and adding to the beam.\n",
    "                log_probs, chars = prob_fn(seq)\n",
    "                for log_prob, char in zip(log_probs, chars): \n",
    "                    log_prob,char = log_prob.item(), char.item()\n",
    "                    score += log_prob   #log probabilities are additive\n",
    "#                     score = score_func(score, len(seq))\n",
    "                    curr_beam.add(score, (char==end_tok), seq+[char])\n",
    "        \n",
    "        (best_score, best_complete, best_seq) = max(curr_beam)\n",
    "        if best_complete == True: return (best_seq[1:], best_score)   # returns first complete beam not best...\n",
    "            \n",
    "        prev_beam = curr_beam\n",
    "        \n",
    "    (best_score, best_complete, best_seq) = max(curr_beam)\n",
    "    return (best_seq[1:], best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def beam_decode(net, src, beam_width, seq_len):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        feats = net.transformer.encode(net.img_enc(src))        \n",
    "        return beamsearch(partial(prob_func, net=net, feats=feats, beam_width=beam_width), seq_len, beam_width)\n",
    "    \n",
    "def prob_func(tgt, net=None, feats=None, beam_width=5):\n",
    "    tgt = torch.tensor([tgt], dtype=torch.long, device=device)\n",
    "    mask = subsequent_mask(tgt.size(-1))\n",
    "    dec_outs = net.transformer.decode(feats, tgt, mask)\n",
    "    logits = net.transformer.generate(dec_outs[:,-1])\n",
    "    \n",
    "    log_probs = logits - torch.logsumexp(logits, 1)  # more numerically stable\n",
    "    # log_probs = F.softmax(logits, -1).log()\n",
    "    \n",
    "    return torch.topk(log_probs.squeeze(0), beam_width, dim=-1)\n",
    "#     return zip(res[0][0].detach(),res[1][0].detach())\n",
    "\n",
    "def score_func(log_probs, i, alpha=0.6):\n",
    "    length_penalty = math.pow((5 + i)/6, alpha)\n",
    "    return log_probs/length_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx = 2\n",
    "x1 = x[idx][None]\n",
    "y1 = y[idx][None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "b_res, score = beam_decode(learn.model, image, 3, seq_len)    #294, 3m18s\n",
    "# 294 - 1m40s\n",
    "# 294 - 1m45s (w/ score_func)\n",
    "# 295 - 22s (beam_width=1 ~ greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r = torch.tensor([b_res], dtype=torch.long, device=device)\n",
    "p = char_label_text(r)\n",
    "\n",
    "_cer(truth, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# valid\n",
    "p = char_label_text(v_res[idx][None])\n",
    "t = char_label_text(y1[0])\n",
    "_cer(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# greedy\n",
    "p = char_label_text(g_res[idx][None])\n",
    "t = char_label_text(y1[0])\n",
    "_cer(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# beam (sz=3)\n",
    "r = torch.tensor([b_res], dtype=torch.long, device=device)\n",
    "p = char_label_text(r)\n",
    "t = char_label_text(y1[0])\n",
    "_cer(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stoi = {k:i for i,k in enumerate(itos)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(char_label_text(g_res[idx][None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "st = ''.join([itos[i] for i in b_res])\n",
    "p = '\\n'.join(textwrap.wrap(st, 70))\n",
    "show_img(denorm(x1)[0], figsize=(10,10), title=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Source Attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "img = imgs[idx]\n",
    "\n",
    "v_chars = v_res[idx]\n",
    "v_attns = to_np(torch_scale_attns(v_attn)[idx])\n",
    "\n",
    "g_chars = g_res[idx]\n",
    "g_attns = to_np(torch_scale_attns(g_attn)[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#valid\n",
    "fig, axes = plt.subplots(5,4, gridspec_kw={'hspace': 0.3}, figsize=(20, 20))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    a = g_filter(vv_attns[i])\n",
    "    ax.imshow(img, alpha=None)\n",
    "    ax.imshow(a, cmap='Blues', interpolation='nearest', alpha=0.3)\n",
    "    ax.set_title(itos[v_chars[i].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#greedy\n",
    "fig, axes = plt.subplots(6,4, gridspec_kw={'hspace': 0.3}, figsize=(20, 20))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    a = g_filter(g_attns[i])\n",
    "    ax.imshow(img, alpha=None)\n",
    "    ax.imshow(a, cmap='Blues', interpolation='nearest', alpha=0.3)\n",
    "    ax.set_title(itos[g_chars[i].item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Attention Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "k=16\n",
    "\n",
    "def torch_scale_attns(attns):\n",
    "    bs,sl,hw = attns.shape\n",
    "    num = int(math.sqrt(hw))   # sz // k\n",
    "    mod = attns.view(bs,sl,num,num)\n",
    "    scaled = F.interpolate(mod, size=sz)\n",
    "    return scaled  #([bs, sl, h, w])\n",
    "\n",
    "def g_filter(att):\n",
    "    return gaussian_filter(att, sigma=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def self_attn(layer=-1): return learn.model.transformer.decoder.layers[layer].self_attn.attn.data.cpu()\n",
    "def source_attn(layer=-1): return learn.model.transformer.decoder.layers[layer].src_attn.attn.data.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def transparent_cmap(cmap, N=5):\n",
    "    \"Copy colormap and set alpha values\"\n",
    "    mycmap = plt.cm.get_cmap(cmap, N)\n",
    "    mycmap._init()\n",
    "    mycmap._lut[:,-1] = np.linspace(0, 0.6, N+3)\n",
    "    return mycmap\n",
    "\n",
    "#Use base cmap to create transparent\n",
    "# mycmap = transparent_cmap(plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show_attn(img, attns, chars, ax, color, showChars=True):\n",
    "    for i in range(attns.shape[0]):\n",
    "        c = chars[i].item()\n",
    "        if c not in [0,1,2,3]:\n",
    "            a = g_filter(attns[i])\n",
    "            y,x = scipy.ndimage.center_of_mass(a)\n",
    "            #sns.heatmap(a, cmap=mycmap, cbar=False, ax=ax)\n",
    "            ax.imshow(a, cmap=transparent_cmap(color), interpolation='nearest')\n",
    "            if showChars: ax.text(x-8,y-10,word_itos[c], fontsize=15)\n",
    "\n",
    "    ax.set_title(char_label_text(chars))\n",
    "    ax.imshow(img.permute(1,2,0), alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def thresh_attn(attn, thresh=0.1):\n",
    "    zeros = torch.zeros_like(attn)\n",
    "    new = torch.where(attn >= thresh, attn, zeros)\n",
    "    \n",
    "    # some attns will not have a value over the thresh in which case\n",
    "    # we need to insert top k value at appropriate index\n",
    "    vals, idxs = torch.topk(attn, 1, dim=-1)\n",
    "    \n",
    "    # reshape\n",
    "    flat_new = new.flatten(0,1)\n",
    "    vals = vals.flatten()\n",
    "    idxs = idxs.flatten()\n",
    "    \n",
    "    for i in range(flat_new.size(0)):\n",
    "        flat_new[i,idxs[i]] = vals[i]\n",
    "\n",
    "    new = flat_new.view_as(new)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Decoder Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(context=\"notebook\")\n",
    "\n",
    "def draw(data, x, y, ax):\n",
    "    return sns.heatmap(data, xticklabels=x, square=True, yticklabels=y, vmin=0.0, vmax=1.0,\n",
    "                       cmap='YlOrRd', linewidths=0.05, cbar=False, ax=ax)\n",
    "\n",
    "for layer in range(4):\n",
    "    print(\"Decoder Self-Attention Layer\", layer+1)\n",
    "\n",
    "    fig, axes = plt.subplots(1,4, figsize=(20, 10))\n",
    "    for i,ax in enumerate(axes.flat):\n",
    "        # greedy decoding (no access to true values)\n",
    "        pred = char_split_text(g_res[i])[20:40]\n",
    "        shifted_y = rshift(g_res.float()).long()\n",
    "        true = char_split_text(shifted_y[i])[20:40]\n",
    "        g = draw(self_attn(layer)[i].data[20:40, 20:40], true, pred, ax=ax)\n",
    "        g.set_yticklabels(g.get_yticklabels(), rotation=0) \n",
    "        g.set_xticklabels(g.get_xticklabels(), rotation=0) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Decoder Source-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,4, gridspec_kw={'hspace': 0.5}, figsize=(20, 10))\n",
    "    \n",
    "for idx in range(len(axes.flat)//4):\n",
    "    img = x[idx]\n",
    "    g_chars = g_res[idx]\n",
    "    \n",
    "    # 4 attn layers\n",
    "    for h in range(4):\n",
    "        attn = source_attn(h)\n",
    "        g_attns = to_np(torch_scale_attns(attn)[idx])\n",
    "\n",
    "        show_attn(img, g_attns, g_chars, axes[idx,h], 'YlGn', showChars=False)\n",
    "        axes[idx,h].set_title(f'layer {h+1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Validation vs Greedy (final layer src-attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "v_scaled_attns = torch_scale_attns(thresh_attn(v_attn))\n",
    "g_scaled_attns = torch_scale_attns(thresh_attn(g_attn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2, gridspec_kw={'hspace': 0.5}, figsize=(20, 20))\n",
    "for idx in range(len(axes.flat)//2):\n",
    "    img = imgs[idx]\n",
    "\n",
    "    v_chars = v_res[idx]\n",
    "    v_attns = to_np(v_scaled_attns[idx])\n",
    "\n",
    "    g_chars = g_res[idx]\n",
    "    g_attns = to_np(g_scaled_attns[idx])\n",
    "    \n",
    "    # valid\n",
    "    show_attn(img, v_attns, v_chars, axes[idx,0], 'YlOrRd')\n",
    "    # greedy\n",
    "    show_attn(img, g_attns, g_chars, axes[idx,1], 'YlGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Individual Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx=1\n",
    "img = x[idx]\n",
    "\n",
    "g_chars = g_res[idx]\n",
    "g_scaled_attns = torch_scale_attns(thresh_attn(g_attn)[0:1])  # passing in bs of 1\n",
    "g_attns = to_np(g_scaled_attns[0])  # removing bs\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(20, 20))\n",
    "show_attn(img, g_attns, g_chars, ax, 'YlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(context=\"notebook\")\n",
    "\n",
    "def draw(data, x, y, ax):\n",
    "    mask = np.zeros_like(data)\n",
    "    mask[np.triu_indices_from(mask, k=1)] = True\n",
    "    return sns.heatmap(data, xticklabels=x, square=True, yticklabels=y, vmin=0.0, vmax=1.0,\n",
    "                       mask=mask, cmap='YlOrRd', linewidths=0.05, cbar=False, ax=ax)\n",
    "\n",
    "for layer in range(4):\n",
    "    print(\"Decoder Self-Attention Layer\", layer+1)\n",
    "\n",
    "    fig, ax = plt.subplots(1,1, figsize=(20, 10))\n",
    "    i = 1\n",
    "    # greedy decoding (no access to true values)\n",
    "    pred = char_split_text(g_res[i])[230:280]\n",
    "    shifted_y = rshift(g_res.float()).long()\n",
    "    true = char_split_text(shifted_y[i])[230:280]\n",
    "    g = draw(self_attn(layer)[i].data[230:280, 230:280], true, pred, ax=ax)\n",
    "    g.set_yticklabels(g.get_yticklabels(), rotation=0) \n",
    "    g.set_xticklabels(g.get_xticklabels(), rotation=0) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Backprop - chart dependencies (batch leakage) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xb,yb = next(iter(learn.data.train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.model.eval()   # this is important!!!  otherwise batchnorm will mess things up\n",
    "learn.model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xb.requires_grad_(True)\n",
    "xb.grad.zero_()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shifted_y = rshift(yb).long()\n",
    "tgt_mask = subsequent_mask(shifted_y.size(-1))\n",
    "pb = learn.model(xb, shifted_y, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# loss = learn.loss_func(pb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss = pb[2].sum()\n",
    "loss.backward()\n",
    "assert (xb.grad[2] != 0).any()\n",
    "assert (xb.grad[1] == 0.).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xb.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {},
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
