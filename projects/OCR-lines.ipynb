{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources:\n",
    "\n",
    "http://forums.fast.ai/t/fastai-for-image-captioning/17003/8\n",
    "\n",
    "https://github.com/githubharald/SimpleHTR/blob/master/src/DataLoader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T16:10:14.052907Z",
     "start_time": "2018-08-21T16:10:13.792695Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T16:10:15.636961Z",
     "start_time": "2018-08-21T16:10:14.157860Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastai.fastai.conv_learner import *\n",
    "from fastai.fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T16:10:15.923327Z",
     "start_time": "2018-08-21T16:10:15.874670Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = Path('data/IAM_handwriting')\n",
    "TMP_PATH = PATH/'tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T16:10:16.339052Z",
     "start_time": "2018-08-21T16:10:16.159759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mascii\u001b[m\u001b[m           line_labels.csv \u001b[34mmodels\u001b[m\u001b[m          \u001b[34mtmp\u001b[m\u001b[m             \u001b[34mwords\u001b[m\u001b[m\r\n",
      "\u001b[34mforms\u001b[m\u001b[m           \u001b[34mlines\u001b[m\u001b[m           \u001b[34msentences\u001b[m\u001b[m       word_labels.csv words.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T16:10:16.633441Z",
     "start_time": "2018-08-21T16:10:16.581154Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def open_image(fname):\n",
    "    f = fname if fname.endswith('.png') else fname+'.png'\n",
    "    return Image.open(f'{PATH}/lines/{f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-17T14:35:34.540411Z",
     "start_time": "2018-08-17T14:35:34.449319Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "open_image('r06-143-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:25:51.012682Z",
     "start_time": "2018-08-20T22:25:50.933127Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "line_labels = pd.read_csv(f'{PATH}/ascii/lines.txt', names=['filename','result','value'], escapechar='\\\\', delim_whitespace=True, skiprows=23, header=None, usecols=[0,1,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:26:01.483345Z",
     "start_time": "2018-08-20T22:26:01.429078Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "line_labels.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:26:03.213163Z",
     "start_time": "2018-08-20T22:26:02.959490Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "line_labels['text'] = line_labels.apply(lambda row: row.value.replace('|', ' '), axis=1)\n",
    "line_labels.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T19:22:22.717853Z",
     "start_time": "2018-07-26T19:22:22.657344Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### Tokenize Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:26:19.495788Z",
     "start_time": "2018-08-20T22:26:16.740104Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokens = Tokenizer().proc_all_mp(partition_by_cores(line_labels.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:26:23.800339Z",
     "start_time": "2018-08-20T22:26:23.747488Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.argmax([len(o) for o in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:26:39.236679Z",
     "start_time": "2018-08-20T22:26:39.185129Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokens[4964], len(tokens[4964])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:26:43.833437Z",
     "start_time": "2018-08-20T22:26:43.778435Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.percentile([len(o) for o in tokens], 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Numericalize Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:26:46.008748Z",
     "start_time": "2018-08-20T22:26:45.930308Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "freq = Counter(word for line in tokens for word in line)\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:26:55.379091Z",
     "start_time": "2018-08-20T22:26:55.329999Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "max_vocab=40000\n",
    "min_freq=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:31:06.122995Z",
     "start_time": "2018-08-20T22:31:06.004112Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "itos = [word for word,count in freq.most_common(max_vocab) if count>min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(1, '_bos_')\n",
    "itos.insert(2, '_unk_')\n",
    "\n",
    "stoi = collections.defaultdict(lambda: 2, {v:k for k,v in enumerate(itos)})\n",
    "ids = np.array([np.array([1] + [stoi[word] for word in line]) for line in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:31:09.206531Z",
     "start_time": "2018-08-20T22:31:09.155723Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(ids), len(itos)#, len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:31:17.231073Z",
     "start_time": "2018-08-20T22:31:17.178888Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def idstoline(ids):\n",
    "    return ' '.join(itos[i] for i in ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:31:18.191521Z",
     "start_time": "2018-08-20T22:31:18.139921Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idstoline(ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:32:12.581886Z",
     "start_time": "2018-08-20T22:32:12.451226Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save(TMP_PATH/'ids.npy', ids)\n",
    "pickle.dump(itos, open(TMP_PATH/'itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:37:55.226135Z",
     "start_time": "2018-08-20T22:37:54.847830Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add ids to df\n",
    "line_labels['ids'] = [' '.join(str(p) for p in o) for o in ids]\n",
    "line_labels.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### load Wikitext103 pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:32:23.758047Z",
     "start_time": "2018-08-20T22:32:23.707079Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pre_path = Path('data/aclImdb/models/wt103')\n",
    "pre_lm_path = pre_path/'fwd_wt103.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:32:25.700807Z",
     "start_time": "2018-08-20T22:32:25.082063Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wgts = torch.load(pre_lm_path, map_location=lambda storage, loc: storage )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:32:43.858687Z",
     "start_time": "2018-08-20T22:32:43.769350Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dec_wgts = to_np(wgts['1.decoder.weight'])\n",
    "row_mean = dec_wgts.mean(0)\n",
    "dec_wgts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:33:03.063283Z",
     "start_time": "2018-08-20T22:33:02.872101Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wiki_itos = pickle.load((pre_path/'itos_wt103.pkl').open('rb'))\n",
    "wiki_stoi = collections.defaultdict(lambda: -1, {v:k for k,v in enumerate(wiki_itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:36:03.141199Z",
     "start_time": "2018-08-20T22:36:03.080456Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_emb(dec_wgts, itos):\n",
    "    row_mean = torch.from_numpy(dec_wgts.mean(0))\n",
    "    em_sz = dec_wgts.shape[1]\n",
    "    # embedding: simple lookup table - input=index; output=word vector\n",
    "    # embeddings: rows = vocab size (4085), columns = determined by wiki pre-trained weights (400)\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    # learnable pytorch module has a 'weight' attribute => Variable\n",
    "    # 'weight' attribute has a 'data' attribute => Tensor\n",
    "    wgts = emb.weight.data\n",
    "    # iterate through vocabulary and replace found words w/ pretrained vector weights if available\n",
    "    for idx,word in enumerate(itos):\n",
    "        wiki_int = wiki_stoi[word]\n",
    "        wgts[idx] = torch.from_numpy(dec_wgts[wiki_int]) if wiki_int >= 0 else row_mean\n",
    "    \n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:36:20.971769Z",
     "start_time": "2018-08-20T22:36:20.829573Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "emb_dec = create_emb(dec_wgts, itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:36:51.494319Z",
     "start_time": "2018-08-20T22:36:51.435321Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.save(emb_dec, TMP_PATH/'embedding_decoder.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save DF as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T16:10:19.745287Z",
     "start_time": "2018-08-21T16:10:19.680887Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_dec = torch.load(TMP_PATH/'embedding_decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T16:10:20.078954Z",
     "start_time": "2018-08-21T16:10:19.978619Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = np.load(TMP_PATH/'ids.npy')\n",
    "itos = pickle.load(open(TMP_PATH/'itos.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T16:10:20.371139Z",
     "start_time": "2018-08-21T16:10:20.319771Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CSV = PATH/'line_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T16:10:20.779774Z",
     "start_time": "2018-08-21T16:10:20.703128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a01-000u-00</td>\n",
       "      <td>1 9 32 1311 7 500 41 4 949 39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a01-000u-01</td>\n",
       "      <td>1 2 111 65 162 121 1312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a01-000u-02</td>\n",
       "      <td>1 16 7 25 104 28 9 387 6 162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a01-000u-03</td>\n",
       "      <td>1 894 501 4 41 4 1623 834 46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a01-000u-04</td>\n",
       "      <td>1 205 136 9 2148 26 3 708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                            ids\n",
       "0  a01-000u-00  1 9 32 1311 7 500 41 4 949 39\n",
       "1  a01-000u-01        1 2 111 65 162 121 1312\n",
       "2  a01-000u-02   1 16 7 25 104 28 9 387 6 162\n",
       "3  a01-000u-03   1 894 501 4 41 4 1623 834 46\n",
       "4  a01-000u-04      1 205 136 9 2148 26 3 708"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# line_labels.to_csv(CSV, columns=['filename', 'ids'], index=False)\n",
    "csv = pd.read_csv(CSV)\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:38:53.131147Z",
     "start_time": "2018-08-20T22:38:53.079395Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T15:55:06.919407Z",
     "start_time": "2018-07-31T15:55:06.865125Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CSV.open().readlines()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get val_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T16:10:23.300711Z",
     "start_time": "2018-08-21T16:10:23.248839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2003"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_idxs = np.array(csv.sample(frac=0.15).index)\n",
    "len(val_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Data (rotate, normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T16:10:32.895961Z",
     "start_time": "2018-08-21T16:10:32.848184Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sz = 300\n",
    "bs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T16:10:34.137579Z",
     "start_time": "2018-08-21T16:10:33.929898Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use this md object to load image data w/ transforms\n",
    "\n",
    "# These values were generated initially with tfms_from_model(resnet34)\n",
    "stats = A([ 0.92025,  0.92025,  0.92025], [ 0.12774,  0.12774,  0.12774])\n",
    "\n",
    "aug_tfms = [RandomRotate(1, mode=0), RandomLighting(0.05, 0.05)]\n",
    "\n",
    "tfms = tfms_from_stats(stats, sz, crop_type=CropType.NO, aug_tfms=aug_tfms)\n",
    "data = ImageClassifierData.from_csv(PATH, 'lines', CSV, bs=bs, val_idxs=val_idxs, tfms=tfms, suffix='.png',\n",
    "                                    continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**\n",
    "- x: images (with aug_tfms)\n",
    "- y: array of ints -> represent words in a line\n",
    "    -- pre_pad=False, pad_idx=0, transpose_y=?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T16:10:37.172604Z",
     "start_time": "2018-08-21T16:10:37.124399Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pad ends of lines with pad token for language model\n",
    "data.aug_dl.pre_pad=False\n",
    "data.trn_dl.pre_pad=False\n",
    "data.val_dl.pre_pad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T16:10:56.125204Z",
     "start_time": "2018-08-21T16:10:37.687089Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "denorm = data.trn_ds.denorm\n",
    "x,y = next(iter(data.aug_dl))\n",
    "x = denorm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T16:10:56.502241Z",
     "start_time": "2018-08-21T16:10:56.455710Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idstoline(ids):\n",
    "    return ' '.join(itos[i] for i in ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T22:45:20.797708Z",
     "start_time": "2018-08-20T22:45:20.744665Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ints = to_np(y[9]).astype(int)\n",
    "idstoline(ints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View image transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T15:05:47.354648Z",
     "start_time": "2018-08-21T15:05:47.303949Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None, alpha=None, title=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im, alpha=alpha)\n",
    "    ax.set_axis_off()\n",
    "    if title: ax.set_title(title)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T15:16:05.997215Z",
     "start_time": "2018-08-21T15:16:05.590203Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,1, figsize=(20, 10))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ints = to_np(y[i]).astype(int)\n",
    "    t = idstoline(ints)\n",
    "#     t = data.classes[y[i]]\n",
    "    ax=show_img(x[i], ax=ax, title=t)\n",
    "    \n",
    "plt.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Determine size of dataset (2000 x 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T21:15:10.854374Z",
     "start_time": "2018-07-30T21:15:10.158431Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create a dictionary comprehension of image sizes in the dataset\n",
    "size_d = {k: PIL.Image.open(PATH/k).size for k in data.val_ds.fnames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T21:15:30.201385Z",
     "start_time": "2018-07-30T21:15:30.150609Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "row_sz,col_sz = list(zip(*size_d.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T21:15:49.738310Z",
     "start_time": "2018-07-30T21:15:49.687166Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "row_sz = np.array(row_sz); col_sz = np.array(col_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T21:16:09.499644Z",
     "start_time": "2018-07-30T21:16:09.310733Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(row_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T21:16:31.568001Z",
     "start_time": "2018-07-30T21:16:31.399168Z"
    },
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(col_sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Initial Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conv basis\n",
    "# head_reg4 = nn.Sequential(Flatten(), nn.Linear(25088,em_sz))   # last layer has 7x7x512 in ResNet34\n",
    "# learn = ConvLearner.pretrained(f_model, md, custom_head=head_reg4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T15:55:29.565897Z",
     "start_time": "2018-08-20T15:55:29.517751Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vs = len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T15:55:31.810780Z",
     "start_time": "2018-08-20T15:55:31.052885Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f = vgg19\n",
    "# conv_model = nn.Sequential(*children(f(True))[:-1])\n",
    "\n",
    "f = resnet34\n",
    "conv_model = nn.Sequential(*children(f(True))[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T15:58:24.582179Z",
     "start_time": "2018-08-20T15:58:24.201176Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = conv_model(T(x).permute(0,3,1,2)[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T15:58:26.433591Z",
     "start_time": "2018-08-20T15:58:26.383900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T15:59:21.910208Z",
     "start_time": "2018-08-20T15:59:21.862160Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model[-1][-1].bn2.num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRU**\n",
    "\n",
    "Inputs: input, h_0\n",
    "    - **input** of shape `(seq_len, batch, input_size)`: tensor containing the features\n",
    "      of the input sequence. The input can also be a packed variable length\n",
    "      sequence. See :func:`torch.nn.utils.rnn.pack_padded_sequence`\n",
    "      for details.\n",
    "    - **h_0** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
    "      containing the initial hidden state for each element in the batch.\n",
    "      Defaults to zero if not provided.\n",
    "\n",
    "Outputs: output, h_n\n",
    "    - **output** of shape `(seq_len, batch, hidden_size * num_directions)`: tensor\n",
    "      containing the output features h_t from the last layer of the GRU,\n",
    "      for each t. If a :class:`torch.nn.utils.rnn.PackedSequence` has been\n",
    "      given as the input, the output will also be a packed sequence.\n",
    "    - **h_n** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
    "      containing the hidden state for `t = seq_len`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T15:55:36.828524Z",
     "start_time": "2018-08-20T15:55:36.781123Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em_sz = 400\n",
    "# vocab_size = 4085\n",
    "# batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-17T22:09:32.608636Z",
     "start_time": "2018-08-17T22:09:32.540243Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN_Encoder(nn.Module):\n",
    "    def __init__(self, conv_model, em_sz, p_num):\n",
    "        super().__init__()\n",
    "#         c = conv_model[-2].num_features  #vgg\n",
    "        c = conv_model[-1][-1].bn2.num_features  #resnet\n",
    "        \n",
    "        self.pool = nn.AdaptiveMaxPool2d(p_num)      #(bs,128,7,7)\n",
    "        self.fc1 = nn.Linear(c*(p_num**2), 1000)\n",
    "        self.bn = nn.BatchNorm1d(1000, momentum=0.01)\n",
    "        self.fc2 = nn.Linear(1000, em_sz)\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        feats = conv_model(inp)                  #=> ([50, 128, ?, ?])  (bs,c,h,w)\n",
    "        feats = self.pool(feats)                 #=> ([50, 128, 7, 7])\n",
    "        feats = feats.view(feats.size(0), -1)    #(bs,6272)\n",
    "        feats = self.bn(F.relu(self.fc1(feats))) #(bs,1000)\n",
    "        return self.fc2(feats)                   #(bs,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-16T16:35:26.193958Z",
     "start_time": "2018-08-16T16:35:26.073608Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# based on Show,Attend,Tell - https://github.com/parksunwoo/show_attend_and_tell_pytorch/blob/master/model.py\n",
    "\n",
    "class Seq2SeqCNN_RNN(nn.Module):\n",
    "    def __init__(self, conv_model, vs, em_sz, sl=20, nl=1, p_num=7):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = CNN_Encoder(conv_model, em_sz, p_num)\n",
    "\n",
    "        self.emb = emb_dec #nn.Embedding.from_pretrained(emb_dec)\n",
    "        # self.emb = nn.Embedding(vs, em_sz) #=> Embedding(80, 256)\n",
    "        self.gru = nn.GRU(em_sz, em_sz, num_layers=nl) #, dropout=0.1)\n",
    "        self.drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz, vs) #=> ([256, 80])\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        ### Encoder (Conv Layer) ###\n",
    "        feats = self.encoder(inp)\n",
    "        bs,c = feats.size()   # need this because last batch isn't 50\n",
    "\n",
    "        h = feats.unsqueeze(0)         #(1,bs,256)\n",
    "    \n",
    "        ### DECODER LOOP ###    loop through ~20 times -> for each word in output\n",
    "        dec_inp = V(torch.ones(bs).long()) #=> ([bs])   # initialize first word (with _bos_ token) and then replace \n",
    "        res = []\n",
    "\n",
    "        for i in range(self.sl):            \n",
    "            emb = self.emb(dec_inp).unsqueeze(0)         # embedding => ([1, bs, 256])\n",
    "            outp, h = self.gru(emb, h)                   # rnn => ([1, bs, 256]),  ([1, bs, 256])\n",
    "            outp = self.out(self.drop(outp[0]))          # dropout, linear layer => ([256, 4085])\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])   #=> ([64])\n",
    "#             if (dec_inp==1).all(): break       # 1: padding token => stop, we're done (padding at the end)\n",
    "        return torch.stack(res)                  # stack up list of results into single tensor and return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-16T16:16:29.389558Z",
     "start_time": "2018-08-16T16:16:29.317228Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# categorical cross entropy loss\n",
    "# list of probabilities for each character in vocab; target is correct character\n",
    "\n",
    "def seq2seq_loss(input, target):    \n",
    "    targ = target.transpose(0,1).contiguous()  # need to switch the axes to line up\n",
    "    sl,bs = targ.size()   #=> ([13,50])\n",
    "    sl_in,bs_in,nc = input.size()  #=> ([20, 50, 80])\n",
    "        \n",
    "    # tweak 1: align sequence lengths (input is always 20 but target often is less)\n",
    "    if sl_in>sl: targ = F.pad(targ, (0,0,0,sl_in-sl)) # rank2 tensor requires 4 padding values\n",
    "    # (padLeft, padRight, padTop, padBottom) => (before 1, after 1, before 0, after 0)\n",
    "    # sequence length: add as much padding as necessary at the end\n",
    "    \n",
    "    # input = input[:sl]\n",
    "    targ = targ[:20,:].long()\n",
    "    # cross_entropy expects rank2 tensor but we have sl * bs so we need to flatten out both\n",
    "    # combination of LogSoftmax and NLLLoss\n",
    "    return F.cross_entropy(input.view(-1,nc), targ.view(-1))  #=> ([1000, 80]), ([1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-16T16:35:29.427776Z",
     "start_time": "2018-08-16T16:35:29.282444Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n",
    "rnn = Seq2SeqCNN_RNN(conv_model, vs, em_sz)\n",
    "# SingleModel => way to handle learning rate groups -> treats whole thing as single group\n",
    "# easy way to turn pytorch module into fastai model\n",
    "learn = RNN_Learner(data, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-08-16T16:35:31.255Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find(start_lr=1e-7)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T15:56:56.857796Z",
     "start_time": "2018-08-20T15:56:56.810705Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em_sz,sl = 400,20\n",
    "# vocab_size = 4085\n",
    "# batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid try1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T16:04:38.499612Z",
     "start_time": "2018-08-20T16:04:38.433388Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN_Encoder(nn.Module):\n",
    "    def __init__(self, conv_model, em_sz, p_num):\n",
    "        super().__init__()\n",
    "        # self.c = conv_model[-2].num_features  #vgg\n",
    "        self.c = conv_model[-1][-1].bn2.num_features  #resnet\n",
    "        \n",
    "        self.pool = nn.AdaptiveMaxPool2d(p_num)      #(bs,128,7,7)\n",
    "        self.fc = nn.Linear(self.c, em_sz)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        feats = conv_model(inp)                  #=> ([50, 128, ?, ?])  (bs,c,h,w)\n",
    "        feats = self.pool(feats)                 #=> ([50, 128, 7, 7])\n",
    "        feats = feats.permute(2,3,0,1).view(-1,bs,self.c)  #(p_num**2,bs,c)\n",
    "        feats = self.fc(feats)                   #(49,bs,400)\n",
    "        return feats                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T16:26:33.656294Z",
     "start_time": "2018-08-20T16:26:33.485127Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# based on Show,Attend,Tell - https://github.com/parksunwoo/show_attend_and_tell_pytorch/blob/master/model.py\n",
    "def rand_t(*sz): return torch.randn(sz)/math.sqrt(sz[0])\n",
    "def rand_p(*sz): return nn.Parameter(rand_t(*sz))\n",
    "\n",
    "#class ATTN_Decoder(nn.Module):\n",
    "\n",
    "\n",
    "class Attn_RNN(nn.Module):\n",
    "    def __init__(self, conv_model, vs, em_sz, sl=20, nl=1, p_num=7):\n",
    "        super().__init__()\n",
    "        self.encoder = CNN_Encoder(conv_model, em_sz, p_num)\n",
    "        \n",
    "        self.emb = emb_dec #nn.Embedding.from_pretrained(emb_dec)\n",
    "        # self.emb = nn.Embedding(vs, em_sz) #=> Embedding(80, 256)\n",
    "        self.gru = nn.GRU(em_sz, em_sz, num_layers=nl) #, dropout=0.1)\n",
    "        self.drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz, vs) #=> ([256, 80])\n",
    "        \n",
    "        # setting up Attention Layers\n",
    "        self.W1 = rand_p(em_sz, em_sz)\n",
    "        self.l2 = nn.Linear(em_sz, em_sz) \n",
    "        self.l3 = nn.Linear(em_sz*2, em_sz) #=> ([768, 256])\n",
    "        self.V = rand_p(em_sz)  #=> ([256])\n",
    "\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        ### Encoder (Conv Layer) ###\n",
    "        feats = self.encoder(inp)\n",
    "        mask_sz,bs,c = feats.size()             # need this because last batch isn't 50\n",
    "        #h = feats.unsqueeze(0)             #(bs,256)\n",
    "        \n",
    "    \n",
    "        ### DECODER LOOP ###    loop through ~20 times -> for each word in output\n",
    "        dec_inp = V(torch.zeros(bs).long()) #=> ([bs])   # initialize first word (with _unk_??) and then replace \n",
    "        hidden = torch.zeros(1, 1, em_sz)\n",
    "        res,attns = [],[]\n",
    "\n",
    "        \n",
    "        for i in range(sl):   \n",
    "            # embedded input\n",
    "            emb = self.emb(dec_inp) #=> ([50, 400])\n",
    "            w1e = emb @ self.W1     #=> ([50, 400])     \n",
    "\n",
    "            # hidden state\n",
    "            #w2h = self.l2(h[-1])  #=> ([125, 300])\n",
    "            w2h = self.l2(hidden)    #=> ([1, 1, 400])\n",
    "            \n",
    "            # non-linear activation\n",
    "            u = F.tanh(w1e + w2h) #=> ([30, 125, 300])\n",
    "            # matrix multiply; softmax ensures all weights add up to 1 and 1 is higher than the rest\n",
    "            a = F.softmax(u @ self.V, 0)  #=> ([30, 125])\n",
    "            attns.append(a)\n",
    "            Xa = (a.unsqueeze(2) * feats).sum(0) #=> ([125, 256])\n",
    "#             emb = self.emb(dec_inp) #=> ([125, 556])\n",
    "            wgt_enc = self.l3(torch.cat([emb, Xa], 1)) #=> ([125, 300])\n",
    "            \n",
    "            outp, hidden = self.gru(feats, wgt_enc.unsqueeze(0))\n",
    "\n",
    "            outp = self.out(self.drop(outp[0]))          # dropout, linear layer => ([256, 4085])\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])   #=> ([64])\n",
    "#             if (dec_inp==1).all(): break       # 1: padding token => stop, we're done (padding at the end)\n",
    "        return torch.stack(res)                  # stack up list of results into single tensor and return it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###  Pytorch seq2seq  \n",
    "\n",
    "https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#attention-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-17T15:50:15.509017Z",
     "start_time": "2018-08-17T15:50:15.306326Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Attn_RNN(nn.Module):\n",
    "    def __init__(self, conv_model, vs, em_sz, sl, dropout_p=0.1, nl=1, p_num=7):\n",
    "        # 256, ,10\n",
    "        super(Attn_RNN, self).__init__()\n",
    "        self.em_sz = em_sz  # 256\n",
    "        self.vs = vs  # num words in output ~ vs\n",
    "        self.dropout_p = dropout_p\n",
    "        self.sl = sl    # 10\n",
    "\n",
    "        # ENCODER\n",
    "        c = conv_model[-2].num_features\n",
    "        self.pool = nn.AdaptiveMaxPool2d(p_num)      #(bs,128,7,7)\n",
    "        self.linear = nn.Linear(c*(p_num**2), em_sz)  #(6272, 256)\n",
    "        self.bn = nn.BatchNorm1d(em_sz, momentum=0.01)\n",
    "        \n",
    "        # DECODER\n",
    "        self.embedding = nn.Embedding(self.vs, self.em_sz)\n",
    "        self.attn = nn.Linear(self.em_sz * 2, self.sl)\n",
    "        self.attn_combine = nn.Linear(self.em_sz * 2, self.em_sz)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.em_sz, self.em_sz)\n",
    "        self.out = nn.Linear(self.em_sz, self.vs)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # decoder_input = torch.tensor([[SOS_token]], device=device)  # BOS token\n",
    "        # decoder_hidden = encoder_hidden\n",
    "        # encoder_outputs = ([input_length, max_length, hidden_size])\n",
    "        \n",
    "        \n",
    "        ### Encoder (Conv Layer) ###\n",
    "        feats = conv_model(inp)              #=> ([50, 128, 16, 16])  (bs,c,h,w)\n",
    "        feats = self.pool(feats)             #=> ([50, 64, 7, 7])\n",
    "        out = feats.view(feats.size(0), -1)  #(bs,6272)\n",
    "        out = self.bn(self.linear(out))      #(bs,256)\n",
    "        bs,c = out.size()                    # need this because last batch isn't 50\n",
    "        h = out.unsqueeze(0)                 #(1,bs,256)\n",
    " \n",
    "\n",
    "        ### DECODER LOOP ###    loop through ~20 times -> for each word in output\n",
    "        #dec_inp = V(torch.zeros(bs).long()) #=> ([bs])   # initialize first word (with _unk_??) and then replace \n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        hidden = V(torch.zeros(bs,em_sz)) #=> ([bs])\n",
    "\n",
    "        res,attns = [],[]\n",
    "\n",
    "        # Embed the input & apply dropout\n",
    "        embedded = self.embedding(dec_inp)  \n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        # Concatenate embedded input & hidden -> linear layer -> softmax\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded, hidden), 1)), dim=1)\n",
    "        \n",
    "        # Batch Matrix Multiply attention weights and encoder outputs\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), h)\n",
    "\n",
    "        # Concatenate applied attention & embedded input -> linear layer -> relu\n",
    "        output = torch.cat((embedded, attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T16:26:35.815899Z",
     "start_time": "2018-08-20T16:26:35.755953Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# categorical cross entropy loss\n",
    "# list of probabilities for each character in vocab; target is correct character\n",
    "\n",
    "def seq2seq_loss(input, target):    \n",
    "    targ = target.transpose(0,1).contiguous()  # need to switch the axes to line up\n",
    "    sl,bs = targ.size()   #=> ([13,50])\n",
    "    sl_in,bs_in,nc = input.size()  #=> ([20, 50, 80])\n",
    "        \n",
    "    # tweak 1: align sequence lengths (input is always 20 but target often is less)\n",
    "    if sl_in>sl: targ = F.pad(targ, (0,0,0,sl_in-sl)) # rank2 tensor requires 4 padding values\n",
    "    # (padLeft, padRight, padTop, padBottom) => (before 1, after 1, before 0, after 0)\n",
    "    # sequence length: add as much padding as necessary at the end\n",
    "    \n",
    "    # input = input[:sl]\n",
    "    targ = targ[:20,:].long()\n",
    "    # cross_entropy expects rank2 tensor but we have sl * bs so we need to flatten out both\n",
    "    # combination of LogSoftmax and NLLLoss\n",
    "    return F.cross_entropy(input.view(-1,nc), targ.view(-1))  #=> ([1000, 80]), ([1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T16:26:36.299769Z",
     "start_time": "2018-08-20T16:26:36.213527Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n",
    "rnn = Attn_RNN(conv_model, vs, em_sz, sl)\n",
    "# SingleModel => way to handle learning rate groups -> treats whole thing as single group\n",
    "# easy way to turn pytorch module into fastai model\n",
    "learn = RNN_Learner(data, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T16:29:22.915485Z",
     "start_time": "2018-08-20T16:26:36.757126Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find(start_lr=1e-7)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tensorflow/models/blob/master/research/attention_ocr/python/model.py\n",
    "https://www.tensorflow.org/api_docs/python/tf/contrib/legacy_seq2seq/attention_decoder\n",
    "\n",
    "prev_attn = initialized to zero  \n",
    "cell = GRU or LSTM  \n",
    "input = A list of 2D Tensors [batch_size x input_size]  \n",
    "attention_states = 3D Tensor [batch_size x attn_length x attn_size]  \n",
    "prev_state = 2D Tensor with shape [batch_size x cell.state_size]  \n",
    "\n",
    "First, we run the cell on a combination of the input and previous attention masks:  \n",
    "* cell_output, new_state = cell(linear(input, prev_attn), prev_state)  \n",
    "\n",
    "Then, we calculate new attention masks:  \n",
    "* new_attn = softmax(V^T * tanh(W * attention_states + U * new_state))  \n",
    "\n",
    "and then we calculate the output:  \n",
    "* output = linear(cell_output, new_attn)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev_attn = T(torch.zeros(bs, em_sz))\n",
    "prev_state = T(torch.zeros(bs, em_sz))\n",
    "inp = self.embedding(input)\n",
    "self.linear(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom Up Attention\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "notify_time": "30",
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
